<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dai, Yutong / 戴宇童</title>
    <link>/</link>
    <description>Recent content on Dai, Yutong / 戴宇童</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    
	    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Cheatsheet Template</title>
      <link>/resources/tex-rmd/cheatsheet/</link>
      <pubDate>Fri, 31 May 2019 00:00:00 +0100</pubDate>
      
      <guid>/resources/tex-rmd/cheatsheet/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Homework Template</title>
      <link>/resources/tex-rmd/homework/</link>
      <pubDate>Fri, 31 May 2019 00:00:00 +0100</pubDate>
      
      <guid>/resources/tex-rmd/homework/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Lecture Notes Template</title>
      <link>/resources/tex-rmd/lecturenotes/</link>
      <pubDate>Fri, 31 May 2019 00:00:00 +0100</pubDate>
      
      <guid>/resources/tex-rmd/lecturenotes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>/talk/example/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      
      <guid>/talk/example/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Academic&amp;rsquo;s &lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Further talk details can easily be added to this page using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/slides/example/</guid>
      <description>

&lt;h1 id=&#34;welcome-to-slides&#34;&gt;Welcome to Slides&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://sourcethemes.com/academic/&#34; target=&#34;_blank&#34;&gt;Academic&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;

&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code block:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;

&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;

&lt;p&gt;Block math:&lt;/p&gt;

&lt;p&gt;$$
f\left( x \right) = \;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;

&lt;p&gt;Make content appear incrementally&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
   One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   &lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   Three
&lt;/span&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;

&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;

&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;
&lt;/aside&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;


&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/img/boards.jpg&#34;
  &gt;


&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;

&lt;p&gt;Customize the slide style and background&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/img/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;

&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://discourse.gohugo.io&#34; target=&#34;_blank&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://sourcethemes.com/academic/docs/&#34; target=&#34;_blank&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>(To appear.) Synchronous Parallel Block Coordinate Descent Method for Nonsmooth Convex Function Minimization</title>
      <link>/publication/psum/</link>
      <pubDate>Fri, 01 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/psum/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Anomaly Detection</title>
      <link>/post/anomaly-detection/anomaly-detection/</link>
      <pubDate>Fri, 04 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/anomaly-detection/anomaly-detection/</guid>
      <description>


&lt;div id=&#34;point-anomaly-detection---grubbs-test&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Point Anomaly Detection - Grubbs’ test&lt;/h1&gt;
&lt;p&gt;Grubbs’ test&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; is commonly used technique to detect an outlier in &lt;strong&gt;univariate&lt;/strong&gt; problem, where &lt;strong&gt;normality&lt;/strong&gt; assumption is required. It can be formualted as either one-side testing problem or two-sided testing problem.&lt;/p&gt;
&lt;p&gt;The hypothesis test is defined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H_0: \text{There are no outlier in the data set} \quad H_1: \text{There is exactly one outlier in the data set}.\]&lt;/span&gt; For two-sided testing, it tries to determine whether the observation with the largest absolute deviation is an outlier, where the test statistic is defined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
G = \frac{\max_i |X_i - \bar X|}{s},
\]&lt;/span&gt; where the &lt;span class=&#34;math inline&#34;&gt;\(\bar X\)&lt;/span&gt; is the sample mean and &lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt; is the sample deviation.&lt;/p&gt;
&lt;p&gt;Let’s look at one simulated example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
simulated_data &amp;lt;- rnorm(100, 0, 1)
simulated_data_with_outliers &amp;lt;- c(simulated_data, c(3.5, -3.7))
# normality check
shapiro.test(simulated_data_with_outliers)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Shapiro-Wilk normality test
## 
## data:  simulated_data_with_outliers
## W = 0.9804, p-value = 0.1344&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Shapiro-Wilk normality test impiles the data is normally distributed. Now, let’s performe the grubbs’ test.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(outliers)
grubbs.test(simulated_data_with_outliers, two.sided = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Grubbs test for one outlier
## 
## data:  simulated_data_with_outliers
## G = 3.65380, U = 0.86651, p-value = 0.01626
## alternative hypothesis: lowest value -3.7 is an outlier&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The test result detecs the lowest value as an outlier.&lt;/p&gt;
&lt;p&gt;Let’s remove the -3.7 and performe the test again.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grubbs.test(head(simulated_data_with_outliers,101), two.sided = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Grubbs test for one outlier
## 
## data:  head(simulated_data_with_outliers, 101)
## G = 3.48190, U = 0.87755, p-value = 0.03378
## alternative hypothesis: highest value 3.5 is an outlier&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, let’s remove two outliers altogether.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grubbs.test(head(simulated_data_with_outliers,100), two.sided = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Grubbs test for one outlier
## 
## data:  head(simulated_data_with_outliers, 100)
## G = 2.62880, U = 0.92949, p-value = 0.7584
## alternative hypothesis: lowest value -2.30916887564081 is an outlier&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This impiles there are no outliers.&lt;/p&gt;
&lt;p&gt;Grubbs’ test is useful for identify the outliers of a small amount one at a time, but not suitable to detect a group of outliers.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;collective-anomaly-detection&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Collective Anomaly Detection&lt;/h1&gt;
&lt;div id=&#34;anomaly-in-timeseries---seasonal-hybrid-esd-algorithm&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Anomaly in timeseries - Seasonal Hybrid ESD algorithm&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#  devtools::install_github(&amp;quot;twitter/AnomalyDetection&amp;quot;)
library(AnomalyDetection)
river &amp;lt;- read.csv(&amp;quot;https://raw.githubusercontent.com/Rothdyt/personal-blog/master/static/files/post_data/river.csv&amp;quot;)
results &amp;lt;- AnomalyDetectionVec(river$nitrate, period=12, direction = &amp;#39;both&amp;#39;, plot = T)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results$plot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anomaly-detection/index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;distance-based-anomaly-detection&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Distance-based Anomaly Detection&lt;/h2&gt;
&lt;div id=&#34;global-anomaly---largest-distance&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Global Anomaly - Largest Distance&lt;/h3&gt;
&lt;p&gt;Intuitively, the larger distance the more likely the point would be an outlier.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(FNN)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;FNN&amp;#39; was built under R version 3.4.4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;furniture &amp;lt;- read.csv(&amp;quot;https://raw.githubusercontent.com/Rothdyt/personal-blog/master/static/files/post_data/furniture.csv&amp;quot;)
furniture_scaled &amp;lt;- data.frame(Height = scale(furniture$Height), Width = scale(furniture$Width))
furniture_knn &amp;lt;- get.knn(furniture_scaled, k = 5)
furniture_scaled$score_knn &amp;lt;- rowMeans(furniture_knn$nn.dist)
largest_idx &amp;lt;- which.max(furniture_scaled$score_knn)
plot(furniture_scaled$Height, furniture_scaled$Width, cex=sqrt(furniture_scaled$score_knn), pch=20)
points(furniture_scaled$Height[largest_idx], furniture_scaled$Width[largest_idx], col=&amp;quot;red&amp;quot;, pch=20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anomaly-detection/index_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;local-anomaly---lof&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Local Anomaly - LOF&lt;/h3&gt;
&lt;p&gt;kNN is useful for finding global anomalies, but is less able to surface local outliers.&lt;/p&gt;
&lt;p&gt;LOF is a ratio of densities:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LOF &amp;gt; 1 more likely to be anomalous LOF ≤ 1 less likely to be anomalous&lt;/li&gt;
&lt;li&gt;Large LOF values indicate more isolated points&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dbscan)
furniture_lof &amp;lt;- furniture[,2:3]
furniture_lof$score_lof &amp;lt;- lof(scale(furniture_lof), k=5)
largest_idx &amp;lt;- which.max(furniture_lof$score_lof)
plot(furniture_lof$Height, furniture_lof$Width, cex=sqrt(furniture_lof$score_lof), pch=20)
points(furniture_lof$Height[largest_idx], furniture_lof$Width[largest_idx], col=&amp;quot;red&amp;quot;, pch=20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anomaly-detection/index_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It’s clear that, lof successfuly detects the local outlier.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;isolation-forest&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Isolation Forest&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Isolation Forest is built on the basis of decision trees;&lt;/li&gt;
&lt;li&gt;To grow a decision tree, at each node, a feature and a corresponding cutoff value are randomly selected;&lt;/li&gt;
&lt;li&gt;Intuitively, outliers are less frequent than regular observations and are different from them in terms of values, so outliers should be identified closer to the root of the tree with fewer splits. We use isolation score to characterize this.&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;isolation-score&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Isolation Score&lt;/h2&gt;
&lt;p&gt;We need some quatity to define the isolation score&lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Path Length&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(h(x)\)&lt;/span&gt; of a point &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is measured by the number of edges &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; traverses an iTree from the root node until the traversal is terminated at an external node.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Normalizing constant&lt;/strong&gt; &lt;span class=&#34;math display&#34;&gt;\[c(n) = 2H(n − 1) − (2(n − 1)/n)\]&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is the number of samples to grow a tree and &lt;span class=&#34;math inline&#34;&gt;\(H(i)\)&lt;/span&gt; is the harmonic number and it can be estimated by &lt;span class=&#34;math inline&#34;&gt;\(ln(i) + 0.5772156649\)&lt;/span&gt; (Euler’s constant).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The isolation score &lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt; of an sample &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is defined as &lt;span class=&#34;math display&#34;&gt;\[s(x,n)= 2^{-\frac{E(h(x))}{c(n)}},\]&lt;/span&gt; where the &lt;span class=&#34;math inline&#34;&gt;\(E()\)&lt;/span&gt; is the expectation of &lt;span class=&#34;math inline&#34;&gt;\(h(x)\)&lt;/span&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Interpreting the isolation score:&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Scores between 0 and 1&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Scores near 1 indicate anomalies (small path length)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# devtools::install_github(&amp;quot;Zelazny7/isofor&amp;quot;)
library(isofor)
furniture &amp;lt;- read.csv(&amp;quot;https://raw.githubusercontent.com/Rothdyt/personal-blog/master/static/files/post_data/furniture.csv&amp;quot;)
furniture &amp;lt;- data.frame(Height = furniture$Height, Width = furniture$Width)
scores &amp;lt;- matrix(nrow=dim(furniture)[1])
for (ntree in c(100, 200, 500)){
  furniture_tree &amp;lt;- iForest(furniture, nt = ntree, phi=50)
  scores &amp;lt;- cbind(scores, predict(furniture_tree, furniture)) 
}
plot(scores[,3], scores[,4], xlab = &amp;quot;200 tress&amp;quot;, ylab=&amp;quot;500 tress&amp;quot;)
abline(a=0,b=1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anomaly-detection/index_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This graph is used to assess wheter the number of trees is enough for the isolation score to converge. From the graph above, we know that 200 tress are enough for us to identify the anomalies.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lattice)
furniture_forest &amp;lt;- iForest(furniture, nt = 200, phi=50)
h_seq &amp;lt;- seq(min(furniture$Height), max(furniture$Height), length.out = 20) 
w_seq &amp;lt;- seq(min(furniture$Width), max(furniture$Width), length.out = 20)
furniture_grid &amp;lt;- expand.grid(Width = w_seq, Height = h_seq)
furniture_grid$score &amp;lt;- predict(furniture_forest, furniture_grid)
contourplot(score ~ Height + Width, data = furniture_grid,region = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anomaly-detection/index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This contour graph used to identify the anomaly regions.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Grubbs%27_test_for_outliers&#34;&gt;https://en.wikipedia.org/wiki/Grubbs%27_test_for_outliers&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Zhihua Zhou et al. &lt;a href=&#34;https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf&#34; class=&#34;uri&#34;&gt;https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf&lt;/a&gt;&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Decision Tree: How to find the path from the root to the desired terminal node</title>
      <link>/post/decison-tree-path/decision-tree-how-to-find-the-path-from-the-root-to-the-desired-terminal-node/</link>
      <pubDate>Sat, 07 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/decison-tree-path/decision-tree-how-to-find-the-path-from-the-root-to-the-desired-terminal-node/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#prepare-a-fitted-random-forest&#34;&gt;Prepare a fitted random forest&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#find-the-path-to-desired-terminal-node&#34;&gt;Find the path to desired terminal node&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#collect-paths-in-the-random-forest&#34;&gt;Collect Paths in the random forest&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#summarize-the-decison-region&#34;&gt;Summarize the decison region&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;prepare-a-fitted-random-forest&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Prepare a fitted random forest&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;import random
import pandas as pd
from sklearn.ensemble.forest import RandomForestRegressor
from sklearn import tree
data = pd.DataFrame({&amp;quot;Y&amp;quot;:[1,5,3,4,3,4,2], &amp;quot;X_1&amp;quot;:[&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;, &amp;quot;blue&amp;quot;, &amp;quot;red&amp;quot;,&amp;quot;red&amp;quot;,&amp;quot;blue&amp;quot;, &amp;quot;red&amp;quot;],
                    &amp;quot;X_2&amp;quot;:[18.4, 7.5, 9.3, 3.7, 5.2, 3.2, 5.2]})
data = pd.get_dummies(data)
X = data.drop([&amp;quot;Y&amp;quot;], axis=1)
y = data[&amp;quot;Y&amp;quot;]
rf = RandomForestRegressor(n_estimators = 10, random_state = 1234)
rf.fit(X, y)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;output:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;RandomForestRegressor(bootstrap=True, criterion=&amp;#39;mse&amp;#39;, max_depth=None,
           max_features=&amp;#39;auto&amp;#39;, max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=1234, verbose=0, warm_start=False)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;find-the-path-to-desired-terminal-node&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Find the path to desired terminal node&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;import pydotplus
import re 
def return_node_path_to_max_prediction(onetree, verbose=True):
    &amp;quot;&amp;quot;&amp;quot;
    @input: a tree from the sklearn randomforest
    @output: the node path to maxmium terminal node
        [[split_node_1], [split_node_2], ...]
        [splite_node_1] = [var_index, cutoff, direction]
    &amp;quot;&amp;quot;&amp;quot;
    if verbose:
        print(&amp;quot;Generating Tree Graph, it may take a while...&amp;quot;)
    dot_data = tree.export_graphviz(onetree,
                                    out_file = None,
                                    filled   = True,
                                    rounded  = True,
                                    special_characters = True)  
    graph = pydotplus.graph_from_dot_data(dot_data)
    graph_ = {}
    for edge in graph.get_edge_list():
        graph_[edge.get_source()] = edge.get_destination()
    # find all terminal node
    terminal_node = {}
    non_decimal = re.compile(r&amp;#39;[^\d.]+&amp;#39;)
    for node in graph.get_node_list():
        if node.get_name() not in graph_:
            if node.get_name() not in [&amp;quot;node&amp;quot;, &amp;quot;edge&amp;quot;]:
                value = node.get_label()
                value = re.sub(r&amp;#39;.*v&amp;#39;, &amp;#39;v&amp;#39;, value)
                terminal_node[node.get_name()] = float(non_decimal.sub(&amp;#39;&amp;#39;, value))
    # find the path down to the terminal with maximum predition value
    flag = True
    destination = max(terminal_node, key=terminal_node.get)
    edge_list = graph.get_edge_list()
    node_list = graph.get_node_list()
    split_node = []
    while flag:
        myedge = [edge for edge in edge_list  if edge.get_destination() == destination][0]
        if int(myedge.get_destination()) - int(myedge.get_source()) &amp;gt; 1:
            direction = &amp;quot;Right&amp;quot;
        else:
            direction = &amp;quot;Left&amp;quot;
        
        mynode = [node for node in node_list if node.get_name() == myedge.get_source()][0]
        var_val = re.findall(r&amp;quot;[-+]?\d*\.\d+|\d+&amp;quot;, mynode.get_label())[:2]
        # record the growing path:
        #  var_val[0]: Index of variable participating in splitting
        #  var_val[1]: cutoff point of the splitting
        #  direction: If Right, means greater than var_val[1]; 
        #             If Left, means no greater than var_val[1]
        split_node.append([int(var_val[0]),float(var_val[1]),direction])
        if verbose:
            print(myedge.get_destination() + &amp;quot;&amp;lt;-&amp;quot; + myedge.get_source() + 
                  &amp;quot;: Split at Variable X&amp;quot; + var_val[0] + &amp;quot;; The cutoff is &amp;quot; + var_val[1] + 
                 &amp;quot;; Turn &amp;quot; + direction)
        destination = myedge.get_source()
        if destination == &amp;quot;0&amp;quot;:
            flag = False
        
    return [*reversed(split_node)]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Test:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;return_node_path_to_max_prediction(rf[1], verbose=True)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Outputs:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Generating Tree Graph, it may take a while...
3&amp;lt;-1: Split at Variable X0; The cutoff is 5.6; Turn Right
1&amp;lt;-0: Split at Variable X0; The cutoff is 12.95; Turn Left&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the output above, we know the path from the root to the desired terminal node is :&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Root[X0(&amp;lt;= 12.95)] -&amp;gt; X0 (&amp;gt;=5.6) -&amp;gt; Terminal Node&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;collect-paths-in-the-random-forest&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Collect Paths in the random forest&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;def collect_path(rf, verbose=True):
    n_tree = len(rf)
    result = []
    for i in range(n_tree):
        if verbose:
            print(&amp;quot;Construct the %s tree graph out of %s trees&amp;quot; %(i+1, n_tree))
        result.append(return_node_path_to_max_prediction(rf.estimators_[i], verbose=False))
    return result&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Test:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;result = collect_path(rf)
print(result)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Outputs:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Construct the 1 tree graph out of 10 trees
Construct the 2 tree graph out of 10 trees
Construct the 3 tree graph out of 10 trees
Construct the 4 tree graph out of 10 trees
Construct the 5 tree graph out of 10 trees
Construct the 6 tree graph out of 10 trees
Construct the 7 tree graph out of 10 trees
Construct the 8 tree graph out of 10 trees
Construct the 9 tree graph out of 10 trees
Construct the 10 tree graph out of 10 trees
[[[0, 4.2, &amp;#39;Left&amp;#39;]], [[0, 12.95, &amp;#39;Left&amp;#39;], [0, 5.6, &amp;#39;Right&amp;#39;]], [[1, 0.5, &amp;#39;Right&amp;#39;], [0, 8.4, &amp;#39;Left&amp;#39;]], [[0, 13.85, &amp;#39;Left&amp;#39;], [0, 8.4, &amp;#39;Left&amp;#39;], [1, 0.5, &amp;#39;Right&amp;#39;]], [[0, 8.4, &amp;#39;Left&amp;#39;], [0, 6.35, &amp;#39;Right&amp;#39;]], [[0, 12.95, &amp;#39;Left&amp;#39;], [0, 5.6, &amp;#39;Right&amp;#39;]], [[2, 0.5, &amp;#39;Left&amp;#39;], [0, 5.35, &amp;#39;Right&amp;#39;]], [[1, 0.5, &amp;#39;Right&amp;#39;], [0, 5.35, &amp;#39;Right&amp;#39;]], [[0, 13.85, &amp;#39;Left&amp;#39;], [1, 0.5, &amp;#39;Right&amp;#39;], [0, 8.4, &amp;#39;Left&amp;#39;], [0, 5.35, &amp;#39;Right&amp;#39;]], [[0, 13.85, &amp;#39;Left&amp;#39;], [0, 6.35, &amp;#39;Right&amp;#39;], [0, 8.4, &amp;#39;Left&amp;#39;]]]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;summarize-the-decison-region&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Summarize the decison region&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;def summarize_region(result, features):
    decision_region = {k: [[] for _ in range(2)] for k in features}
    for i in range(len(result)):
        for j in range(len(result[i])):
            if result[i][j][2] == &amp;quot;Left&amp;quot;:
                 decision_region[features[result[i][j][0]]][0].append(result[i][j][1])
            else:
                decision_region[features[result[i][j][0]]][1].append(result[i][j][1]) 
    
    decision_region_ = {}
    for k in features:
        try:
            upper_bound = min(decision_region[k][0])
        except ValueError:
            upper_bound = &amp;quot;Unknown&amp;quot;
        try:
            lower_bound = max(decision_region[k][1])
        except ValueError:
            lower_bound = &amp;quot;Unknown&amp;quot;
        decision_region_[k] = [lower_bound, upper_bound]
        
    value_to_remove = [&amp;#39;Unknown&amp;#39;, &amp;#39;Unknown&amp;#39;]
    decision_region_ = {key: value for key, value in decision_region_.items() if value != value_to_remove}
    value_to_remove = [0.5, 0.5]
    decision_region_ = {key: value for key, value in decision_region_.items() if value != value_to_remove}
    
    return (decision_region_)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Test:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;features = X.columns
summarize_region(result, features)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Outputs:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{&amp;#39;X_1_blue&amp;#39;: [0.5, &amp;#39;Unknown&amp;#39;], &amp;#39;X_1_red&amp;#39;: [&amp;#39;Unknown&amp;#39;, 0.5], &amp;#39;X_2&amp;#39;: [6.35, 4.2]}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the output above, we know that the decision region:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{blue} * [6.35, 4.2]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But it seems that the region &lt;strong&gt;[6.35, 4.2]&lt;/strong&gt; is not reasonable due to the poorly generated data. But it may happens in some situations, which may require us to come up with new ways to ensemble these terminal nodes.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Real Estate Market Data Analysis</title>
      <link>/project/boston-housing/</link>
      <pubDate>Sun, 10 Dec 2017 00:00:00 +0800</pubDate>
      
      <guid>/project/boston-housing/</guid>
      <description>&lt;p&gt;In this project, we&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Develope data products to help Airbnb hosts to determine listing prices using Sparse Regression and RandomForest&lt;/li&gt;
&lt;li&gt;Researched how amenities and geolocation in uence listing prices&lt;/li&gt;
&lt;li&gt;Designed a User Interface for customers to gain insight into Airbnb rental markets in Boston&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;a href=&#34;https://mediaspace.illinois.edu/media/t/1_3yvpnzqn&#34; target=&#34;_blank&#34;&gt;Video Presentation&lt;/a&gt; and &lt;a href=&#34;https://yutongdai.shinyapps.io/shinyapp/&#34; target=&#34;_blank&#34;&gt;Rshiny App Demo&lt;/a&gt; are also provided.&lt;/p&gt;

&lt;iframe id=&#34;kmsembed-1_3yvpnzqn&#34; width=&#34;640&#34; height=&#34;394&#34; src=&#34;https://mediaspace.illinois.edu/embed/secure/iframe/entryId/1_3yvpnzqn/uiConfId/26883701&#34; class=&#34;kmsembed&#34; allowfullscreen webkitallowfullscreen mozAllowFullScreen allow=&#34;autoplay *; fullscreen *; encrypted-media *&#34; frameborder=&#34;0&#34; title=&#34;Kaltura Player&#34;&gt;&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Show and Tell: A Neural Image Caption Generator</title>
      <link>/project/show-and-tell/</link>
      <pubDate>Sun, 10 Dec 2017 00:00:00 +0800</pubDate>
      
      <guid>/project/show-and-tell/</guid>
      <description>&lt;p&gt;This is the deep learning course final project trying to reporduce the results reported in the paper, &lt;a href=&#34;https://arxiv.org/pdf/1411.4555.pdf&#34; target=&#34;_blank&#34;&gt;Show and Tell: A Neural Image Caption Generator&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The model is trained on the &lt;a href=&#34;http://cocodataset.org/#home&#34; target=&#34;_blank&#34;&gt;MS coco2014 dataset&lt;/a&gt;. Our final result looks like&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./caption-demo.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;For code, UI, and report  please click &lt;a href=&#34;https://github.com/Rothdyt/Projects/tree/master/Show-and-tell&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Variational Gaussian Mixtures</title>
      <link>/project/variational-inference/</link>
      <pubDate>Sun, 10 Dec 2017 00:00:00 +0800</pubDate>
      
      <guid>/project/variational-inference/</guid>
      <description>&lt;p&gt;This is the statistical computing course final project, trying to understand, reporduce and extend some results reported in the paper, &lt;a href=&#34;https://arxiv.org/pdf/1601.00670.pdf&#34; target=&#34;_blank&#34;&gt;Variational Inference: A Review for Statisticians&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Three datasets are used here, simulated data, &lt;a href=&#34;https://www.stat.cmu.edu/~larry/all-of-statistics/=data/faithful.dat&#34; target=&#34;_blank&#34;&gt;old faithful&lt;/a&gt; and &lt;a href=&#34;https://www.imageclef.org&#34; target=&#34;_blank&#34;&gt;imageCLEF&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Our final result looks like&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Simulated data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;./simulation.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;old faithful
&lt;img src=&#34;./old_faithful.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;imageclef&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;./imageclef.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;For code and report please click &lt;a href=&#34;https://github.com/Rothdyt/Projects/tree/master/Show-and-tell&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Convergence Analysis for Block Coordinate Decent Algorithm and Powell&#39;s Examples</title>
      <link>/post/powell/convergence-analysis-for-block-coordinate-descent-algorithm-and-powells-examples/</link>
      <pubDate>Thu, 17 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/powell/convergence-analysis-for-block-coordinate-descent-algorithm-and-powells-examples/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#problem-description&#34;&gt;Problem description&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#notations&#34;&gt;Notations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#assumption&#34;&gt;Assumption&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#algorithm&#34;&gt;Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#convergence-analysis&#34;&gt;Convergence Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#powells-example&#34;&gt;Powell’s example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#r-codes-for-numerical-experiments&#34;&gt;R codes for numerical experiments&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;We mainly focus on the convergence of Block coordinate decent with exact minimization, whose block update strategy employs Gauss-Seidel manner. And then use Powell’s example to see what will happen if some conditions are not met.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Reference: 1. Dimitri .P Bertsekas, Nonlinear Programming 2ed 2. Powell ,1973, ON SEARCH DIRECTIONS FOR MINIMIZATION ALGORITHMS&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;problem-description&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Problem description&lt;/h1&gt;
&lt;div id=&#34;notations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Notations&lt;/h2&gt;
&lt;p&gt;We want to solve the problem:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mathop{min}_{x\in X}\quad f(x)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where X is a Cartesian product of closed convex sets $X_1,…,X_m:X=_{i=1}^n X_i $&lt;/p&gt;
&lt;p&gt;We assume that &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt; is a closed convex subset of &lt;span class=&#34;math inline&#34;&gt;\(R^{n_i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n=\sum_{i=1}^m n_i\)&lt;/span&gt;. The vector is partitioned into &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; block(s) such that &lt;span class=&#34;math inline&#34;&gt;\(x_i \in X^{n_i}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We denote &lt;span class=&#34;math inline&#34;&gt;\(\nabla_i f\)&lt;/span&gt; as the gradient of &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; with respect to component &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumption&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumption&lt;/h2&gt;
&lt;p&gt;We shall assume that for every &lt;span class=&#34;math inline&#34;&gt;\(x\in X\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(i=1,2,...m\)&lt;/span&gt; the optimization problem&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mathop{min}_{\xi\in X_i}\quad f(x_1,...,x_{i-1},\xi,x_{i+1,....,x_m})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;has &lt;strong&gt;at least one solution&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;algorithm&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Algorithm&lt;/h2&gt;
&lt;p&gt;The Gauss-Seidel method, generates the next iterate &lt;span class=&#34;math inline&#34;&gt;\(x^{k+1}=(x^{k+1}_1,...,x^{k+1}_m)\)&lt;/span&gt;, given the current the iterate &lt;span class=&#34;math inline&#34;&gt;\(x^{k}=(x^{k}_1,...,x^{k}_m)\)&lt;/span&gt;, according to the iteration&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x^{k+1}_i=\mathop{argmin}_{\xi\in X_i}\quad f(x_1^{k+1},...,x^{k+1}_{i-1},\xi,x^k_{i+1},...,x_m^k)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;convergence-analysis&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Convergence Analysis&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;Theorem&lt;/code&gt; Suppose that &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; is &lt;strong&gt;continuously differentiable&lt;/strong&gt; over the set &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; defined as above. Furthermore, suppose that for each &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x\in X\)&lt;/span&gt;,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x_1,...,x_{i-1},\xi,x_{i+1,....,x_m})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;viewed as a function of &lt;span class=&#34;math inline&#34;&gt;\(\xi\)&lt;/span&gt;, attains a unique minimum &lt;span class=&#34;math inline&#34;&gt;\(\bar x_i\)&lt;/span&gt; over &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt; and is monotonically non-increasing in the interval from &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(\bar \xi\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(\{x_k\}\)&lt;/span&gt; be the sequence generated by the block coordinate method with Gauss-Seidel manner. Then, every limit point of &lt;span class=&#34;math inline&#34;&gt;\(\{x_k\}\)&lt;/span&gt; is a stationary point.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;PROOF&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Let&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[z_i^k=(x_1^{k+1},...,x_i^{k+1},x_{i+1}^k,...,x_m^k)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;By the nature of this algorithm, for all &lt;span class=&#34;math inline&#34;&gt;\(k\geq 0\)&lt;/span&gt;, we have following inequality&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x^k)\geq f(z_1^k)\geq f(z_2^k)\geq ...\geq f(z_{m-1}^k)\geq f(x^{k+1}) \quad (*)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Since &lt;span class=&#34;math inline&#34;&gt;\(\{x_k\}in X\)&lt;/span&gt;, we can assume &lt;span class=&#34;math inline&#34;&gt;\(\{x^{k_j}\}\)&lt;/span&gt; is the subsequence that converges to &lt;span class=&#34;math inline&#34;&gt;\(\bar x=(\bar x_1,..,\bar x_m)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Now we want prove that &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt; is the stationary point of &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;From (*), we know that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(z_1^{k_j})\leq f(x_1,x_2^{k_j},..., x_m^{k_j})\qquad \forall x_1\in X_1\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(j\rightarrow +\infty\)&lt;/span&gt;, we derive&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(\bar x)\leq f(x_1,\bar x_2,..., \bar x_m)\overset \Delta = h(x_1)\qquad \forall x_1\in X_1\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;which implies that &lt;span class=&#34;math inline&#34;&gt;\(\bar x_i\)&lt;/span&gt; is the minima of &lt;span class=&#34;math inline&#34;&gt;\(h(x_1)\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(X_1\)&lt;/span&gt;. Using the optimality over a convex set, we conclude that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[h&amp;#39;(\bar x_1)(\bar x_1 -x_1)\geq 0 \Leftrightarrow (x_1-\bar x_1)^T\nabla_1f(\bar x_1)\geq 0\qquad x_1\in X_1\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;At this stage, if we can prove that &lt;span class=&#34;math inline&#34;&gt;\(\{z_1^{k_j}\}\)&lt;/span&gt; converges to &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt;, we can show that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ (x_2-\bar x_2)^T\nabla_2 f(\bar x_2)\geq 0\qquad x_2\in X_2\]&lt;/span&gt;, since&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(z_1^{k_j})=f(x_1^{k_j+1},x_2^{k_j},x_3^{k_j},...,x_m^{k_j})\leq f(x_1^{k_j+1},x_2,x_3^{k_j},...,x_m^{k_j})\qquad x_2\in X_2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(j\rightarrow +\infty\)&lt;/span&gt;, we derive&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(\bar x)\leq f(\bar x_1,\bar x_2,\bar x_3,..., \bar x_m)\qquad \forall x_2\in X_2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[(x_2-\bar x_2)^T\nabla_2f(\bar x_2)\geq 0\qquad x_2\in X_2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;(Note: Although &lt;span class=&#34;math inline&#34;&gt;\(x_1^{k_j+1}\)&lt;/span&gt; may not in the sequence &lt;span class=&#34;math inline&#34;&gt;\(\{x_1^{k_t}\}_{t\geq 1}\)&lt;/span&gt; ,which convergences to &lt;span class=&#34;math inline&#34;&gt;\(\bar x_1\)&lt;/span&gt;, but &lt;span class=&#34;math inline&#34;&gt;\(\{z_1^{k_j}\}\)&lt;/span&gt; converges to &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt;, so its component &lt;span class=&#34;math inline&#34;&gt;\(x_1^{k_j+1}\)&lt;/span&gt; converges to &lt;span class=&#34;math inline&#34;&gt;\(\bar x_1\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;Furthermore, if we prove that for &lt;span class=&#34;math inline&#34;&gt;\(i=1,2,...,m-1\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(\{z_i^{k_j}\}\)&lt;/span&gt; convergences to &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt;, then we have&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[(x_i-\bar x_i)^T\nabla_i\;f(\bar x_i)\geq 0\qquad x_i\in X_i\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;And thus &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt; is a stationary point, since &lt;span class=&#34;math inline&#34;&gt;\((x-\bar x)^T\nabla f(\bar x)\geq 0\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;By far, it remains to prove that &lt;span class=&#34;math inline&#34;&gt;\(\{z_i^{k_j}\}\quad,\forall i\)&lt;/span&gt; convergence to &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt;. First,we try to prove that &lt;span class=&#34;math inline&#34;&gt;\(\{z_1^{k_1}\}\)&lt;/span&gt; convergence to &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Assume the contrary that &lt;span class=&#34;math inline&#34;&gt;\(r^{k_j}=\vert \vert z_1^{k_j}-x^{k_j}\vert \vert\)&lt;/span&gt; doesn’t convergence to 0. Let &lt;span class=&#34;math inline&#34;&gt;\(s_1^{k_j}=(z_1^{k_j}-x^{k_j})/r^{k_j}\)&lt;/span&gt;. Thus, &lt;span class=&#34;math inline&#34;&gt;\(z_1^{k_j}=x^{k_j}+r^{k_j}s_1^{k_j}\)&lt;/span&gt; , &lt;span class=&#34;math inline&#34;&gt;\(\vert \vert r_{k_j}\vert \vert =1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(s_1^{k_j}\)&lt;/span&gt; differs from 0 only along the first block-component. Since &lt;span class=&#34;math inline&#34;&gt;\(\{s_1^{k_j}\}\)&lt;/span&gt; belong to a compact set and therefore without loss of generality, we assume &lt;span class=&#34;math inline&#34;&gt;\(s_1^{k_j}\)&lt;/span&gt; convergences to &lt;span class=&#34;math inline&#34;&gt;\(\bar s_1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Since &lt;span class=&#34;math inline&#34;&gt;\(r^{k_j}&amp;gt;0\)&lt;/span&gt;,we can find a &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\in (0,1)\)&lt;/span&gt;, such that &lt;span class=&#34;math inline&#34;&gt;\(x^{k_j}+\epsilon s_1^{k_j}\)&lt;/span&gt; lies on the segment joining &lt;span class=&#34;math inline&#34;&gt;\(x^{k_j}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x^{k_j}+s_1^{k_j}=z_1^{k_j}\)&lt;/span&gt;. Using the non-increasing property of &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;,we derive,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(z_1^{k_j})\leq f(x^{k_j}+\epsilon s_1^{k_j}) \leq f(x^{k_j})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Again, using (*), we conclude&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x^{k_{j+1}})\leq f(z_1^{k_j})\leq f(x^{k_j}+\epsilon s_1^{k_j}) \leq f(x^{k_j})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(j\rightarrow +\infty\)&lt;/span&gt;, we derive &lt;span class=&#34;math inline&#34;&gt;\(f(\bar x)=f(\bar x+\epsilon \bar s_1)\)&lt;/span&gt;, which contradicts the hypothesis that &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; is uniquely minimized when viewed as a function of the first block component. This contradiction establishes that &lt;span class=&#34;math inline&#34;&gt;\(\{z_1^{k_1}\}\)&lt;/span&gt; convergence to &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Similarly, let &lt;span class=&#34;math inline&#34;&gt;\(r_t^{k_j}=\vert \vert z_t^{k_j}-z_{t-1}^{k_j}\vert \vert\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(t=2,3,...,m-1\)&lt;/span&gt; and using the same technique shown above, we finally prove that &lt;span class=&#34;math inline&#34;&gt;\(\{z_i^{k_j}\},\quad \forall i\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;powells-example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Powell’s example&lt;/h1&gt;
&lt;p&gt;In &lt;em&gt;ON SEARCH DIRECTIONS FOR MINIMIZATION ALGORITHMS&lt;/em&gt;, Power actually gives three examples that sequences generated by the algorithm discussed above do not convergence to stationary points once some hypothesis are not met.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The first example is straightforward, However, the remarkable properties of this example can be destroyed by making a small perturbation to the starting vector &lt;span class=&#34;math inline&#34;&gt;\(x^0\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The second example is not sensitive to either small changes in the initial data or to small errors introduced during the iterative process, for example computer rounding errors.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The third example suggests that a function that is infinitely differentiable that also causes an endless loop in the iterative minimization method.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We here only presents the first example. Consider the following function&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x,y,z)=-(xy+yz+zx)+(x-1)_+^2+(-x-1)_+^2+(y-1)_+^2+(-y-1)_+^2+(z-1)_+^2+(-z-1)_+^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[(x-c)_+^2=\begin{cases}0,x-c&amp;lt; 0\\ (x-c)^2,x-c\geq 0\end{cases}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Given the starting point &lt;span class=&#34;math inline&#34;&gt;\(x_0=(-1-e,1+\frac{1}{2}e,-1-\frac{1}{4}e)\)&lt;/span&gt; and use block coordinate decent algorithm,and we update the variable in a manner of &lt;span class=&#34;math inline&#34;&gt;\(x\rightarrow y\rightarrow z\rightarrow x ...\)&lt;/span&gt; with&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x_{k+1}^{**}\leftarrow \text{sign}(y_k+z_k)[1+\frac{1}{2}\vert y_k+z_k\vert ]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{k+1}^{**}\leftarrow \text{sign}(x_{k+1}+z_k)[1+\frac{1}{2}\vert x_{k+1}+z_k\vert ]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[z_{k+1}^{**}\leftarrow \text{sign}(x_{k+1}+y_{k+1})[1+\frac{1}{2}\vert x_{k+1}+y_{k+1}\vert ]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We here present the first six steps of this case&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;cycle/totall iteration&lt;/th&gt;
&lt;th&gt;x&lt;/th&gt;
&lt;th&gt;y&lt;/th&gt;
&lt;th&gt;z&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{8}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+$e $&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{4}e\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;1/2&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{8}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{16}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{4}e\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;1/3&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{8}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{16}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{32}e\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;2/4&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{64}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{16}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{32}e\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;2/5&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{64}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{128}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{32}e\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;2/6&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{64}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{128}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{256}e\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;3/7&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{512}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{128}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{256}e\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This result implies that the sequence obtained by this algorithm can not converge to one single point since &lt;span class=&#34;math inline&#34;&gt;\(x-coordinate\)&lt;/span&gt; change its sign as the even cycle and odd cycle alternate. Situations are similar for &lt;span class=&#34;math inline&#34;&gt;\(y-coordinate\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(z-coordinate\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;But &lt;span class=&#34;math inline&#34;&gt;\(\{x_k\}\)&lt;/span&gt; has six sub-sequences which convergence to (1,1,-1), (1,-1,-1), (1,-1,1), (-1,-1,1),(-1,-1,1),(-1,1,1),(-1,1,-1) respectively.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;14748787199151.jpg&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;A hint to derive the update formula:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x\leftarrow \text{sign}(y+z)[1+\frac{1}{2}(y+z)]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Indeed, derivates of &lt;span class=&#34;math inline&#34;&gt;\((x-1)_+^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\((-x-1)_+^2\)&lt;/span&gt; are as follows respecively&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{d(x-1)_+^2}{dx}=\begin{cases}2(x-1),x\geq 1\\0,x&amp;lt;1\end{cases}\quad 
    \frac{d(-x-1)_+^2}{dx}=\begin{cases}2(-x-1),x\leq -1\\0,x&amp;gt;-1\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;So for the univariate optimization problem, setting the derivate of &lt;span class=&#34;math inline&#34;&gt;\(g(x)=f(x,y,z)\)&lt;/span&gt; to zero, we conclude&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{\partial f(x,y,x)}{\partial x}=0\Rightarrow 
\begin{cases}x\geq 1: x=1+\frac{1}{2}(y+z)\\-1&amp;lt; x&amp;lt;1: -(y+z)=0\\x\leq -1:x=-1+\frac{1}{2}(y+z) \end{cases}\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The gradient of &lt;span class=&#34;math inline&#34;&gt;\(f(x,y,z)\)&lt;/span&gt; on this cyclic path, is &lt;span class=&#34;math inline&#34;&gt;\(\nabla f(x,y,z)=(-y-z,-x-z,-x-y)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\vert \vert \nabla f(x,y,z)\vert \vert _1=2\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;This example is unstable with respect to small perturbations. Small changes in the starting point &lt;span class=&#34;math inline&#34;&gt;\(x_0=(-1-e,1+\frac{1}{2}e,-1-\frac{1}{4}e)\)&lt;/span&gt; or smal errors in the numbers that are computed during the calculation will destroy the cyclic behavior.&lt;/p&gt;
&lt;p&gt;It’s s clear the choice of perturbations &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt; plays a key role. Say, &lt;span class=&#34;math inline&#34;&gt;\(x_0=(-1-e_1,1+e_2,-1-e_3)\)&lt;/span&gt; and we have &lt;span class=&#34;math inline&#34;&gt;\(e_k=\frac{1}{2}(e_{k-2}- e_{k-1})\)&lt;/span&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;cycle/totall iteration&lt;/th&gt;
&lt;th&gt;x&lt;/th&gt;
&lt;th&gt;y&lt;/th&gt;
&lt;th&gt;z&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(e_4\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(e_2\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(e_3\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;1/2&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(e_4\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(e_5\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(e_3\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;1/3&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(e_4\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(e_5\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(e_6\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;2/4&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(e_7\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(e_5\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(e_6\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;2/5&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(e_7\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(e_8\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(e_6\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;2/6&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(e_7\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(e_8\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(e_9\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;To preserve the cyclic behavior , we have to make sure that &lt;span class=&#34;math inline&#34;&gt;\(e_{k-2}&amp;gt;e_{k-1}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;And in practice, when we do some numerical tests, we shall find that, this theoretically-existed endless loop actual breaks down due to the rounding errors. A brief illustration is given below. In this experiment, loop ends at the 52 steps.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;Snip20161117_13.png&#34; alt=&#34;Snip20161117_13&#34; /&gt;&lt;br /&gt;
&lt;img src=&#34;Snip20161117_14.png&#34; alt=&#34;Snip20161117_14&#34; /&gt; &lt;img src=&#34;Snip20161117_15.png&#34; alt=&#34;Snip20161117_15&#34; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;As&lt;br /&gt;
&lt;span class=&#34;math display&#34;&gt;\[\frac{\partial f(x,y,x)}{\partial x}=0\Rightarrow 
\begin{cases}x\geq 1: x=1+\frac{1}{2}(y+z)\\-1&amp;lt; x&amp;lt;1: -(y+z)=0\\x\leq -1:x=-1+\frac{1}{2}(y+z) \end{cases}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;suggests that, when &lt;span class=&#34;math inline&#34;&gt;\(-1&amp;lt;x&amp;lt;1\)&lt;/span&gt;, the choice of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is arbitrary and we set &lt;span class=&#34;math inline&#34;&gt;\(x^*=0\)&lt;/span&gt; in the case above. So the uniqueness requirement is violated. It turns out that the six vertices are even not the stationary points.&lt;/p&gt;
&lt;p&gt;For example, at point &lt;span class=&#34;math inline&#34;&gt;\(\bar x=(1,1,-1)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\nabla f(\bar x)=(0,0,-2)\)&lt;/span&gt; and for any ponit &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; in the unit cubic &lt;span class=&#34;math inline&#34;&gt;\((x-\bar x)^T\nabla f(\bar x)\leq 0\)&lt;/span&gt;. Say, &lt;span class=&#34;math inline&#34;&gt;\(x=(0.9,0.9,-0.9)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\((x-\bar x)^T\nabla f(\bar x)=-0.2&amp;lt;0\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Actually, as in the proof of &lt;code&gt;Theorem&lt;/code&gt;, we prove that &lt;span class=&#34;math inline&#34;&gt;\(\{z_1^{k_j}\}\)&lt;/span&gt; converges to &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt; is the limit point of &lt;span class=&#34;math inline&#34;&gt;\(\{x^{k_j}\}\)&lt;/span&gt;. But in this example, the limit point of &lt;span class=&#34;math inline&#34;&gt;\(\{z_1^{k_j}\}\)&lt;/span&gt; is (1,1,-1) while the limit point of &lt;span class=&#34;math inline&#34;&gt;\(\{x^{k_j}\}\)&lt;/span&gt; is either (-1,1,-1) or (1,-1,1). So the requirement of uniqueness is not met.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;r-codes-for-numerical-experiments&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R codes for numerical experiments&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;####################
### Function for test ###
####################

PowellE1&amp;lt;-function(xstart,cycles,fig=T){
  #######function part ##############
  UpdateCycle&amp;lt;-function(x){
    Sign&amp;lt;-function(x){
      if (x&amp;gt;0){
        return(1)
      }else{
        if (x&amp;lt;0){
          return(-1)
        }else{
          return(0)
        }
      }
    }
    x.new&amp;lt;-c()
    x.new[1]&amp;lt;-Sign(x[2]+x[3])*(1+0.5*abs(x[2]+x[3]))
    x.new[2]&amp;lt;-Sign(x.new[1]+x[3])*(1+0.5*abs(x.new[1]+x[3]))
    x.new[3]&amp;lt;-Sign(x.new[1]+x.new[2])*(1+0.5*abs(x.new[1]+x.new[2]))
    cycle&amp;lt;-matrix(c(x.new[1],x[2],x[3],x.new[1],x.new[2],x[3],x.new[1],x.new[2],x.new[3]),
                  ncol=3,byrow=T)
    return(cycle)
  }
  
  fpowell&amp;lt;-function(x){
    
    PostivePart&amp;lt;-function(x){
      ifelse(x&amp;gt;=0,x,0)
    }
    
    fval&amp;lt;-(-(x[1]*x[2]+x[2]*x[3]+x[1]*x[3]))+
      PostivePart(x[1]-1)^2+PostivePart(-x[1]-1)^2+
      PostivePart(x[2]-1)^2+PostivePart(-x[2]-1)^2+
      PostivePart(x[3]-1)^2+PostivePart(-x[3]-1)^2
    return(fval)
  }
  ############ operation part ################
  x.store&amp;lt;-matrix(ncol=3,nrow=cycles*3+1)
  x.store[1,]&amp;lt;-xstart
  for (i in seq_len(cycles)){
    x.store[(3*i-1):(3*i+1),]&amp;lt;-UpdateCycle(x.store[3*i-2,])
  }
  x.store&amp;lt;-x.store[-1,]
  fval&amp;lt;-rep(0,cycles*3)
  
  for(i in seq_len(cycles*3)){
    fval[i]&amp;lt;-fpowell(x.store[i,])
  }
  fval&amp;lt;-as.matrix(fval)
  
  if (fig==T){
    plot(fval,ylim=c(min(fval)-1,max(fval)+1),type=&amp;quot;l&amp;quot;,xlab=&amp;quot;Iterations&amp;quot;,ylab = &amp;quot;F value&amp;quot;)
  }
  r&amp;lt;-list()
  r$x.iterate&amp;lt;-x.store
  r$fval&amp;lt;-fval
  return(r)
}


##################
#### Test 1 ########
##################


perturb&amp;lt;-0.5
xstart&amp;lt;-c(-1-perturb,1+0.5*perturb,-1-0.25*perturb)
cycles&amp;lt;-20

r&amp;lt;-PowellE1(xstart,cycles,fig=T)

##################
#### Test 2 ########
##################

perturb&amp;lt;-0.5
xstart&amp;lt;-c(-1-perturb,1+0.5*perturb,-1-0.25*perturb)
cycles&amp;lt;-20

r&amp;lt;-PowellE1(xstart,cycles,fig=T)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/powell/index_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;##################
#### Test 3 ########
##################

xstart&amp;lt;-c(3,2,1)
cycles&amp;lt;-100

r&amp;lt;-PowellE1(xstart,cycles,fig=T)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/powell/index_files/figure-html/unnamed-chunk-1-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
