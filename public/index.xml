<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Yutong Dai / 戴宇童 on Yutong Dai / 戴宇童</title>
    <link>/</link>
    <description>Recent content in Yutong Dai / 戴宇童 on Yutong Dai / 戴宇童</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 -0400</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Decision Tree: How to find the path from the root to the desired terminal node</title>
      <link>/post/en/decision-tree-how-to-find-the-path-from-the-root-to-the-desired-terminal-node/</link>
      <pubDate>Sat, 07 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/en/decision-tree-how-to-find-the-path-from-the-root-to-the-desired-terminal-node/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#prepare-a-fitted-random-forest&#34;&gt;Prepare a fitted random forest&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#find-the-path-to-desired-terminal-node&#34;&gt;Find the path to desired terminal node&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#collect-paths-in-the-random-forest&#34;&gt;Collect Paths in the random forest&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#summarize-the-decison-region&#34;&gt;Summarize the decison region&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;prepare-a-fitted-random-forest&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Prepare a fitted random forest&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;import random
import pandas as pd
from sklearn.ensemble.forest import RandomForestRegressor
from sklearn import tree
data = pd.DataFrame({&amp;quot;Y&amp;quot;:[1,5,3,4,3,4,2], &amp;quot;X_1&amp;quot;:[&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;, &amp;quot;blue&amp;quot;, &amp;quot;red&amp;quot;,&amp;quot;red&amp;quot;,&amp;quot;blue&amp;quot;, &amp;quot;red&amp;quot;],
                    &amp;quot;X_2&amp;quot;:[18.4, 7.5, 9.3, 3.7, 5.2, 3.2, 5.2]})
data = pd.get_dummies(data)
X = data.drop([&amp;quot;Y&amp;quot;], axis=1)
y = data[&amp;quot;Y&amp;quot;]
rf = RandomForestRegressor(n_estimators = 10, random_state = 1234)
rf.fit(X, y)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;output:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;RandomForestRegressor(bootstrap=True, criterion=&amp;#39;mse&amp;#39;, max_depth=None,
           max_features=&amp;#39;auto&amp;#39;, max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=1234, verbose=0, warm_start=False)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;find-the-path-to-desired-terminal-node&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Find the path to desired terminal node&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;import pydotplus
import re 
def return_node_path_to_max_prediction(onetree, verbose=True):
    &amp;quot;&amp;quot;&amp;quot;
    @input: a tree from the sklearn randomforest
    @output: the node path to maxmium terminal node
        [[split_node_1], [split_node_2], ...]
        [splite_node_1] = [var_index, cutoff, direction]
    &amp;quot;&amp;quot;&amp;quot;
    if verbose:
        print(&amp;quot;Generating Tree Graph, it may take a while...&amp;quot;)
    dot_data = tree.export_graphviz(onetree,
                                    out_file = None,
                                    filled   = True,
                                    rounded  = True,
                                    special_characters = True)  
    graph = pydotplus.graph_from_dot_data(dot_data)
    graph_ = {}
    for edge in graph.get_edge_list():
        graph_[edge.get_source()] = edge.get_destination()
    # find all terminal node
    terminal_node = {}
    non_decimal = re.compile(r&amp;#39;[^\d.]+&amp;#39;)
    for node in graph.get_node_list():
        if node.get_name() not in graph_:
            if node.get_name() not in [&amp;quot;node&amp;quot;, &amp;quot;edge&amp;quot;]:
                value = node.get_label()
                value = re.sub(r&amp;#39;.*v&amp;#39;, &amp;#39;v&amp;#39;, value)
                terminal_node[node.get_name()] = float(non_decimal.sub(&amp;#39;&amp;#39;, value))
    # find the path down to the terminal with maximum predition value
    flag = True
    destination = max(terminal_node, key=terminal_node.get)
    edge_list = graph.get_edge_list()
    node_list = graph.get_node_list()
    split_node = []
    while flag:
        myedge = [edge for edge in edge_list  if edge.get_destination() == destination][0]
        if int(myedge.get_destination()) - int(myedge.get_source()) &amp;gt; 1:
            direction = &amp;quot;Right&amp;quot;
        else:
            direction = &amp;quot;Left&amp;quot;
        
        mynode = [node for node in node_list if node.get_name() == myedge.get_source()][0]
        var_val = re.findall(r&amp;quot;[-+]?\d*\.\d+|\d+&amp;quot;, mynode.get_label())[:2]
        # record the growing path:
        #  var_val[0]: Index of variable participating in splitting
        #  var_val[1]: cutoff point of the splitting
        #  direction: If Right, means greater than var_val[1]; 
        #             If Left, means no greater than var_val[1]
        split_node.append([int(var_val[0]),float(var_val[1]),direction])
        if verbose:
            print(myedge.get_destination() + &amp;quot;&amp;lt;-&amp;quot; + myedge.get_source() + 
                  &amp;quot;: Split at Variable X&amp;quot; + var_val[0] + &amp;quot;; The cutoff is &amp;quot; + var_val[1] + 
                 &amp;quot;; Turn &amp;quot; + direction)
        destination = myedge.get_source()
        if destination == &amp;quot;0&amp;quot;:
            flag = False
        
    return [*reversed(split_node)]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Test:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;return_node_path_to_max_prediction(rf[1], verbose=True)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Outputs:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Generating Tree Graph, it may take a while...
3&amp;lt;-1: Split at Variable X0; The cutoff is 5.6; Turn Right
1&amp;lt;-0: Split at Variable X0; The cutoff is 12.95; Turn Left&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the output above, we know the path from the root to the desired terminal node is :&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Root[X0(&amp;lt;= 12.95)] -&amp;gt; X0 (&amp;gt;=5.6) -&amp;gt; Terminal Node&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;collect-paths-in-the-random-forest&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Collect Paths in the random forest&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;def collect_path(rf, verbose=True):
    n_tree = len(rf)
    result = []
    for i in range(n_tree):
        if verbose:
            print(&amp;quot;Construct the %s tree graph out of %s trees&amp;quot; %(i+1, n_tree))
        result.append(return_node_path_to_max_prediction(rf.estimators_[i], verbose=False))
    return result&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Test:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;result = collect_path(rf)
print(result)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Outputs:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Construct the 1 tree graph out of 10 trees
Construct the 2 tree graph out of 10 trees
Construct the 3 tree graph out of 10 trees
Construct the 4 tree graph out of 10 trees
Construct the 5 tree graph out of 10 trees
Construct the 6 tree graph out of 10 trees
Construct the 7 tree graph out of 10 trees
Construct the 8 tree graph out of 10 trees
Construct the 9 tree graph out of 10 trees
Construct the 10 tree graph out of 10 trees
[[[0, 4.2, &amp;#39;Left&amp;#39;]], [[0, 12.95, &amp;#39;Left&amp;#39;], [0, 5.6, &amp;#39;Right&amp;#39;]], [[1, 0.5, &amp;#39;Right&amp;#39;], [0, 8.4, &amp;#39;Left&amp;#39;]], [[0, 13.85, &amp;#39;Left&amp;#39;], [0, 8.4, &amp;#39;Left&amp;#39;], [1, 0.5, &amp;#39;Right&amp;#39;]], [[0, 8.4, &amp;#39;Left&amp;#39;], [0, 6.35, &amp;#39;Right&amp;#39;]], [[0, 12.95, &amp;#39;Left&amp;#39;], [0, 5.6, &amp;#39;Right&amp;#39;]], [[2, 0.5, &amp;#39;Left&amp;#39;], [0, 5.35, &amp;#39;Right&amp;#39;]], [[1, 0.5, &amp;#39;Right&amp;#39;], [0, 5.35, &amp;#39;Right&amp;#39;]], [[0, 13.85, &amp;#39;Left&amp;#39;], [1, 0.5, &amp;#39;Right&amp;#39;], [0, 8.4, &amp;#39;Left&amp;#39;], [0, 5.35, &amp;#39;Right&amp;#39;]], [[0, 13.85, &amp;#39;Left&amp;#39;], [0, 6.35, &amp;#39;Right&amp;#39;], [0, 8.4, &amp;#39;Left&amp;#39;]]]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;summarize-the-decison-region&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Summarize the decison region&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;def summarize_region(result, features):
    decision_region = {k: [[] for _ in range(2)] for k in features}
    for i in range(len(result)):
        for j in range(len(result[i])):
            if result[i][j][2] == &amp;quot;Left&amp;quot;:
                 decision_region[features[result[i][j][0]]][0].append(result[i][j][1])
            else:
                decision_region[features[result[i][j][0]]][1].append(result[i][j][1]) 
    
    decision_region_ = {}
    for k in features:
        try:
            upper_bound = min(decision_region[k][0])
        except ValueError:
            upper_bound = &amp;quot;Unknown&amp;quot;
        try:
            lower_bound = max(decision_region[k][1])
        except ValueError:
            lower_bound = &amp;quot;Unknown&amp;quot;
        decision_region_[k] = [lower_bound, upper_bound]
        
    value_to_remove = [&amp;#39;Unknown&amp;#39;, &amp;#39;Unknown&amp;#39;]
    decision_region_ = {key: value for key, value in decision_region_.items() if value != value_to_remove}
    value_to_remove = [0.5, 0.5]
    decision_region_ = {key: value for key, value in decision_region_.items() if value != value_to_remove}
    
    return (decision_region_)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Test:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;features = X.columns
summarize_region(result, features)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Outputs:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{&amp;#39;X_1_blue&amp;#39;: [0.5, &amp;#39;Unknown&amp;#39;], &amp;#39;X_1_red&amp;#39;: [&amp;#39;Unknown&amp;#39;, 0.5], &amp;#39;X_2&amp;#39;: [6.35, 4.2]}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the output above, we know that the decision region:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{blue} * [6.35, 4.2]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But it seems that the region &lt;strong&gt;[6.35, 4.2]&lt;/strong&gt; is not reasonable due to the poorly generated data. But it may happens in some situations, which may require us to come up with new ways to ensemble these terminal nodes.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Fitting Linear Mixed Models</title>
      <link>/post/en/fitting-linear-mixed-models/</link>
      <pubDate>Tue, 12 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/en/fitting-linear-mixed-models/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#decide-the-random-effects-covariance-structure&#34;&gt;Decide the random-effects covariance structure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#case-study&#34;&gt;Case-Study&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#igf-i&#34;&gt;IGF-I&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;decide-the-random-effects-covariance-structure&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Decide the random-effects covariance structure&lt;/h1&gt;
&lt;p&gt;Use function &lt;code&gt;lmList&lt;/code&gt; to have an idea of&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;which random-effects to include, and&lt;/li&gt;
&lt;li&gt;what the covariance structure to use.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(nlme)
# centering x to remove the correlation between intercept and slope
orth.list &amp;lt;- lmList( distance ~ I(age-11) | Subject, data = Orthodont)
# 1-id/2: significance level to identify the outlier
pairs(orth.list, id = 0.01, adj = -0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/EN/2018-06-12-fitting-linear-mixed-models_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;case-study&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Case-Study&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;orth.lme &amp;lt;- lme(distance ~ I(age-11), Orthodont, ~I(age-11) | Subject)
summary(orth.lme)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear mixed-effects model fit by REML
##  Data: Orthodont 
##        AIC      BIC    logLik
##   454.6367 470.6173 -221.3183
## 
## Random effects:
##  Formula: ~I(age - 11) | Subject
##  Structure: General positive-definite, Log-Cholesky parametrization
##             StdDev    Corr  
## (Intercept) 2.1343289 (Intr)
## I(age - 11) 0.2264278 0.503 
## Residual    1.3100402       
## 
## Fixed effects: distance ~ I(age - 11) 
##                 Value Std.Error DF  t-value p-value
## (Intercept) 24.023148 0.4296601 80 55.91198       0
## I(age - 11)  0.660185 0.0712533 80  9.26533       0
##  Correlation: 
##             (Intr)
## I(age - 11) 0.294 
## 
## Standardized Within-Group Residuals:
##          Min           Q1          Med           Q3          Max 
## -3.223106910 -0.493760892  0.007316481  0.472151223  3.916031726 
## 
## Number of Observations: 108
## Number of Groups: 27&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(fitted(orth.lme, level = 0:1), 4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      fixed  Subject
## 1 22.04259 24.81965
## 2 23.36296 26.57139
## 3 24.68333 28.32313
## 4 26.00370 30.07487&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;A quick explanation for the deriviation of fixed and subject.&lt;/strong&gt; Our model is built as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
y_{ij} = (\beta_0 + b_{i,1}) + (\beta_1 + b_{i,2})x_{ij} + \epsilon_{ij}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For &lt;code&gt;fixed&lt;/code&gt; column, the fitted values are on the population level, that is &lt;span class=&#34;math display&#34;&gt;\[\hat y_{ij}=\hat\beta_0 + \hat\beta_1x_{ij}.\]&lt;/span&gt; For example, for &lt;code&gt;subject:M01&lt;/code&gt; at &lt;code&gt;age:8&lt;/code&gt;, the fitted value is &lt;span class=&#34;math inline&#34;&gt;\(24.023148 + 0.660185 \times (8-11) = 22.04259\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;For &lt;code&gt;Subject&lt;/code&gt; column, the fitted values are on the each subject level, that is &lt;span class=&#34;math display&#34;&gt;\[\hat y_{ij}=(\hat\beta_0+\hat b_{i,1}) + (\hat\beta_1+\hat b_{i,2})x_{ij}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For example, for &lt;code&gt;subject:M01&lt;/code&gt; at &lt;code&gt;age:8&lt;/code&gt;, the fitted value is &lt;span class=&#34;math inline&#34;&gt;\(27.44726 + 0.8758702 \times (8-11) = 24.81965\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\((\hat\beta_0+\hat b_{i,1})\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\((\hat\beta_1+\hat b_{i,2})\)&lt;/span&gt; are derived from&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef(orth.lme,level=1)[rownames(coef(orth.lme,level=1)) == &amp;quot;M01&amp;quot;,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     (Intercept) I(age - 11)
## M01    27.44726   0.8758702&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(\hat b_{i,1}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\hat b_{i,2}\)&lt;/span&gt; are derived from&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;random.effects(orth.lme)[rownames(coef(orth.lme,level=1)) == &amp;quot;M01&amp;quot;,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     (Intercept) I(age - 11)
## M01    3.424112    0.215685&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;orth.lme.gender &amp;lt;- update(orth.lme, fixed = distance ~ I(age-11) * Sex)
summary(orth.lme.gender)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear mixed-effects model fit by REML
##  Data: Orthodont 
##        AIC      BIC    logLik
##   448.5817 469.7368 -216.2908
## 
## Random effects:
##  Formula: ~I(age - 11) | Subject
##  Structure: General positive-definite, Log-Cholesky parametrization
##             StdDev    Corr  
## (Intercept) 1.8303267 (Intr)
## I(age - 11) 0.1803454 0.206 
## Residual    1.3100397       
## 
## Fixed effects: distance ~ I(age - 11) + Sex + I(age - 11):Sex 
##                           Value Std.Error DF  t-value p-value
## (Intercept)           24.968750 0.4860007 79 51.37596  0.0000
## I(age - 11)            0.784375 0.0859995 79  9.12069  0.0000
## SexFemale             -2.321023 0.7614168 25 -3.04829  0.0054
## I(age - 11):SexFemale -0.304830 0.1347353 79 -2.26243  0.0264
##  Correlation: 
##                       (Intr) I(g-11) SexFml
## I(age - 11)            0.102               
## SexFemale             -0.638 -0.065        
## I(age - 11):SexFemale -0.065 -0.638   0.102
## 
## Standardized Within-Group Residuals:
##          Min           Q1          Med           Q3          Max 
## -3.168078484 -0.385939134  0.007103929  0.445154686  3.849463230 
## 
## Number of Observations: 108
## Number of Groups: 27&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fitted(orth.lme.gender, level = 0:1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        fixed  Subject
## 1   22.61562 24.84572
## 2   24.18437 26.57649
## 3   25.75312 28.30725
## 4   27.32187 30.03802
## 5   22.61562 21.27478
## 6   24.18437 22.79641
## 7   25.75312 24.31803
## 8   27.32187 25.83966
## 9   22.61562 22.03311
## 10  24.18437 23.56449
## 11  25.75312 25.09588
## 12  27.32187 26.62726
## 13  22.61562 24.46451
## 14  24.18437 25.75133
## 15  25.75312 27.03814
## 16  27.32187 28.32495
## 17  22.61562 20.90249
## 18  24.18437 22.45429
## 19  25.75312 24.00610
## 20  27.32187 25.55790
## 21  22.61562 23.88527
## 22  24.18437 25.43272
## 23  25.75312 26.98017
## 24  27.32187 28.52762
## 25  22.61562 21.57351
## 26  24.18437 23.11840
## 27  25.75312 24.66330
## 28  27.32187 26.20819
## 29  22.61562 21.99187
## 30  24.18437 23.31291
## 31  25.75312 24.63395
## 32  27.32187 25.95500
## 33  22.61562 22.60752
## 34  24.18437 24.28229
## 35  25.75312 25.95705
## 36  27.32187 27.63182
## 37  22.61562 26.47272
## 38  24.18437 28.14284
## 39  25.75312 29.81295
## 40  27.32187 31.48307
## 41  22.61562 21.81724
## 42  24.18437 23.10495
## 43  25.75312 24.39267
## 44  27.32187 25.68038
## 45  22.61562 21.84919
## 46  24.18437 23.51420
## 47  25.75312 25.17920
## 48  27.32187 26.84421
## 49  22.61562 21.15031
## 50  24.18437 23.32308
## 51  25.75312 25.49584
## 52  27.32187 27.66861
## 53  22.61562 22.72716
## 54  24.18437 24.15480
## 55  25.75312 25.58244
## 56  27.32187 27.01008
## 57  22.61562 23.13140
## 58  24.18437 24.90616
## 59  25.75312 26.68091
## 60  27.32187 28.45567
## 61  22.61562 21.12319
## 62  24.18437 22.51465
## 63  25.75312 23.90610
## 64  27.32187 25.29756
## 65  21.20909 20.20973
## 66  22.16818 21.07931
## 67  23.12727 21.94889
## 68  24.08636 22.81848
## 69  21.20909 21.27124
## 70  22.16818 22.41092
## 71  23.12727 23.55060
## 72  24.08636 24.69027
## 73  21.20909 21.86869
## 74  22.16818 23.05491
## 75  23.12727 24.24113
## 76  24.08636 25.42735
## 77  21.20909 23.09591
## 78  22.16818 24.11142
## 79  23.12727 25.12694
## 80  24.08636 26.14246
## 81  21.20909 21.34035
## 82  22.16818 22.18951
## 83  23.12727 23.03868
## 84  24.08636 23.88784
## 85  21.20909 19.99832
## 86  22.16818 20.86130
## 87  23.12727 21.72427
## 88  24.08636 22.58725
## 89  21.20909 21.45516
## 90  22.16818 22.46121
## 91  23.12727 23.46727
## 92  24.08636 24.47333
## 93  21.20909 22.04815
## 94  22.16818 22.86368
## 95  23.12727 23.67921
## 96  24.08636 24.49475
## 97  21.20909 20.07189
## 98  22.16818 20.88141
## 99  23.12727 21.69094
## 100 24.08636 22.50047
## 101 21.20909 17.72334
## 102 22.16818 18.55704
## 103 23.12727 19.39073
## 104 24.08636 20.22443
## 105 21.20909 24.21723
## 106 22.16818 25.37929
## 107 23.12727 26.54134
## 108 24.08636 27.70339&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;orth.lm.gender &amp;lt;- lm( distance ~ Sex * I(age - 11), Orthodont)
summary(orth.lm.gender)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = distance ~ Sex * I(age - 11), data = Orthodont)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.6156 -1.3219 -0.1682  1.3299  5.2469 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)            24.9687     0.2821  88.504  &amp;lt; 2e-16 ***
## SexFemale              -2.3210     0.4420  -5.251 8.05e-07 ***
## I(age - 11)             0.7844     0.1262   6.217 1.07e-08 ***
## SexFemale:I(age - 11)  -0.3048     0.1977  -1.542    0.126    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 2.257 on 104 degrees of freedom
## Multiple R-squared:  0.4227, Adjusted R-squared:  0.4061 
## F-statistic: 25.39 on 3 and 104 DF,  p-value: 2.108e-12&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(orth.lme.gender, orth.lm.gender)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in anova.lme(orth.lme.gender, orth.lm.gender): fitted objects with
## different fixed effects. REML comparisons are not meaningful.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                 Model df      AIC      BIC    logLik   Test  L.Ratio
## orth.lme.gender     1  8 448.5817 469.7368 -216.2908                
## orth.lm.gender      2  5 493.5591 506.7811 -241.7796 1 vs 2 50.97746
##                 p-value
## orth.lme.gender        
## orth.lm.gender   &amp;lt;.0001&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;igf-i&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;IGF-I&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(kableExtra)
knitr::kable(t(IGF)) %&amp;gt;% kable_styling(&amp;quot;striped&amp;quot;)  &lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
1
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
3
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
4
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
5
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
6
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
7
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
8
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
9
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
10
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
11
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
12
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
13
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
14
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
15
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
16
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
17
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
18
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
19
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
20
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
21
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
22
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
23
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
24
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
25
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
26
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
27
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
28
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
29
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
30
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
31
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
32
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
33
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
34
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
35
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
36
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
37
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
38
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
39
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
40
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
41
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
42
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
43
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
44
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
45
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
46
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
47
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
48
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
49
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
50
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
51
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
52
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
53
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
54
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
55
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
56
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
57
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
58
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
59
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
60
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
61
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
62
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
63
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
64
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
65
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
66
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
67
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
68
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
69
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
70
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
71
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
72
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
73
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
74
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
75
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
76
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
77
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
78
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
79
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
80
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
81
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
82
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
83
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
84
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
85
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
86
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
87
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
88
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
89
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
90
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
91
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
92
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
93
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
94
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
95
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
96
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
97
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
98
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
99
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
100
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
101
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
102
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
103
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
104
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
105
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
106
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
107
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
108
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
109
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
110
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
111
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
112
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
113
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
114
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
115
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
116
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
117
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
118
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
119
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
120
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
121
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
122
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
123
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
124
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
125
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
126
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
127
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
128
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
129
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
130
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
131
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
132
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
133
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
134
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
135
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
136
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
137
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
138
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
139
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
140
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
141
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
142
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
143
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
144
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
145
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
146
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
147
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
148
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
149
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
150
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
151
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
152
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
153
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
154
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
155
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
156
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
157
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
158
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
159
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
160
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
161
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
162
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
163
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
164
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
165
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
166
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
167
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
168
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
169
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
170
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
171
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
172
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
173
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
174
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
175
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
176
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
177
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
178
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
179
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
180
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
181
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
182
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
183
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
184
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
185
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
186
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
187
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
188
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
189
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
190
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
191
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
192
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
193
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
194
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
195
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
196
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
197
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
198
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
199
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
200
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
201
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
202
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
203
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
204
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
205
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
206
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
207
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
208
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
209
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
210
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
211
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
212
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
213
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
214
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
215
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
216
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
217
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
218
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
219
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
220
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
221
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
222
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
223
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
224
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
225
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
226
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
227
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
228
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
229
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
230
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
231
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
232
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
233
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
234
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
235
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
236
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
237
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
age
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
41
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
42
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
42
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
43
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
18
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
32
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
32
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
40
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
42
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
47
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
29
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
37
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
41
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
42
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
43
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
44
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
47
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
47
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
48
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
49
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
19
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
19
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
17
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
29
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
37
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
37
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
37
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
37
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
42
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
43
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
44
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
44
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
48
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
17
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
17
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
18
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
29
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
31
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
31
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
32
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
37
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
39
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
42
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
43
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
43
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
47
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
19
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
29
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
29
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
29
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
40
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
41
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
13
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
conc
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.90
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.68
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.32
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.94
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.19
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.18
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.88
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.24
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.88
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.40
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.59
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.77
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.57
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.86
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.87
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.65
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.34
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.93
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.33
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.99
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3.38
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.44
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.24
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.39
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.34
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.27
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.48
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.23
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.77
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.33
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.78
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.01
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.85
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.94
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.43
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.66
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.62
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6.20
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.30
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.09
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.78
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.66
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.76
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.81
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.92
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.32
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3.30
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.88
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.91
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.86
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.40
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.94
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.42
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.40
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.68
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.71
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9.55
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.94
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6.17
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.34
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8.14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.51
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.31
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.81
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.26
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.72
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.08
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3.99
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.87
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.92
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6.13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6.30
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.97
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.98
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6.68
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.33
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6.08
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.76
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.31
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6.66
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.52
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.48
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.08
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.63
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.38
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.78
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9.34
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.58
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.19
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.44
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.31
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.71
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.65
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.23
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.98
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.08
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.84
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.84
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.85
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.32
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.47
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.49
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.43
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.29
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6.25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.63
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.18
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.17
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.98
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.38
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3.76
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.63
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6.12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6.53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.55
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.62
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.58
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.41
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.84
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.83
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.36
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.81
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.35
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.46
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.09
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.78
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.44
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.98
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.56
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.83
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.27
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.90
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.94
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.78
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.42
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.42
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.38
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.55
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.81
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.62
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6.08
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.80
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.32
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.95
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.44
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.48
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.26
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.21
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.65
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.62
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.71
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.38
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.34
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.69
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9.74
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9.60
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.58
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.94
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.66
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.23
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.62
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.63
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.01
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.43
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6.17
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.57
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.82
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.84
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.55
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.17
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6.50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.36
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.47
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.57
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.36
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.93
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.49
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3.25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.91
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.74
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.95
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.54
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.29
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.59
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.66
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.69
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.18
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.19
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.35
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.28
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.47
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.55
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.75
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.41
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.65
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.81
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.71
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.95
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.74
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.68
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.83
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.30
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.63
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(IGF)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/EN/2018-06-12-fitting-linear-mixed-models_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;IGF.lmod &amp;lt;- lm(conc ~ age, data=IGF)
summary(IGF.lmod)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = conc ~ age, data = IGF)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.4877 -0.3736 -0.0091  0.2577  4.4144 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  5.3510594  0.1037341   51.58   &amp;lt;2e-16 ***
## age         -0.0006692  0.0039425   -0.17    0.865    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.8327 on 235 degrees of freedom
## Multiple R-squared:  0.0001226,  Adjusted R-squared:  -0.004132 
## F-statistic: 0.02882 on 1 and 235 DF,  p-value: 0.8654&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;IGF.lme.general &amp;lt;- lme(conc~age, data=IGF, random=list(Lot=pdSymm(~age)))
# Note lme(conc~age, data=IGF, random= ~ age | Lot) fails &amp;lt;https://stackoverflow.com/questions/7923387/error-with-nlme&amp;gt;
summary(IGF.lme.general)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear mixed-effects model fit by REML
##  Data: IGF 
##        AIC      BIC    logLik
##   606.3662 627.1237 -297.1831
## 
## Random effects:
##  Formula: ~age | Lot
##  Structure: General positive-definite
##             StdDev     Corr  
## (Intercept) 0.08251248 (Intr)
## age         0.00809218 -1    
## Residual    0.82062771       
## 
## Fixed effects: conc ~ age 
##                 Value  Std.Error  DF  t-value p-value
## (Intercept)  5.374974 0.10748847 226 50.00513  0.0000
## age         -0.002535 0.00504434 226 -0.50255  0.6158
##  Correlation: 
##     (Intr)
## age -0.818
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -5.43068351 -0.40522899 -0.03980665  0.36652519  5.21477600 
## 
## Number of Observations: 237
## Number of Groups: 10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;IGF.lme.diag &amp;lt;- lme(conc~age, data=IGF, random=list(Lot=pdDiag(~age)))
summary(IGF.lme.diag)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear mixed-effects model fit by REML
##  Data: IGF 
##        AIC      BIC    logLik
##   604.8006 622.0985 -297.4003
## 
## Random effects:
##  Formula: ~age | Lot
##  Structure: Diagonal
##          (Intercept)         age  Residual
## StdDev: 3.622081e-05 0.005372173 0.8218034
## 
## Fixed effects: conc ~ age 
##                 Value  Std.Error  DF  t-value p-value
## (Intercept)  5.369037 0.10378887 226 51.73037  0.0000
## age         -0.001930 0.00457021 226 -0.42233  0.6732
##  Correlation: 
##     (Intr)
## age -0.768
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -5.50939808 -0.41468591 -0.02726379  0.34697775  5.22750187 
## 
## Number of Observations: 237
## Number of Groups: 10&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The structure of grouped data</title>
      <link>/post/en/the-structure-of-grouped-data/</link>
      <pubDate>Fri, 08 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/en/the-structure-of-grouped-data/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Play with Sparse Matrix</title>
      <link>/post/en/play-with-sparse-matrix/</link>
      <pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/en/play-with-sparse-matrix/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#motivation&#34;&gt;Motivation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#solution&#34;&gt;Solution&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#slicing&#34;&gt;Slicing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#basic-linear-algebra-operations&#34;&gt;Basic linear algebra operations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;motivation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Motivation&lt;/h1&gt;
&lt;p&gt;Recently, I have to deal with matrices with sparsity structures. If I coerce them using the &lt;code&gt;as.matrix&lt;/code&gt; function, they consume my RAM wildly. So I turn to the package &lt;a href=&#34;http://www.econ.uiuc.edu/~roger/research/sparse/SparseM.pdf&#34;&gt;SparseM&lt;/a&gt; for possible solutions.&lt;/p&gt;
&lt;p&gt;What I want to do are,&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Performe basic linear algebra operations on sparse matrices, mainly including multiplication, transpose, and etc.&lt;/li&gt;
&lt;li&gt;Slice rows or columns by their indices.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The package &lt;code&gt;SparseM&lt;/code&gt; can perfectly fulfill my needs.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;solution&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Solution&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)
A &amp;lt;- matrix(rnorm(16), ncol=4, nrow=4)
A[A &amp;lt; 0] &amp;lt;- 0
A&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           [,1]      [,2] [,3]       [,4]
## [1,] 0.0000000 0.4291247    0 0.00000000
## [2,] 0.2774292 0.5060559    0 0.06445882
## [3,] 1.0844412 0.0000000    0 0.95949406
## [4,] 0.0000000 0.0000000    0 0.00000000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We reformat A in &lt;code&gt;csr&lt;/code&gt; form:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;suppressMessages(library(SparseM)) 
A.csr &amp;lt;- as.matrix.csr(A)
A.csr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## An object of class &amp;quot;matrix.csr&amp;quot;
## Slot &amp;quot;ra&amp;quot;:
## [1] 0.42912469 0.27742924 0.50605589 0.06445882 1.08444118 0.95949406
## 
## Slot &amp;quot;ja&amp;quot;:
## [1] 2 1 2 4 1 4
## 
## Slot &amp;quot;ia&amp;quot;:
## [1] 1 2 5 7 7
## 
## Slot &amp;quot;dimension&amp;quot;:
## [1] 4 4&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;ra: a real array of non-zero elements containing the non-zero elements of A, stored in row order. Thus, if i &amp;lt; j, all elements of row i precede elements from row j. The order of elements within the rows is immaterial.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;ja: an integer array of non-zero elements containing the column indices of the elements stored in ra.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;ia: an integer array of n+1 elements containing pointers to the beginning of each row in the arrays ra and ja. Thus ia[i] indicates the position in the arrays ra and ja where the ith row begins. The last (n + 1)st element of ia indicates where the n + 1 row would start, if it existed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;slicing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Slicing&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;A.csr[,1:2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## An object of class &amp;quot;matrix.csr&amp;quot;
## Slot &amp;quot;ra&amp;quot;:
## [1] 0.4291247 0.2774292 0.5060559 1.0844412
## 
## Slot &amp;quot;ja&amp;quot;:
## [1] 2 1 2 1
## 
## Slot &amp;quot;ia&amp;quot;:
## [1] 1 2 4 5 5
## 
## Slot &amp;quot;dimension&amp;quot;:
## [1] 4 2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as.matrix(A.csr[,1:2])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           [,1]      [,2]
## [1,] 0.0000000 0.4291247
## [2,] 0.2774292 0.5060559
## [3,] 1.0844412 0.0000000
## [4,] 0.0000000 0.0000000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;A.csr[, -1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## An object of class &amp;quot;matrix.csr&amp;quot;
## Slot &amp;quot;ra&amp;quot;:
## [1] 0.42912469 0.50605589 0.06445882 0.95949406
## 
## Slot &amp;quot;ja&amp;quot;:
## [1] 1 1 3 3
## 
## Slot &amp;quot;ia&amp;quot;:
## [1] 1 2 4 5 5
## 
## Slot &amp;quot;dimension&amp;quot;:
## [1] 4 3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as.matrix(A.csr[, -1])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           [,1] [,2]       [,3]
## [1,] 0.4291247    0 0.00000000
## [2,] 0.5060559    0 0.06445882
## [3,] 0.0000000    0 0.95949406
## [4,] 0.0000000    0 0.00000000&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;basic-linear-algebra-operations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Basic linear algebra operations&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t(A.csr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## An object of class &amp;quot;matrix.csr&amp;quot;
## Slot &amp;quot;ra&amp;quot;:
## [1] 0.27742924 1.08444118 0.42912469 0.50605589 0.06445882 0.95949406
## 
## Slot &amp;quot;ja&amp;quot;:
## [1] 2 3 1 2 2 3
## 
## Slot &amp;quot;ia&amp;quot;:
## [1] 1 3 5 5 7
## 
## Slot &amp;quot;dimension&amp;quot;:
## [1] 4 4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as.matrix(A.csr %*% c(1,2,3,4))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           [,1]
## [1,] 0.8582494
## [2,] 1.5473763
## [3,] 4.9224174
## [4,] 0.0000000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;A %*% c(1,2,3,4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           [,1]
## [1,] 0.8582494
## [2,] 1.5473763
## [3,] 4.9224174
## [4,] 0.0000000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can even visualize its sparse structure:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)
A &amp;lt;- matrix(rnorm(2000), ncol=50, nrow=40)
A[abs(A) &amp;lt; 0.7] &amp;lt;- 0
image(as.matrix.csr(A))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/EN/2018-06-01-play-with-sparse-matrix_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Get Data from the Website</title>
      <link>/post/en/get-data-from-website/</link>
      <pubDate>Thu, 31 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/en/get-data-from-website/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#motivation&#34;&gt;Motivation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#solutions&#34;&gt;Solutions&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#download&#34;&gt;Download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#uncompress-data-files&#34;&gt;Uncompress data files&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#load-libsvm-format-data&#34;&gt;Load libsvm format data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#complete-code&#34;&gt;Complete Code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;motivation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Motivation&lt;/h1&gt;
&lt;p&gt;I’m using the datasets &lt;a href=&#34;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&#34;&gt;libsvm&lt;/a&gt; to do some numerical experiments. The sizes of datasets, like epsilon&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;, are of severalGBs. So it is hard to play with the data on my desktop. I am lucky to run the experiments on a server. So my workflow is:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Download datasets on the server.&lt;/li&gt;
&lt;li&gt;Preprocess datastes.&lt;/li&gt;
&lt;li&gt;Run experiments.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The problems I encounted are&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;How to use &lt;code&gt;R&lt;/code&gt; functions to download data?&lt;/li&gt;
&lt;li&gt;Since dataset files are compressed, how to uncompresse them?&lt;/li&gt;
&lt;li&gt;How to read dataset are of the &lt;code&gt;libsvm&lt;/code&gt; format?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;solutions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Solutions&lt;/h1&gt;
&lt;p&gt;If you only care about the way to download datasets from R, then you can stop once finish reading the following subsection.&lt;/p&gt;
&lt;div id=&#34;download&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Download&lt;/h2&gt;
&lt;p&gt;Use built-in function &lt;code&gt;download.file&lt;/code&gt;, one can finish the task.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;download.file(target_path, path_filename_extension)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example,&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;download.file(https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/epsilon_normalized.bz2, &amp;quot;./data/epsilon_normalized.bz2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;uncompress-data-files&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Uncompress data files&lt;/h2&gt;
&lt;p&gt;Changce are that you datasets are compressed in &lt;code&gt;.zip&lt;/code&gt;, &lt;code&gt;.bz2&lt;/code&gt; and etc. formats, so you cannot directly load your data into the memory. You can use the function &lt;code&gt;bunzip2&lt;/code&gt; from the &lt;code&gt;R.utils&lt;/code&gt; packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bunzip2(path_filet_to_uncompress, path_file_to_save, remove = FALSE, skip = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;remove: If TRUE, the compressed file will be removed once uncompression finished.&lt;/li&gt;
&lt;li&gt;skip: If TRUE and the output file already exists, the output file is returned as is.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;download.file(&amp;quot;./data/epsilon_normalized.bz2&amp;quot;, &amp;quot;./data/epsilon_normalized&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, the original dataset file &lt;code&gt;epsilon_normalized&lt;/code&gt; has no extension.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;load-libsvm-format-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Load libsvm format data&lt;/h2&gt;
&lt;p&gt;The libsvm format data is of form&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;label&amp;gt; &amp;lt;index 1&amp;gt;:&amp;lt;value 1&amp;gt; &amp;lt;index 2&amp;gt;:&amp;lt;value 2&amp;gt; ... &amp;lt;index n&amp;gt;:&amp;lt;value n&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1 1:12 2:34 3:56
2 1:98 2:76 3:65&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more information, please refer to this &lt;a href=&#34;https://stats.stackexchange.com/questions/61328/libsvm-data-format&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We can use the &lt;code&gt;read.matrix.csr&lt;/code&gt; function from the &lt;code&gt;e1071&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- read.matrix.csr(file, fac=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example,&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- read.matrix.csr(&amp;quot;./data/epsilon_normalized&amp;quot;, fac=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that &lt;code&gt;data&lt;/code&gt; here is a list and matrix are stored in &lt;code&gt;sparse matrix&lt;/code&gt; format. We can use &lt;code&gt;data$x&lt;/code&gt; and &lt;code&gt;data$y&lt;/code&gt; to extract the feature matrix and the label vector respectively.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;complete-code&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Complete Code&lt;/h2&gt;
&lt;p&gt;The complete code to download and uncompress data files is&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_data &amp;lt;- function(target_path, save_path, save_name, extension, unzip=TRUE){
  path_file &amp;lt;- paste(save_path,save_name,sep=&amp;quot;/&amp;quot;)
  path_file_extension &amp;lt;- paste(path_file, extension, sep=&amp;quot;.&amp;quot;)
  download.file(target_path, path_file_extension)
  if (unzip){
    require(R.utils)
    bunzip2(path_file_extension, path_file, remove = FALSE, skip = TRUE)
    print(&amp;quot;unzip finished!&amp;quot;)
  }
  print(paste(&amp;quot;data is strored at:&amp;quot;, save_path))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The complete code to load &lt;code&gt;libsvm&lt;/code&gt; format data is&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;process_data &amp;lt;- function(file, convert_to_factor=FALSE){
  require(e1071)
  require(SparseM)
  print(&amp;quot;loading data&amp;quot;)
  data &amp;lt;- read.matrix.csr(file, fac=convert_to_factor)
  print(&amp;quot;loading finished&amp;quot;)
  x &amp;lt;- as.matrix(data$x)
  print(&amp;quot;x was conveted to dense matrix form&amp;quot;)
  y &amp;lt;- as.matrix(data$y)
  results &amp;lt;- list(x=x,y=y)
  return(results)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/epsilon_normalized.bz2&#34; class=&#34;uri&#34;&gt;https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/epsilon_normalized.bz2&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bookdown Syntax</title>
      <link>/post/en/bookdown-syntax/</link>
      <pubDate>Mon, 28 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/en/bookdown-syntax/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#math-equations-with-labels&#34;&gt;Math Equations with labels&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;Following contents are adapeted from Yihui Xie’s &lt;a href=&#34;https://bookdown.org/yihui/bookdown/components.html&#34;&gt;bookdown&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;math-equations-with-labels&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Math Equations with labels&lt;/h1&gt;
&lt;p&gt;My personal preference is to use &lt;code&gt;algin&lt;/code&gt; and &lt;code&gt;equation&lt;/code&gt; for long or complicated and simple expressions respectively. The slight differeces, compared with the &lt;span class=&#34;math inline&#34;&gt;\(\bf \LaTeX\)&lt;/span&gt; syntax, are the way we assign labels to expressions. Instead of using &lt;code&gt;\label{foo}&lt;/code&gt;, in blogdown (bookdown), it is recommend to use the syntax &lt;code&gt;(\#eq:foo)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Following are two simple examples. Use&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;\begin{equation}
  f(k) = \binom{n}{k} p^k(1-p)^{n-k}
  (\#eq:binom)
\end{equation}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to produce&lt;/p&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:binom&#34;&gt;\[\begin{equation}
  f(k) = \binom{n}{k} p^k(1-p)^{n-k}
  \tag{1}
\end{equation}\]&lt;/span&gt;
&lt;p&gt;Similarly, we can use &amp;amp; to algin equations.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;\begin{align}
&amp;amp; f(x;\mu,\sigma) = \frac{1}{\sqrt{2\pi}}\exp(\frac{1}{2\sigma^2}(x-\mu)^2) (\#eq:gaussian)\\
&amp;amp; f(x;\lambda) = \lambda e^{-\lambda}I(x&amp;gt;0) (\#eq:exp)
\end{align}&lt;/code&gt;&lt;/pre&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:exp&#34; id=&#34;eq:gaussian&#34;&gt;\[\begin{align}
&amp;amp; f(x;\mu,\sigma) = \frac{1}{\sqrt{2\pi}}\exp(\frac{1}{2\sigma^2}(x-\mu)^2) \tag{2}\\
&amp;amp; f(x;\lambda) = \lambda e^{-\lambda}I(x&amp;gt;0) \tag{3}
\end{align}\]&lt;/span&gt;
&lt;p&gt;For HTML output, bookdown can only number the equations with labels. Please make sure equations without labels are not numbered by either using the &lt;code&gt;equation*&lt;/code&gt; environment or adding &lt;code&gt;\nonumber&lt;/code&gt; or &lt;code&gt;\notag&lt;/code&gt; to your equations. The same rules apply to other math environments, such as eqnarray, gather, align, and so on (e.g., you can use the align* environment).&lt;/p&gt;
&lt;p&gt;To refer to a equation, please use &lt;code&gt;\@ref(eq:label)&lt;/code&gt;. For example,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;\@ref(eq:binom)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;can produce its index &lt;a href=&#34;#eq:binom&#34;&gt;(1)&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Explore the Linear Mixed Effect Model</title>
      <link>/post/en/explore-the-linear-mixed-effect-model/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/en/explore-the-linear-mixed-effect-model/</guid>
      <description>&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#why-ramdom-effect-models&#34;&gt;Why Ramdom Effect Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#one-way-classification-with-rail-example&#34;&gt;One-way classification with &lt;code&gt;Rail&lt;/code&gt; example&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#rail-data&#34;&gt;&lt;code&gt;Rail&lt;/code&gt; Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#modeling&#34;&gt;Modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#fitting-the-model-with-the-package-nlme&#34;&gt;Fitting the model with the package &lt;code&gt;nlme&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#diagnostic&#34;&gt;Diagnostic&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#two-way-classification-a-randomized-block-design&#34;&gt;Two-way classification: A Randomized Block Design&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#egrostool-no-replications&#34;&gt;&lt;code&gt;egroStool&lt;/code&gt;: No Replications&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#modeling-1&#34;&gt;Modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#diagnostic-1&#34;&gt;Diagnostic&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#machines-replications&#34;&gt;&lt;code&gt;Machines&lt;/code&gt;: Replications&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#modeling-2&#34;&gt;Modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#model-selection&#34;&gt;Model Selection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#extensions-for-interaction-terms&#34;&gt;Extensions for interaction terms&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ancova-with-random-effects-orthodont&#34;&gt;ANCOVA with random effects: &lt;code&gt;Orthodont&lt;/code&gt;&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#modeling-random-intercept&#34;&gt;Modeling: Random Intercept&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#modeling-random-intercept-1&#34;&gt;Modeling: Random Intercept&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#predicitons&#34;&gt;Predicitons&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#nested-classification-factors-pixel&#34;&gt;Nested Classification Factors: &lt;code&gt;Pixel&lt;/code&gt;&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#modeling-3&#34;&gt;Modeling&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#split-plot&#34;&gt;Split-plot&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;References: Pinheiro, J. C., &amp;amp; Bates, D. (2009). Mixed-Effects Models in S and S-PLUS. &lt;em&gt;Statistics and Computing&lt;/em&gt;, Springer.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;why-ramdom-effect-models&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Why Ramdom Effect Models&lt;/h1&gt;
&lt;p&gt;Compared with the linear fixed effect models, the advantages of modeling data with linear mixed-effect models (MLE) are:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Rather than models the specific type of sample of &lt;em&gt;levels&lt;/em&gt; from the &lt;strong&gt;factor&lt;/strong&gt; of interest, e.g &lt;em&gt;Rail tyep I&lt;/em&gt; and &lt;em&gt;Rail type II&lt;/em&gt; sampled from all possible types of the &lt;strong&gt;Rail&lt;/strong&gt;, LME models the factor from the population perspective.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Provide an estimate of the between-level variability.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Prevent the model complexity (# of parameters) increases linearly with the increase with # of levels.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;one-way-classification-with-rail-example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;One-way classification with &lt;code&gt;Rail&lt;/code&gt; example&lt;/h1&gt;
&lt;div id=&#34;rail-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;Rail&lt;/code&gt; Data&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;suppressMessages(library(nlme))
suppressMessages(library(kableExtra))
knitr::kable(t(Rail)) %&amp;gt;%  kable_styling(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;) %&amp;gt;%
  scroll_box(width = &amp;quot;100%&amp;quot;, height = &amp;quot;100%&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:100%; overflow-x: scroll; width:100%; &#34;&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
1
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
3
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
4
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
5
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
6
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
7
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
8
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
9
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
10
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
11
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
12
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
13
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
14
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
15
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
16
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
17
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
18
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Rail
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
travel
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
55
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
54
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
37
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
32
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
78
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
91
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
85
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
92
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
96
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
49
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
51
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
80
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
85
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
83
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(Rail)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/EN/2018-03-16-explore-the-linear-mixed-effect-model_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;modeling&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modeling&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Model and assumptions&lt;/strong&gt; &lt;span class=&#34;math display&#34;&gt;\[
y_{ij} = \mu + b_i + \epsilon_{ij} 
\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_i \sim N(0,\sigma_b^2)\)&lt;/span&gt;;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{ij} \sim N(0,\sigma^2)\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;parameters&lt;/th&gt;
&lt;th&gt;explanation&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;population mean&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma_b^2\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;between-rail variability&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{ij}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;noise&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;within-rail variability&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_i\)&lt;/span&gt; represents the deviation of the i-th type of rail from the population, it is not a parameter.&lt;/li&gt;
&lt;li&gt;Note &lt;strong&gt;this is a balcance design.&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;fitting-the-model-with-the-package-nlme&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fitting the model with the package &lt;code&gt;nlme&lt;/code&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rail_data &amp;lt;- Rail
lm.random &amp;lt;- lme(fixed = travel~1, data=rail_data, random = ~1 | Rail)
# fixed = travel~1: only the intercept is the fixed effect
# random = ~1 | Rail: there is a single random effect for each group and the grouping is given by the Rail
summary(lm.random)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear mixed-effects model fit by REML
##  Data: rail_data 
##       AIC      BIC   logLik
##   128.177 130.6766 -61.0885
## 
## Random effects:
##  Formula: ~1 | Rail
##         (Intercept) Residual
## StdDev:    24.80547 4.020779
## 
## Fixed effects: travel ~ 1 
##             Value Std.Error DF  t-value p-value
## (Intercept)  66.5  10.17104 12 6.538173       0
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -1.61882658 -0.28217671  0.03569328  0.21955784  1.61437744 
## 
## Number of Observations: 18
## Number of Groups: 6&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\mu =\)&lt;/span&gt; 66.5&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\sigma_b^2=24.80547\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\sigma^2=\)&lt;/span&gt; 4.0207794&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;diagnostic&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Diagnostic&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Confidence Intervals on parameters&lt;/strong&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;intervals(lm.random)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Approximate 95% confidence intervals
## 
##  Fixed effects:
##                lower est.    upper
## (Intercept) 44.33921 66.5 88.66079
## attr(,&amp;quot;label&amp;quot;)
## [1] &amp;quot;Fixed effects:&amp;quot;
## 
##  Random Effects:
##   Level: Rail 
##                    lower     est.    upper
## sd((Intercept)) 13.27434 24.80547 46.35341
## 
##  Within-group standard error:
##    lower     est.    upper 
## 2.695007 4.020779 5.998747&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The estimation of &lt;span class=&#34;math inline&#34;&gt;\(\mu,\sigma_b,\sigma\)&lt;/span&gt; are really raw and imprecise.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ANOVA of the fixed effect:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(lm.random)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             numDF denDF F-value p-value
## (Intercept)     1    12 42.7477  &amp;lt;.0001&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;two-way-classification-a-randomized-block-design&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Two-way classification: A Randomized Block Design&lt;/h1&gt;
&lt;p&gt;For block design, we have two types of factors, one is called &lt;em&gt;experimental&lt;/em&gt; factor for fixed effects while the other is called &lt;em&gt;blocking&lt;/em&gt; factor for the random effects.&lt;/p&gt;
&lt;div id=&#34;egrostool-no-replications&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;egroStool&lt;/code&gt;: No Replications&lt;/h2&gt;
&lt;p&gt;We want to make inferences subjects and types of stools are blocking factors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::kable(t(ergoStool)) %&amp;gt;% kable_styling(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;) %&amp;gt;%
  scroll_box(width = &amp;quot;100%&amp;quot;, height = &amp;quot;100%&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:100%; overflow-x: scroll; width:100%; &#34;&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
1
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
3
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
4
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
5
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
6
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
7
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
8
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
9
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
10
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
11
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
12
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
13
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
14
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
15
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
16
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
17
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
18
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
19
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
20
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
21
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
22
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
23
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
24
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
25
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
26
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
27
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
28
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
29
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
30
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
31
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
32
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
33
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
34
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
35
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
36
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
effort
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Type
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
T4
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Subject
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(ergoStool)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/EN/2018-03-16-explore-the-linear-mixed-effect-model_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;modeling-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Modeling&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Model and assumptions:&lt;/strong&gt; &lt;span class=&#34;math display&#34;&gt;\[
y_{ij} = \beta_j + b_i + \epsilon_{ij} 
\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_i \sim N(0,\sigma_b^2)\)&lt;/span&gt;;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{ij} \sim N(0,\sigma^2)\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;parameters&lt;/th&gt;
&lt;th&gt;explanation&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta_j\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;experimental factor (researchers are interested in)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma_b^2\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;between-rail variability&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{ij}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;noise&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;within-rail variability&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;Note &lt;strong&gt;this is a balcance design&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;choose-the-contrasts&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Choose the contrasts&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ergoStool %&amp;gt;% filter(Subject == &amp;quot;1&amp;quot;) %&amp;gt;% model.matrix(effort ~ Type, .)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;bindrcpp&amp;#39; was built under R version 3.4.4&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   (Intercept) TypeT2 TypeT3 TypeT4
## 1           1      0      0      0
## 2           1      1      0      0
## 3           1      0      1      0
## 4           1      0      0      1
## attr(,&amp;quot;assign&amp;quot;)
## [1] 0 1 1 1
## attr(,&amp;quot;contrasts&amp;quot;)
## attr(,&amp;quot;contrasts&amp;quot;)$Type
## [1] &amp;quot;contr.treatment&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lmod.random &amp;lt;- lme(effort ~ Type, data = ergoStool, random = ~1 | Subject)
summary(lmod.random)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear mixed-effects model fit by REML
##  Data: ergoStool 
##        AIC      BIC    logLik
##   133.1308 141.9252 -60.56539
## 
## Random effects:
##  Formula: ~1 | Subject
##         (Intercept) Residual
## StdDev:    1.332465 1.100295
## 
## Fixed effects: effort ~ Type 
##                Value Std.Error DF   t-value p-value
## (Intercept) 8.555556 0.5760123 24 14.853079  0.0000
## TypeT2      3.888889 0.5186838 24  7.497610  0.0000
## TypeT3      2.222222 0.5186838 24  4.284348  0.0003
## TypeT4      0.666667 0.5186838 24  1.285304  0.2110
##  Correlation: 
##        (Intr) TypeT2 TypeT3
## TypeT2 -0.45               
## TypeT3 -0.45   0.50        
## TypeT4 -0.45   0.50   0.50 
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -1.80200345 -0.64316591  0.05783115  0.70099706  1.63142054 
## 
## Number of Observations: 36
## Number of Groups: 9&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1=\)&lt;/span&gt;intercept: reference level(TypeT1);&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_i=\)&lt;/span&gt; (TypeTi) + intercept i=2,3,4&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Significance Tests for fixed effects&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(\beta_2=\beta_3=\beta_4=0\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(lmod.random)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             numDF denDF  F-value p-value
## (Intercept)     1    24 455.0075  &amp;lt;.0001
## Type            3    24  22.3556  &amp;lt;.0001&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(F_{3,24} &amp;gt; 22.3556)&amp;lt;.0001\)&lt;/span&gt;, there are significance variation within the each type of stools.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;diagnostic-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Diagnostic&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;intervals(lmod.random)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Approximate 95% confidence intervals
## 
##  Fixed effects:
##                  lower      est.    upper
## (Intercept)  7.3667247 8.5555556 9.744386
## TypeT2       2.8183781 3.8888889 4.959400
## TypeT3       1.1517114 2.2222222 3.292733
## TypeT4      -0.4038442 0.6666667 1.737177
## attr(,&amp;quot;label&amp;quot;)
## [1] &amp;quot;Fixed effects:&amp;quot;
## 
##  Random Effects:
##   Level: Subject 
##                    lower     est.    upper
## sd((Intercept)) 0.749509 1.332465 2.368835
## 
##  Within-group standard error:
##     lower      est.     upper 
## 0.8292494 1.1002946 1.4599324&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(lmod.random,
     form = resid(., type=&amp;quot;p&amp;quot;) ~ fitted(.) | Subject,
     abline = 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/EN/2018-03-16-explore-the-linear-mixed-effect-model_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;machines-replications&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;Machines&lt;/code&gt;: Replications&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;With replications, we are able to access the interactions between the experimental and blocking effects!!&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::kable(t(Machines)) %&amp;gt;% kable_styling(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;) %&amp;gt;%
  scroll_box(width = &amp;quot;100%&amp;quot;, height = &amp;quot;100%&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:100%; overflow-x: scroll; width:100%; &#34;&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
1
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
3
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
4
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
5
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
6
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
7
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
8
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
9
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
10
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
11
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
12
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
13
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
14
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
15
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
16
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
17
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
18
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
19
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
20
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
21
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
22
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
23
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
24
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
25
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
26
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
27
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
28
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
29
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
30
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
31
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
32
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
33
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
34
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
35
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
36
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
37
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
38
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
39
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
40
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
41
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
42
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
43
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
44
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
45
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
46
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
47
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
48
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
49
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
50
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
51
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
52
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
53
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
54
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Worker
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Machine
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
score
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
52.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
52.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
53.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
51.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
52.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
53.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
60.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
60.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
58.4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
51.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
52.3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
50.3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
50.9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
51.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
51.4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
46.4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
44.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
49.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
62.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
62.6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
64.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
59.7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
60.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
59.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
68.6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
65.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
69.7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
63.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
62.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
62.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
64.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
65.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
65.4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
43.7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
44.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
43.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
67.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
67.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
61.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
61.7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
62.3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
70.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
70.6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
71.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
64.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
64.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
72.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
72.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
71.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
62.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
61.4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
60.5
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Machines %&amp;gt;% {plot.experiment(.$score,.$Machine,.$Worker,
                lab.x = &amp;quot;Score&amp;quot;, lab.y = &amp;quot;Worker&amp;quot;, lab.experimental = &amp;quot;Machine&amp;quot;)}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/EN/2018-03-16-explore-the-linear-mixed-effect-model_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;modeling-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Modeling&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Model and assumptions - without interactions:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
y_{ijk} = \beta_j + b_i + \epsilon_{ijk} 
\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_i \sim N(0,\sigma_b^2)\)&lt;/span&gt;;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{ijk} \sim N(0,\sigma^2)\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;parameters&lt;/th&gt;
&lt;th&gt;explanation&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta_j\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;experimental factor (researchers are interested in)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma_b^2\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;between-rail variability&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{ijk}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;noise&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;within-rail variability&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;Note &lt;strong&gt;this is a balcance design&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lmod.random &amp;lt;- lme(score ~ Machine, data = Machines, random = ~1 | Worker)
summary(lmod.random)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear mixed-effects model fit by REML
##  Data: Machines 
##        AIC      BIC    logLik
##   296.8782 306.5373 -143.4391
## 
## Random effects:
##  Formula: ~1 | Worker
##         (Intercept) Residual
## StdDev:    5.146552 3.161647
## 
## Fixed effects: score ~ Machine 
##                Value Std.Error DF  t-value p-value
## (Intercept) 52.35556  2.229312 46 23.48507       0
## MachineB     7.96667  1.053883 46  7.55935       0
## MachineC    13.91667  1.053883 46 13.20514       0
##  Correlation: 
##          (Intr) MachnB
## MachineB -0.236       
## MachineC -0.236  0.500
## 
## Standardized Within-Group Residuals:
##        Min         Q1        Med         Q3        Max 
## -2.7248806 -0.5232891  0.1327564  0.6513056  1.7559058 
## 
## Number of Observations: 54
## Number of Groups: 6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Model and assumptions - with interactions&lt;/strong&gt; &lt;span class=&#34;math display&#34;&gt;\[
y_{ijk} = \beta_j + b_i + b_{ij} + \epsilon_{ijk} 
\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_i \sim N(0,\sigma_1^2)\)&lt;/span&gt;;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_{ij} \sim N(0,\sigma_2^2)\)&lt;/span&gt;;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{ijk} \sim N(0,\sigma^2)\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;table style=&#34;width:18%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;8%&#34; /&gt;
&lt;col width=&#34;9%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;parameters&lt;/th&gt;
&lt;th&gt;explanation&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta_j\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;experimental factor (researchers are interested in)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_i\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;blocking factor (source of variablity that is not of the primary interest)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_{ij}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;interaction effects between experimental factor and blocking factor&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma_b^2\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;between-rail variability&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{ijk}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;noise&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;within-rail variability&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;Note &lt;strong&gt;this is a balcance design.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Worker/Machine: Modeling two levels of random effects, Worker and Machine within Worker
lmod.random.interact &amp;lt;- lme(score ~ Machine, data = Machines, random = ~1 | Worker/Machine)
summary(lmod.random.interact)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear mixed-effects model fit by REML
##  Data: Machines 
##        AIC      BIC    logLik
##   227.6876 239.2785 -107.8438
## 
## Random effects:
##  Formula: ~1 | Worker
##         (Intercept)
## StdDev:     4.78105
## 
##  Formula: ~1 | Machine %in% Worker
##         (Intercept)  Residual
## StdDev:    3.729532 0.9615771
## 
## Fixed effects: score ~ Machine 
##                Value Std.Error DF   t-value p-value
## (Intercept) 52.35556  2.485828 36 21.061613  0.0000
## MachineB     7.96667  2.176972 10  3.659518  0.0044
## MachineC    13.91667  2.176972 10  6.392672  0.0001
##  Correlation: 
##          (Intr) MachnB
## MachineB -0.438       
## MachineC -0.438  0.500
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -2.26958675 -0.54846580 -0.01070594  0.43936568  2.54005792 
## 
## Number of Observations: 54
## Number of Groups: 
##              Worker Machine %in% Worker 
##                   6                  18&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta_1 =52.36\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\beta_2 = 52.36 + 7.97\)&lt;/span&gt;, … &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1 = 4.78105\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\sigma_2 =3.729532\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\sigma = 0.9615771\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-selection&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model Selection&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H_0: \text{the restricted model} \qquad H_A: \text{the general model}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(lmod.random,lmod.random.interact)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                      Model df      AIC      BIC    logLik   Test  L.Ratio
## lmod.random              1  5 296.8782 306.5373 -143.4391                
## lmod.random.interact     2  6 227.6876 239.2785 -107.8438 1 vs 2 71.19063
##                      p-value
## lmod.random                 
## lmod.random.interact  &amp;lt;.0001&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(LR=2[\log(L_A)-\log(L_0)] \sim \chi^2_{df_A -df_0}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The likelihood ratio test suggests that model with interatcions are preferred.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;extensions-for-interaction-terms&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Extensions for interaction terms&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Machines %&amp;gt;% filter(Worker == &amp;quot;1&amp;quot;) %&amp;gt;% {plot.experiment(.$score,.$Machine,.$Worker,
                lab.x = &amp;quot;Score&amp;quot;, lab.y = &amp;quot;Worker&amp;quot;, lab.experimental = &amp;quot;Machine&amp;quot;)}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/EN/2018-03-16-explore-the-linear-mixed-effect-model_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For each worker, say Worker 1, we previously assume&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
y_{1jk} = \beta_j + b_1 + b_{1j} + \epsilon_{1jk} 
\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_1 \sim N(0,\sigma_1^2)\)&lt;/span&gt;;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_{1j} \sim N(0,\sigma_2^2)\)&lt;/span&gt;;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{1jk} \sim N(0,\sigma^2)\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We assume &lt;span class=&#34;math inline&#34;&gt;\(b_{1j}\)&lt;/span&gt; iid &lt;span class=&#34;math inline&#34;&gt;\(N(0,\sigma_2^2)\)&lt;/span&gt;, but from the graph above, it seems that it’s not plausible. We can turn to more general variacne structures.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\bf{y_{1}} = X_1\beta + Z_1b_1 + \epsilon_{1}
\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\({\bf{b_1}} \sim N_3(0,\Phi)\)&lt;/span&gt;;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\({\bf{\epsilon_{1}}} \sim N(0,\sigma^2I_3)\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To fit this model, we need to specify the &lt;span class=&#34;math inline&#34;&gt;\(X_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(Z_1\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fixed effect X_1
Machines %&amp;gt;% filter(Worker == &amp;quot;1&amp;quot;) %&amp;gt;% {model.matrix( score ~ Machine, .)}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   (Intercept) MachineB MachineC
## 1           1        0        0
## 2           1        0        0
## 3           1        0        0
## 4           1        1        0
## 5           1        1        0
## 6           1        1        0
## 7           1        0        1
## 8           1        0        1
## 9           1        0        1
## attr(,&amp;quot;assign&amp;quot;)
## [1] 0 1 1
## attr(,&amp;quot;contrasts&amp;quot;)
## attr(,&amp;quot;contrasts&amp;quot;)$Machine
## [1] &amp;quot;contr.treatment&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fixed effect Z_1
Machines %&amp;gt;% filter(Worker == &amp;quot;1&amp;quot;) %&amp;gt;% {model.matrix(  score ~ Machine - 1, .)}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   MachineA MachineB MachineC
## 1        1        0        0
## 2        1        0        0
## 3        1        0        0
## 4        0        1        0
## 5        0        1        0
## 6        0        1        0
## 7        0        0        1
## 8        0        0        1
## 9        0        0        1
## attr(,&amp;quot;assign&amp;quot;)
## [1] 1 1 1
## attr(,&amp;quot;contrasts&amp;quot;)
## attr(,&amp;quot;contrasts&amp;quot;)$Machine
## [1] &amp;quot;contr.treatment&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lmod.random.interact.general &amp;lt;- lme(score ~ Machine, Machines, random = ~ Machine -1 | Worker)
summary(lmod.random.interact.general)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear mixed-effects model fit by REML
##  Data: Machines 
##        AIC      BIC    logLik
##   228.3112 247.6295 -104.1556
## 
## Random effects:
##  Formula: ~Machine - 1 | Worker
##  Structure: General positive-definite, Log-Cholesky parametrization
##          StdDev    Corr         
## MachineA 4.0792807 MachnA MachnB
## MachineB 8.6252908 0.803        
## MachineC 4.3894795 0.623  0.771 
## Residual 0.9615766              
## 
## Fixed effects: score ~ Machine 
##                Value Std.Error DF   t-value p-value
## (Intercept) 52.35556  1.680711 46 31.150834  0.0000
## MachineB     7.96667  2.420851 46  3.290854  0.0019
## MachineC    13.91667  1.540100 46  9.036211  0.0000
##  Correlation: 
##          (Intr) MachnB
## MachineB  0.463       
## MachineC -0.374  0.301
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -2.39354008 -0.51377575  0.02690829  0.47245472  2.53338699 
## 
## Number of Observations: 54
## Number of Groups: 6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Model Selection&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(lmod.random, lmod.random.interact, lmod.random.interact.general)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                              Model df      AIC      BIC    logLik   Test
## lmod.random                      1  5 296.8782 306.5373 -143.4391       
## lmod.random.interact             2  6 227.6876 239.2785 -107.8438 1 vs 2
## lmod.random.interact.general     3 10 228.3112 247.6295 -104.1556 2 vs 3
##                               L.Ratio p-value
## lmod.random                                  
## lmod.random.interact         71.19063  &amp;lt;.0001
## lmod.random.interact.general  7.37635  0.1173&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There’s no evidence to support more general model.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;ancova-with-random-effects-orthodont&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;ANCOVA with random effects: &lt;code&gt;Orthodont&lt;/code&gt;&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;OrthFe &amp;lt;- Orthodont %&amp;gt;% filter(Sex == &amp;quot;Female&amp;quot;)
knitr::kable(t(OrthFe)) %&amp;gt;% kable_styling(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;) %&amp;gt;%
  scroll_box(width = &amp;quot;100%&amp;quot;, height = &amp;quot;100%&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:100%; overflow-x: scroll; width:100%; &#34;&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
20.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
23.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
24.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
25.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
20.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
24.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
24.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
26.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
23.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
24.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
25.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
26.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
23.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
22.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
23.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
20.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
22.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
22.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
23.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
25.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
23.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
23.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
23.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
24.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
20.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
22.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
16.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
19.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
19.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
19.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
24.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
25.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
28.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
28.0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
age
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Subject
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F01
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F01
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F01
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F01
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F04
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F04
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F04
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F04
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F08
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F08
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F08
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F08
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F09
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F09
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F09
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F09
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F11
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sex
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Female
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;modeling-random-intercept&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Modeling: Random Intercept&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Model and assumptions:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\bf{y_{i}} = X_i\beta + Z_ib_i + \epsilon_{i}
\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_i \sim N(0,\sigma^2)\)&lt;/span&gt;;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{i} \sim N(0,\sigma^2I)\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example,&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fixed effect X_1
OrthFe  %&amp;gt;% filter(Subject == &amp;quot;F01&amp;quot;) %&amp;gt;% {model.matrix( distance ~ age, .)}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   (Intercept) age
## 1           1   8
## 2           1  10
## 3           1  12
## 4           1  14
## attr(,&amp;quot;assign&amp;quot;)
## [1] 0 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# random effect Z_1
OrthFe  %&amp;gt;% filter(Subject == &amp;quot;F01&amp;quot;) %&amp;gt;% {model.matrix(  distance ~ 1, .)}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   (Intercept)
## 1           1
## 2           1
## 3           1
## 4           1
## attr(,&amp;quot;assign&amp;quot;)
## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lmod.OrthFe &amp;lt;- lme(distance ~ age, data=OrthFe, random = ~ 1 | Subject)
summary(lmod.OrthFe)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear mixed-effects model fit by REML
##  Data: OrthFe 
##        AIC     BIC    logLik
##   149.2183 156.169 -70.60916
## 
## Random effects:
##  Formula: ~1 | Subject
##         (Intercept)  Residual
## StdDev:     2.06847 0.7800331
## 
## Fixed effects: distance ~ age 
##                 Value Std.Error DF   t-value p-value
## (Intercept) 17.372727 0.8587419 32 20.230440       0
## age          0.479545 0.0525898 32  9.118598       0
##  Correlation: 
##     (Intr)
## age -0.674
## 
## Standardized Within-Group Residuals:
##        Min         Q1        Med         Q3        Max 
## -2.2736479 -0.7090164  0.1728237  0.4122128  1.6325181 
## 
## Number of Observations: 44
## Number of Groups: 11&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;modeling-random-intercept-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Modeling: Random Intercept&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Model and assumptions:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\bf{y_{i}} = X_i\beta + Z_i{\bf b_i} + \epsilon_{i}
\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_i \sim N_2(0,\Phi)\)&lt;/span&gt;;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{i} \sim N(0,\sigma^2I)\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Here&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(b_i=(b_{i1},b_{i2})\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(Z_i\)&lt;/span&gt; is identical to &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lmod.OrthFe.slope &amp;lt;- lme(distance ~ age, data=OrthFe, random = ~ age | Subject)
summary(lmod.OrthFe.slope)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear mixed-effects model fit by REML
##  Data: OrthFe 
##        AIC      BIC    logLik
##   149.4287 159.8547 -68.71435
## 
## Random effects:
##  Formula: ~age | Subject
##  Structure: General positive-definite, Log-Cholesky parametrization
##             StdDev    Corr  
## (Intercept) 1.8841866 (Intr)
## age         0.1609278 -0.354
## Residual    0.6682746       
## 
## Fixed effects: distance ~ age 
##                 Value Std.Error DF   t-value p-value
## (Intercept) 17.372727 0.7606027 32 22.840737       0
## age          0.479545 0.0662140 32  7.242353       0
##  Correlation: 
##     (Intr)
## age -0.637
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -1.85438224 -0.46784889  0.06779759  0.42976634  1.59215840 
## 
## Number of Observations: 44
## Number of Groups: 11&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(lmod.OrthFe, lmod.OrthFe.slope)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                   Model df      AIC      BIC    logLik   Test  L.Ratio
## lmod.OrthFe           1  4 149.2183 156.1690 -70.60916                
## lmod.OrthFe.slope     2  6 149.4287 159.8547 -68.71435 1 vs 2 3.789622
##                   p-value
## lmod.OrthFe              
## lmod.OrthFe.slope  0.1503&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This result implies there’s no explicit evidence to support the random slope model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;predicitons&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Predicitons&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt; knitr::kable(t(random.effects(lmod.OrthFe)))  %&amp;gt;% kable_styling(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;) %&amp;gt;%
  scroll_box(width = &amp;quot;100%&amp;quot;, height = &amp;quot;100%&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:100%; overflow-x: scroll; width:100%; &#34;&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
F10
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
F09
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
F06
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
F01
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
F05
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
F07
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
F02
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
F08
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
F03
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
F04
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
F11
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-4.005329
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.470449
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.470449
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.229032
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.021947
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3401786
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3401786
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7023042
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.06443
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.150807
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.599309
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;nested-classification-factors-pixel&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Nested Classification Factors: &lt;code&gt;Pixel&lt;/code&gt;&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::kable(t(Pixel)) %&amp;gt;% kable_styling(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;) %&amp;gt;%
  scroll_box(width = &amp;quot;100%&amp;quot;, height = &amp;quot;100%&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:100%; overflow-x: scroll; width:100%; &#34;&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
1
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
3
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
4
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
5
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
6
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
7
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
8
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
9
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
10
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
11
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
12
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
13
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
14
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
15
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
16
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
17
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
18
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
19
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
20
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
21
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
22
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
23
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
24
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
25
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
26
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
27
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
28
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
29
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
30
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
31
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
32
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
33
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
34
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
35
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
36
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
37
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
38
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
39
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
40
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
41
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
42
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
43
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
44
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
45
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
46
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
47
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
48
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
49
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
50
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
51
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
52
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
53
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
54
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
55
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
56
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
57
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
58
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
59
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
60
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
61
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
62
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
63
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
64
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
65
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
66
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
67
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
68
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
69
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
70
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
71
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
72
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
73
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
74
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
75
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
76
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
77
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
78
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
79
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
80
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
81
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
82
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
83
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
84
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
85
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
86
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
87
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
88
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
89
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
90
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
91
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
92
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
93
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
94
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
95
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
96
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
97
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
98
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
99
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
100
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
101
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
102
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Dog
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Side
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
L
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
day
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
pixel
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1045.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1044.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1042.9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1050.4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1045.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1038.9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1039.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1041.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1045.6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1051.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1054.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1052.7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1062.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1050.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1039.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1082.9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1091.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1088.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1099.4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1086.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1073.6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1034.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1090.7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1126.4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1108.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1122.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1100.7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1102.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1124.4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1128.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1124.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1126.7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1109.9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1094.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1084.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1093.9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1082.7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1076.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1151.3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1160.3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1139.7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1133.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1077.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1085.9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1100.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1083.4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1068.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1064.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1095.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1094.7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1081.4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1040.9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1054.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1051.9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1054.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1051.3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1051.4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1046.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1053.6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1052.9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1053.6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1057.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1064.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1065.3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1053.4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1043.9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1069.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1082.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1077.7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1073.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1076.4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1053.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1039.9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1114.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1111.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1100.3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1124.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1113.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1077.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1114.7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1117.6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1128.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1130.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1102.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1106.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1121.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1115.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1105.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1092.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1129.7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1136.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1108.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1094.3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1098.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1103.6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1106.8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1105.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1097.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1099.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1132.3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1154.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1161.1
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(Pixel)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/EN/2018-03-16-explore-the-linear-mixed-effect-model_files/figure-html/unnamed-chunk-32-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;modeling-3&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modeling&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Model and assumptions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
y_{ijk} = \beta_1 + \beta_2 d_{ik} + b_{i1} + b_{i2}d_{i,k} + b_{ij} + \epsilon_{ijk}
\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{ijk} \sim N(0,\sigma^2)\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;parameters&lt;/th&gt;
&lt;th&gt;explanation&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;intercept&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;slope&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma_b^2\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;between-rail variability&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{ijk}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;noise&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;within-rail variability&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;observation&lt;/th&gt;
&lt;th&gt;explanation&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(y_{ijk}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;the k-th observation on the i-th dog’s j-th side&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(d_{ik}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;k-th obsservation on i-th dog&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_{i1}\)&lt;/span&gt;: random shift on intercept&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_{i2}\)&lt;/span&gt;: random shift on slope&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_{ij}\)&lt;/span&gt;: random shift on intercept for &lt;code&gt;side&lt;/code&gt; within &lt;code&gt;dog&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lmod.nested &amp;lt;- lme(fixed = pixel ~ day + I(day^2), data=Pixel, random = 
                     list(Dog = pixel ~ day, Side = pixel ~ 1))
summary(lmod.nested)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear mixed-effects model fit by REML
##  Data: Pixel 
##        AIC      BIC    logLik
##   841.2102 861.9712 -412.6051
## 
## Random effects:
##  Formula: pixel ~ day | Dog
##  Structure: General positive-definite, Log-Cholesky parametrization
##             StdDev   Corr  
## (Intercept) 28.36990 (Intr)
## day          1.84375 -0.555
## 
##  Formula: pixel ~ 1 | Side %in% Dog
##         (Intercept) Residual
## StdDev:    16.82431 8.989606
## 
## Fixed effects: pixel ~ day + I(day^2) 
##                 Value Std.Error DF   t-value p-value
## (Intercept) 1073.3391 10.171686 80 105.52225       0
## day            6.1296  0.879321 80   6.97083       0
## I(day^2)      -0.3674  0.033945 80 -10.82179       0
##  Correlation: 
##          (Intr) day   
## day      -0.517       
## I(day^2)  0.186 -0.668
## 
## Standardized Within-Group Residuals:
##        Min         Q1        Med         Q3        Max 
## -2.8290572 -0.4491811  0.0255493  0.5572163  2.7519651 
## 
## Number of Observations: 102
## Number of Groups: 
##           Dog Side %in% Dog 
##            10            20&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;intervals(lmod.nested)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Approximate 95% confidence intervals
## 
##  Fixed effects:
##                    lower         est.        upper
## (Intercept) 1053.0968388 1073.3391382 1093.5814376
## day            4.3796925    6.1295971    7.8795016
## I(day^2)      -0.4349038   -0.3673503   -0.2997967
## attr(,&amp;quot;label&amp;quot;)
## [1] &amp;quot;Fixed effects:&amp;quot;
## 
##  Random Effects:
##   Level: Dog 
##                           lower       est.      upper
## sd((Intercept))      15.9292099 28.3699038 50.5267650
## sd(day)               1.0814073  1.8437505  3.1435110
## cor((Intercept),day) -0.8943751 -0.5547222  0.1906591
##   Level: Side 
##                    lower     est.    upper
## sd((Intercept)) 10.41733 16.82431 27.17176
## 
##  Within-group standard error:
##     lower      est.     upper 
##  7.634529  8.989606 10.585199&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(augPred(lmod.nested))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/EN/2018-03-16-explore-the-linear-mixed-effect-model_files/figure-html/unnamed-chunk-35-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lmod.nested.res1 &amp;lt;- lme(fixed = pixel ~ day + I(day^2), data=Pixel, random = ~ day|Dog)
summary(lmod.nested.res1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear mixed-effects model fit by REML
##  Data: Pixel 
##        AIC      BIC    logLik
##   884.5196 902.6854 -435.2598
## 
## Random effects:
##  Formula: ~day | Dog
##  Structure: General positive-definite, Log-Cholesky parametrization
##             StdDev    Corr  
## (Intercept) 29.883240 (Intr)
## day          1.754207 -0.489
## Residual    14.056243       
## 
## Fixed effects: pixel ~ day + I(day^2) 
##                 Value Std.Error DF   t-value p-value
## (Intercept) 1072.9283 10.445666 90 102.71516       0
## day            6.0889  1.146997 90   5.30856       0
## I(day^2)      -0.3568  0.052210 90  -6.83314       0
##  Correlation: 
##          (Intr) day   
## day      -0.541       
## I(day^2)  0.286 -0.799
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -2.85494002 -0.53431941 -0.01425967  0.56188163  2.81513852 
## 
## Number of Observations: 102
## Number of Groups: 10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(lmod.nested.res1, lmod.nested)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                  Model df      AIC      BIC    logLik   Test L.Ratio
## lmod.nested.res1     1  7 884.5196 902.6854 -435.2598               
## lmod.nested          2  8 841.2102 861.9712 -412.6051 1 vs 2 45.3094
##                  p-value
## lmod.nested.res1        
## lmod.nested       &amp;lt;.0001&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lmod.nested.res2 &amp;lt;- lme(fixed = pixel ~ day + I(day^2), data=Pixel, 
                        random = ~ 1|Dog/Side)
anova(lmod.nested.res2, lmod.nested)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                  Model df      AIC      BIC    logLik   Test  L.Ratio
## lmod.nested.res2     1  6 876.8390 892.4098 -432.4195                
## lmod.nested          2  8 841.2102 861.9712 -412.6051 1 vs 2 39.62885
##                  p-value
## lmod.nested.res2        
## lmod.nested       &amp;lt;.0001&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;split-plot&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Split-plot&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(Oats,inner=Oats$Variety)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/EN/2018-03-16-explore-the-linear-mixed-effect-model_files/figure-html/unnamed-chunk-39-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Real Estate Market Data Analysis</title>
      <link>/project/boston-housing/</link>
      <pubDate>Sun, 10 Dec 2017 00:00:00 -0500</pubDate>
      
      <guid>/project/boston-housing/</guid>
      <description>&lt;p&gt;In this project, we&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Develope data products to help Airbnb hosts to determine listing prices using Sparse Regression and RandomForest&lt;/li&gt;
&lt;li&gt;Researched how amenities and geolocation in uence listing prices&lt;/li&gt;
&lt;li&gt;Designed a User Interface for customers to gain insight into Airbnb rental markets in Boston&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;a href=&#34;https://mediaspace.illinois.edu/media/t/1_3yvpnzqn&#34; target=&#34;_blank&#34;&gt;Video Presentation&lt;/a&gt; and &lt;a href=&#34;https://yutongdai.shinyapps.io/shinyapp/&#34; target=&#34;_blank&#34;&gt;Rshiny App Demo&lt;/a&gt; are also provided.&lt;/p&gt;

&lt;iframe id=&#34;kmsembed-1_3yvpnzqn&#34; width=&#34;640&#34; height=&#34;394&#34; src=&#34;https://mediaspace.illinois.edu/embed/secure/iframe/entryId/1_3yvpnzqn/uiConfId/26883701&#34; class=&#34;kmsembed&#34; allowfullscreen webkitallowfullscreen mozAllowFullScreen allow=&#34;autoplay *; fullscreen *; encrypted-media *&#34; frameborder=&#34;0&#34; title=&#34;Kaltura Player&#34;&gt;&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Show and Tell: A Neural Image Caption Generator</title>
      <link>/project/show-and-tell/</link>
      <pubDate>Sun, 10 Dec 2017 00:00:00 -0500</pubDate>
      
      <guid>/project/show-and-tell/</guid>
      <description>&lt;p&gt;This is the deep learning course final project trying to reporduce the results reported in the paper, &lt;a href=&#34;https://arxiv.org/pdf/1411.4555.pdf&#34; target=&#34;_blank&#34;&gt;Show and Tell: A Neural Image Caption Generator&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The model is trained on the &lt;a href=&#34;http://cocodataset.org/#home&#34; target=&#34;_blank&#34;&gt;MS coco2014 dataset&lt;/a&gt;. Our final result looks like&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/project-pics/caption-demo.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;For code, UI, and report  please click &lt;a href=&#34;https://github.com/Rothdyt/Projects/tree/master/Show-and-tell&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Variational Gaussian Mixtures</title>
      <link>/project/variational-inference/</link>
      <pubDate>Sun, 10 Dec 2017 00:00:00 -0500</pubDate>
      
      <guid>/project/variational-inference/</guid>
      <description>&lt;p&gt;This is the statistical computing course final project, trying to understand, reporduce and extend some results reported in the paper, &lt;a href=&#34;https://arxiv.org/pdf/1601.00670.pdf&#34; target=&#34;_blank&#34;&gt;Variational Inference: A Review for Statisticians&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Three datasets are used here, simulated data, &lt;a href=&#34;https://www.stat.cmu.edu/~larry/all-of-statistics/=data/faithful.dat&#34; target=&#34;_blank&#34;&gt;old faithful&lt;/a&gt; and &lt;a href=&#34;https://www.imageclef.org&#34; target=&#34;_blank&#34;&gt;imageCLEF&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Our final result looks like&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Simulated data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;/img/project-pics/simulation.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;old faithful
&lt;img src=&#34;/img/project-pics/old_faithful.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;imageclef&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;/img/project-pics/imageclef.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;For code and report please click &lt;a href=&#34;https://github.com/Rothdyt/Projects/tree/master/Show-and-tell&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lagrange乘子理论(3)</title>
      <link>/post/zh/lag3/</link>
      <pubDate>Wed, 21 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/zh/lag3/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#beyond-kkt&#34;&gt;Beyond KKT&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#fritz-john-&#34;&gt;Fritz-John 最优性条件&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#fritz-john--kkt-&#34;&gt;从Fritz-John 条件到 KKT 条件&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a&gt;凸集约束的情形&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;beyond-kkt&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Beyond KKT&lt;/h2&gt;
&lt;p&gt;在前面的讨论中，我们看到最优点的正则性对Lagrange乘子的存在性是必不可少的。&lt;/p&gt;
&lt;p&gt;下面我们要讨论一个问题，如果我们把正则性拿掉，需要补充什么条件才可以保证存在乘子（不一定是Lagrange乘子）满足类似的性质呢。&lt;/p&gt;
&lt;div id=&#34;fritz-john-&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fritz-John 最优性条件&lt;/h3&gt;
&lt;p&gt;假设$x^* $是满足下面问题的局部最小值点，&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{minimize}\; f(x)\qquad\qquad\qquad\qquad\\
\text{subject to}\; h_i(x)=0,i=1,2,...,m\\
\qquad\qquad g_j(x)\leq 0, j=1,2,...,r
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中 &lt;span class=&#34;math inline&#34;&gt;\(f: R^n\;\vert \rightarrow R\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(h_i: R^n\;\vert \rightarrow R\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(g_j: R^n\;\vert \rightarrow R\)&lt;/span&gt;均是连续可微的。那么存在唯一的标量&lt;span class=&#34;math inline&#34;&gt;\(\mu_0^* 和\)&lt;/span&gt;乘子&lt;span class=&#34;math inline&#34;&gt;\(\lambda^* =(\lambda_1^* ,...,\lambda_m^* ),\mu^* =(\mu_1^* ,...,\mu_r^* )\)&lt;/span&gt;满足如下条件:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_0^* \nabla f(x^* )+\sum_{i=1}^m\lambda_i\nabla h_i(x^* )+\sum_{j=1}^r\mu_j\nabla g_j(x^* )=0\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_j\geq 0\quad j=0,...,r\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_0^* ,\lambda_1^* ,...,\lambda_m^* ,\mu_1^* ,...,\mu_r^* \text{不全为0}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\text{在}x^* \text{的每个领域上都存在一点x使得对于所有不为0的}\lambda_i^* ,\text{有}\lambda_i^* h_i(x^* )&amp;gt;0;\text{对所有不为0的}\mu_j^* ,\text{有}\mu_j^* g_j(x)&amp;gt;0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;该命题的证明可以参考用惩罚法证明等式约束情况下的Lagrange最优性定理。即构造函数列&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[F_k(x)=f(x)+\frac{k}{2}\sum_{i=1}^m h_i(x)+\frac{k}{2}\sum_{j=1}^r(g^+_j(x))^2+\frac{1}{2}\vert \vert x-x^* \vert \vert ^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;然后考虑优化问题&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{minimize} F_k(x)\\
\text{subject to} x\in S
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中&lt;span class=&#34;math inline&#34;&gt;\(S=\{x\vert \vert \vert x-x^* \vert \vert \leq \epsilon\},\epsilon&amp;gt;0\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;条件4&lt;/code&gt;蕴含了互补松弛条件【&lt;span class=&#34;math inline&#34;&gt;\(\mu_j^* g_j(x)=0\)&lt;/span&gt;】。这是因为当&lt;span class=&#34;math inline&#34;&gt;\(\mu_j^* \neq 0\)&lt;/span&gt;时，由条件4我们有&lt;span class=&#34;math inline&#34;&gt;\(g_j(x)&amp;gt;0\)&lt;/span&gt;，再利用&lt;span class=&#34;math inline&#34;&gt;\(g_j(x)\)&lt;/span&gt;的连续性，我们知道&lt;span class=&#34;math inline&#34;&gt;\(g_j(x^* )=0\)&lt;/span&gt;,即条件4可以推出较弱的互补松弛条件。并且条件4缩小了满足Fritz-John条件候选乘子的范围。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;fritz-john--kkt-&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;从Fritz-John 条件到 KKT 条件&lt;/h3&gt;
&lt;p&gt;设$x^* &lt;span class=&#34;math inline&#34;&gt;\(是问题的局部最优值点，注意到只要能够证明到不存在\)&lt;/span&gt;_j^* =0&lt;span class=&#34;math inline&#34;&gt;\(使得Fritz-John 中的条件1-4成立，则我们可以保证\)&lt;/span&gt;_0&lt;sup&gt;* &amp;gt;0&lt;span class=&#34;math inline&#34;&gt;\(，进一步得到了以\)&lt;/span&gt;&lt;/sup&gt;* /_0&lt;sup&gt;* ,&lt;/sup&gt;* /_0^* &lt;span class=&#34;math inline&#34;&gt;\(为Lagrange乘子的KKT条件。不失一般性，我们可以只讨论\)&lt;/span&gt;_0^* =0,_0^* =1&lt;span class=&#34;math inline&#34;&gt;\(的两种情形【对于\)&lt;/span&gt;_0^* &amp;gt;0&lt;span class=&#34;math inline&#34;&gt;\(的情形只需等式两边同时除以\)&lt;/span&gt;_0^* &lt;span class=&#34;math inline&#34;&gt;\(】，下面几个命题告诉我们在什么情况下可以够保证不存在\)&lt;/span&gt;_j^* =0$使得Fritz-John 条件中的条件1-4成立。&lt;/p&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;正则性假设&lt;/h4&gt;
&lt;p&gt;假设$x^* $是满足正则性的下述问题的局部最小值点&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{minimize}\; f(x)\qquad\qquad\qquad\qquad\\
\text{subject to}\; h_i(x)=0,i=1,2,...,m\\
\qquad\qquad g_j(x)\leq 0, j=1,2,...,r
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中 &lt;span class=&#34;math inline&#34;&gt;\(f: R^n\;\vert \rightarrow R\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(h_i: R^n\;\vert \rightarrow R\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(g_j: R^n\;\vert \rightarrow R\)&lt;/span&gt;均是连续可微的。那么存在唯一的Lagrange乘子&lt;span class=&#34;math inline&#34;&gt;\(\lambda^* =(\lambda_1^* ,...,\lambda_m^* ),\mu^* =(\mu_1^* ,...,\mu_r^* )\)&lt;/span&gt;满足如下条件:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\nabla f(x^* )+\sum_{i=1}^m\lambda_i\nabla h_i(x^* )+\sum_{j=1}^r\mu_j\nabla g_j(x^* )=0\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_j\geq 0\quad j=0,...,r\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\text{在}x^* \text{的每个领域上都存在一点x使得对于所有不为0的}\lambda_i^* ,\text{有}\lambda_i^* h_i(x^* )&amp;gt;0;\text{对所有不为0的}\mu_j^* ,\text{有}\mu_j^* g_j(x)&amp;gt;0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;proof&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;由$x^* &lt;span class=&#34;math inline&#34;&gt;\(的正则性，我们知道对于不全为0的\)&lt;/span&gt;_1^* ,…,_m^* ,_1^* ,…,_r^* $下式不成立&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sum_{i=1}^m\lambda^* _i\nabla h_i(x^* )+\sum_{j=1}^r \mu_jg_j(x^* )=0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;故当&lt;span class=&#34;math inline&#34;&gt;\(\mu_0^* =0\)&lt;/span&gt;时，Fritz John条件1不成立。因此可以取&lt;span class=&#34;math inline&#34;&gt;\(\mu_0^* =1\)&lt;/span&gt;，并且由$x^* $的最优性，我们有&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\nabla f(x^* )+\sum_{i=1}^m\lambda^* _i\nabla h_i(x^* )+\sum_{j=1}^r \mu_jg_j(x^* )=0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;条件2与3是直接从Fritz John条件中得到的。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;线性等式约束和凹不等式约束假设&lt;/h4&gt;
&lt;p&gt;假设$x^* $是满足下述问题的局部最小值点&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{minimize}\; f(x)\qquad\qquad\qquad\qquad\\
\text{subject to}\; h_i(x)=0,i=1,2,...,m\\
\qquad\qquad g_j(x)\leq 0, j=1,2,...,r
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中 &lt;span class=&#34;math inline&#34;&gt;\(f: R^n\;\vert \rightarrow R\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(h_i: R^n\;\vert \rightarrow R\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(g_j: R^n\;\vert \rightarrow R\)&lt;/span&gt;均是连续可微的。假设所有&lt;span class=&#34;math inline&#34;&gt;\(h_i\)&lt;/span&gt;是线性函数，&lt;span class=&#34;math inline&#34;&gt;\(g_j\)&lt;/span&gt;是凹函数。那么存在唯一的Lagrange乘子&lt;span class=&#34;math inline&#34;&gt;\(\lambda^* =(\lambda_1^* ,...,\lambda_m^* ),\mu^* =(\mu_1^* ,...,\mu_r^* )\)&lt;/span&gt;满足如下条件:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\nabla f(x^* )+\sum_{i=1}^m\lambda_i\nabla h_i(x^* )+\sum_{j=1}^r\mu_j\nabla g_j(x^* )=0\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_j\geq 0\quad j=0,...,r\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\text{在}x^* \text{的每个领域上都存在一点x使得对于所有不为0的}\lambda_i^* ,\text{有}\lambda_i^* h_i(x^* )&amp;gt;0;\text{对所有不为0的}\mu_j^* ,\text{有}\mu_j^* g_j(x)&amp;gt;0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;proof&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;首先我们假设&lt;span class=&#34;math inline&#34;&gt;\(\mu_0^* =0\)&lt;/span&gt;。对任意&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;将&lt;span class=&#34;math inline&#34;&gt;\(h_i(x),g_j(x)\)&lt;/span&gt;分别在$x^* $展开到一阶，即&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
h_i(x)=h_i(x^* )+\nabla h_i(x^* )^T(x-x^* )\quad i=1,2,...,m \\
g_j(x)\leq g_i(x)^* +\nabla g_i(x^* )^T(x-x^* )\quad i=1,2,...,m 
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;对上式关于&lt;span class=&#34;math inline&#34;&gt;\(i,j\)&lt;/span&gt;求和得到&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\sum_{i=1}^m \lambda_i^* h_i(x)+\sum_{j=1}^r\mu_j^* g_j(x)\leq  \sum_{i=1}^m \lambda_i^* h_i(x^* )+\sum_{j=1}^r\mu_j^* g_j(x^* )+(x-x^* )^T\big(\sum_{i=1}^m \lambda_i^*  \nabla h_i(x^* )+\sum_{j=1}^r\mu_j^*  \nabla g_j(x^* )\big)\leq 0\quad (****)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;后面一个不等号成立是因为,由Fritz John条件1，&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sum_{i=1}^m \lambda_i^*  \nabla h_i(x^* )+\sum_{j=1}^r\mu_j^*  \nabla g_j(x^* )=0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;同时由$x&lt;sup&gt;* &lt;span class=&#34;math inline&#34;&gt;\(的最优性，我们有\)&lt;/span&gt;h_i(x&lt;/sup&gt;* )=0,g_j(x^* )0$。&lt;/p&gt;
&lt;p&gt;由Fritz John 条件3，我们可以知道，当&lt;span class=&#34;math inline&#34;&gt;\(\mu_0^* =0\)&lt;/span&gt;时，则&lt;span class=&#34;math inline&#34;&gt;\(\lambda_1^* ,...,\lambda_m^* ,\mu_1^* ,...,\mu_r^* \text{不全为0}\)&lt;/span&gt;。利用Fritz John 条件3，对于那些使得&lt;span class=&#34;math inline&#34;&gt;\(\lambda_i\neq ,\mu_j\neq 0\)&lt;/span&gt;的&lt;span class=&#34;math inline&#34;&gt;\(i,j\)&lt;/span&gt;,存在&lt;span class=&#34;math inline&#34;&gt;\(x_0\)&lt;/span&gt;满足&lt;span class=&#34;math inline&#34;&gt;\(\lambda_ih_i(x_0)&amp;gt;0,\mu_jg_j(x_0)&amp;gt;0\)&lt;/span&gt;，进而有&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sum_{i=1}^m \lambda_i^* h_i(x_0)+\sum_{j=1}^r\mu_j^* g_j(x_0)&amp;gt;0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;从而与（****）式矛盾。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;constraint-qualification&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Constraint Qualification&lt;/h4&gt;
&lt;p&gt;假设$x^* $是满足下述问题的局部最小值点&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{minimize}\; f(x)\qquad\qquad\qquad\qquad\\
\text{subject to}\; h_i(x)=0,i=1,2,...,m\\
\qquad\qquad g_j(x)\leq 0, j=1,2,...,r
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中 &lt;span class=&#34;math inline&#34;&gt;\(f: R^n\;\vert \rightarrow R\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(h_i: R^n\;\vert \rightarrow R\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(g_j: R^n\;\vert \rightarrow R\)&lt;/span&gt;均是连续可微的。假设&lt;span class=&#34;math inline&#34;&gt;\(\{\nabla h_i(x^* )\}\)&lt;/span&gt;线性无关，而且存在向量&lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;使得 &lt;span class=&#34;math inline&#34;&gt;\(\forall i\)&lt;/span&gt;以及&lt;span class=&#34;math inline&#34;&gt;\(\forall j\in A(x^* )\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[d^T\nabla h_i(x^* )&amp;gt;0 \qquad d^T\nabla g_j(x^* )&amp;lt;0 \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;那么存在唯一的Lagrange乘子&lt;span class=&#34;math inline&#34;&gt;\(\lambda^* =(\lambda_1^* ,...,\lambda_m^* ),\mu^* =(\mu_1^* ,...,\mu_r^* )\)&lt;/span&gt;满足如下条件:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\nabla f(x^* )+\sum_{i=1}^m\lambda_i\nabla h_i(x^* )+\sum_{j=1}^r\mu_j\nabla g_j(x^* )=0\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_j\geq 0\quad j=0,...,r\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\text{在}x^* \text{的每个领域上都存在一点x使得对于所有不为0的}\lambda_i^* ,\text{有}\lambda_i^* h_i(x^* )&amp;gt;0;\text{对所有不为0的}\mu_j^* ,\text{有}\mu_j^* g_j(x)&amp;gt;0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;proof&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;考虑满足Fritz John条件的乘子 $_0^* ,_1^* ,…,_m^* ,_1^* ,…,_r^* &lt;span class=&#34;math inline&#34;&gt;\(，以及假设\)&lt;/span&gt;_0^* =0$。则有&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sum_{i=1}^m\lambda_i\nabla h_i(x^* )+\sum_{j=1}^r\mu_j\nabla g_j(x^* )=0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由于$_1^* ,…,_m^* ,_1^* ,…,_r&lt;sup&gt;* &lt;span class=&#34;math inline&#34;&gt;\(不全为0。我们断言至少存在一个\)&lt;/span&gt;jA(x&lt;/sup&gt;* )&lt;span class=&#34;math inline&#34;&gt;\(使得\)&lt;/span&gt;_j&lt;sup&gt;* &amp;gt;0&lt;span class=&#34;math inline&#34;&gt;\(【否则与\)&lt;/span&gt;{h_i(x&lt;/sup&gt;* )}$线性无关矛盾】。因此有&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[d^T\big(\sum_{i=1}^m\lambda_i\nabla h_i(x^* )+\sum_{j=1}^r\mu_j\nabla g_j(x^* )\big)&amp;lt;0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;从而矛盾，因此有&lt;span class=&#34;math inline&#34;&gt;\(\mu_0^* =1\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;注意命题中&lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;的存在想问题，可以转换为更容易验证的假设，即对任意&lt;span class=&#34;math inline&#34;&gt;\(j\in A(x^* )\)&lt;/span&gt;存在&lt;span class=&#34;math inline&#34;&gt;\(d_j\)&lt;/span&gt;满足&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\forall i, d_j^T\nabla h_i(x^* )=0\\
\nabla d_j^Tg_j(x^* )&amp;lt;0 \qquad \nabla d_{\bar j}^Tg_{\bar j}(x^* )\leq 0 \quad \bar j \notin A(x^* )
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;取&lt;span class=&#34;math inline&#34;&gt;\(d=\sum_{j \in A(x^* )} d_j\)&lt;/span&gt;即可。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;凸不等式约束&lt;/h4&gt;
&lt;p&gt;假设$x^* $是满足下述问题的局部最小值点&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{minimize}\; f(x)\qquad\qquad\qquad\qquad\\
\text{subject to}\; h_i(x)=0,i=1,2,...,m\\
\qquad\qquad g_j(x)\leq 0, j=1,2,...,r
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中 &lt;span class=&#34;math inline&#34;&gt;\(f: R^n\;\vert \rightarrow R\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(h_i: R^n\;\vert \rightarrow R\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(g_j: R^n\;\vert \rightarrow R\)&lt;/span&gt;均是连续可微的。假设所有&lt;span class=&#34;math inline&#34;&gt;\(h_i\)&lt;/span&gt;是线性函数，&lt;span class=&#34;math inline&#34;&gt;\(g_j\)&lt;/span&gt;是凸函数。如果存在可行解&lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt;，使得&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[g_j(\bar x)&amp;lt;0,\forall j\in A(x^* )\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;那么存在唯一的Lagrange乘子&lt;span class=&#34;math inline&#34;&gt;\(\lambda^* =(\lambda_1^* ,...,\lambda_m^* ),\mu^* =(\mu_1^* ,...,\mu_r^* )\)&lt;/span&gt;满足如下条件:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\nabla f(x^* )+\sum_{i=1}^m\lambda_i\nabla h_i(x^* )+\sum_{j=1}^r\mu_j\nabla g_j(x^* )=0\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_j\geq 0\quad j=0,...,r\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\text{在}x^* \text{的每个领域上都存在一点x使得对于所有不为0的}\lambda_i^* ,\text{有}\lambda_i^* h_i(x^* )&amp;gt;0;\text{对所有不为0的}\mu_j^* ,\text{有}\mu_j^* g_j(x)&amp;gt;0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;Proof&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;考虑到&lt;span class=&#34;math inline&#34;&gt;\(h_i(x)\)&lt;/span&gt;的线性性，不失一般性，我们总可以假设&lt;span class=&#34;math inline&#34;&gt;\(\{\nabla h_i(x)\}\)&lt;/span&gt;线性无关【否则将对应的乘子设为0，从而获得一组线性无关的约束】。利用&lt;span class=&#34;math inline&#34;&gt;\(g_j(x)\)&lt;/span&gt;的凸性&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[0&amp;gt;g_j(\bar x)&amp;gt;g_j(x^* )+(\bar x-x^* )^T\nabla g_j(x^* )=(\bar x-x^* )^T\nabla g_j(x^* )\quad \forall j\in A(x^* )\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由&lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt;的可行性，&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[0=h_i(\bar x)=h_i(x^* )+(\bar x-x^* )^T\nabla h_i(x^* )=(\bar x-x^* )^T\nabla h_i(x^* )\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;令$d=x-x^* $，结合Constraint Qualification命题即的。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;凸集约束的情形&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;凸集约束下的 Fritz-John 最优性条件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;假设$x^* $是满足下面问题的局部最小值点，&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{minimize}\; f(x)\qquad\qquad\qquad\qquad\\
\text{subject to}\; h_i(x)=0,i=1,2,...,m\\
\qquad\qquad g_j(x)\leq 0, j=1,2,...,r\\
x\in X \qquad
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中 &lt;span class=&#34;math inline&#34;&gt;\(f: R^n\;\vert \rightarrow R\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(h_i: R^n\;\vert \rightarrow R\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(g_j: R^n\;\vert \rightarrow R\)&lt;/span&gt;均是连续可微的,X是一个闭凸集。那么存在唯一的标量&lt;span class=&#34;math inline&#34;&gt;\(\mu_0^* 和\)&lt;/span&gt;乘子&lt;span class=&#34;math inline&#34;&gt;\(\lambda^* =(\lambda_1^* ,...,\lambda_m^* ),\mu^* =(\mu_1^* ,...,\mu_r^* )\)&lt;/span&gt;满足如下条件:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;对任意&lt;span class=&#34;math inline&#34;&gt;\(x\in X\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(\mu_0^* \nabla f(x^* )+\sum_{i=1}^m\lambda_i\nabla h_i(x^* )+\sum_{j=1}^r\mu_j\nabla g_j(x^* )=0\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_j\geq 0\quad j=0,...,r\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_0^* ,\lambda_1^* ,...,\lambda_m^* ,\mu_1^* ,...,\mu_r^* \text{不全为0}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\text{在}x^* \text{的每个领域上N都存在一点}x\in X\cap N\text{使得对于所有不为0的}\lambda_i^* ,\text{有}\lambda_i^* h_i(x^* )&amp;gt;0;\text{对所有不为0的}\mu_j^* ,\text{有}\mu_j^* g_j(x)&amp;gt;0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;不难看出除了第一个条件其它条件都是Fritz-John 最优性条件的平行结果；而第一个条件平行于凸集约束的最优性条件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;凸集约束下的 Constraint Qualification&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;假设$x^* $是满足下面问题的局部最小值点，&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{minimize}\; f(x)\qquad\qquad\qquad\qquad\\
\text{subject to}\; h_i(x)=0,i=1,2,...,m\\
\qquad\qquad g_j(x)\leq 0, j=1,2,...,r\\
x\in X \qquad
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中 &lt;span class=&#34;math inline&#34;&gt;\(f: R^n\;\vert \rightarrow R\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(h_i: R^n\;\vert \rightarrow R\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(g_j: R^n\;\vert \rightarrow R\)&lt;/span&gt;均是连续可微的,X是一个闭凸集。并且满足下面两个条件:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;不存在非零向量&lt;span class=&#34;math inline&#34;&gt;\(\lambda =(\lambda_1,...,\lambda_m)\)&lt;/span&gt;使得&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[(x-x^* )^T\big(\sum_{i=1}^m\lambda_i^* \nabla h_i(x^* )\big)\quad \forall x\in X\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在$x^* &lt;span class=&#34;math inline&#34;&gt;\(处存在可行方向\)&lt;/span&gt;d$满足&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[d^T\nabla h_i(x^* )&amp;gt;0 \qquad d^T\nabla g_j(x^* )&amp;lt;0 \]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;那么存在唯一的标量&lt;span class=&#34;math inline&#34;&gt;\(\mu_0^* 和\)&lt;/span&gt;乘子&lt;span class=&#34;math inline&#34;&gt;\(\lambda^* =(\lambda_1^* ,...,\lambda_m^* ),\mu^* =(\mu_1^* ,...,\mu_r^* )\)&lt;/span&gt;满足如下条件:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;对任意&lt;span class=&#34;math inline&#34;&gt;\(x\in X\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(\mu_0^* \nabla f(x^* )+\sum_{i=1}^m\lambda_i\nabla h_i(x^* )+\sum_{j=1}^r\mu_j\nabla g_j(x^* )=0\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_j\geq 0\quad j=0,...,r\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_0^* ,\lambda_1^* ,...,\lambda_m^* ,\mu_1^* ,...,\mu_r^* \text{不全为0}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\text{在}x^* \text{的每个领域上N都存在一点}x\in X\cap N\text{使得对于所有不为0的}\lambda_i^* ,\text{有}\lambda_i^* h_i(x^* )&amp;gt;0;\text{对所有不为0的}\mu_j^* ,\text{有}\mu_j^* g_j(x)&amp;gt;0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;凸集约束下的凸不等式约束&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;假设$x^* $是满足下面问题的局部最小值点，&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{minimize}\; f(x)\qquad\qquad\qquad\qquad\\
\text{subject to}\; h_i(x)=0,i=1,2,...,m\\
\qquad\qquad g_j(x)\leq 0, j=1,2,...,r\\
x\in X \qquad
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中 &lt;span class=&#34;math inline&#34;&gt;\(f: R^n\;\vert \rightarrow R\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(h_i: R^n\;\vert \rightarrow R\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(g_j: R^n\;\vert \rightarrow R\)&lt;/span&gt;均是连续可微的,X是一个闭凸集。假设所有&lt;span class=&#34;math inline&#34;&gt;\(h_i\)&lt;/span&gt;是线性函数，&lt;span class=&#34;math inline&#34;&gt;\(g_j\)&lt;/span&gt;是凸函数，并且满足下面两个条件:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;不存在非零向量&lt;span class=&#34;math inline&#34;&gt;\(\lambda =(\lambda_1,...,\lambda_m)\)&lt;/span&gt;使得&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[(x-x^* )^T\big(\sum_{i=1}^m\lambda_i^* \nabla h_i(x^* )\big)\quad \forall x\in X\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;如果存在可行解&lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt;，使得&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[g_j(\bar x)&amp;lt;0,\forall j\in A(x^* )\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;那么存在唯一的标量&lt;span class=&#34;math inline&#34;&gt;\(\mu_0^* 和\)&lt;/span&gt;乘子&lt;span class=&#34;math inline&#34;&gt;\(\lambda^* =(\lambda_1^* ,...,\lambda_m^* ),\mu^* =(\mu_1^* ,...,\mu_r^* )\)&lt;/span&gt;满足如下条件:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;对任意&lt;span class=&#34;math inline&#34;&gt;\(x\in X\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(\mu_0^* \nabla f(x^* )+\sum_{i=1}^m\lambda_i\nabla h_i(x^* )+\sum_{j=1}^r\mu_j\nabla g_j(x^* )=0\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_j\geq 0\quad j=0,...,r\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_0^* ,\lambda_1^* ,...,\lambda_m^* ,\mu_1^* ,...,\mu_r^* \text{不全为0}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\text{在}x^* \text{的每个领域上N都存在一点}x\in X\cap N\text{使得对于所有不为0的}\lambda_i^* ,\text{有}\lambda_i^* h_i(x^* )&amp;gt;0;\text{对所有不为0的}\mu_j^* ,\text{有}\mu_j^* g_j(x)&amp;gt;0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Lagrange乘子理论(2)</title>
      <link>/post/zh/lag2/</link>
      <pubDate>Wed, 14 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/zh/lag2/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a&gt;不等式约束优化问题&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#karush-kuhn-tucker-&#34;&gt;Karush-Kuhn-Tucker 必要条件&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a&gt;充分条件&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;不等式约束优化问题&lt;/h2&gt;
&lt;p&gt;本节我们考虑优化问题&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{minimize}\; f(x)\qquad\qquad\qquad\qquad\\
\text{subject to}\; h_i(x)=0,i=1,2,...,m\\
\qquad\qquad g_j(x)\leq 0, j=1,2,...,r
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中 &lt;span class=&#34;math inline&#34;&gt;\(f: R^n\;\vert \rightarrow R\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(h_i: R^n\;\vert \rightarrow R\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(g_j: R^n\;\vert \rightarrow R\)&lt;/span&gt;均是连续可微的。为了记号简洁性，我们引入向量值函数&lt;span class=&#34;math inline&#34;&gt;\(h=(h_1,...,h_m)^T\)&lt;/span&gt;,即&lt;span class=&#34;math inline&#34;&gt;\(h: R^n\;\vert \rightarrow R^m\)&lt;/span&gt;与&lt;span class=&#34;math inline&#34;&gt;\(g=(g_1,...,g_r)^T\)&lt;/span&gt;,即&lt;span class=&#34;math inline&#34;&gt;\(g: R^n\;\vert \rightarrow R^r\)&lt;/span&gt;。 从而约束条件变为了 &lt;span class=&#34;math inline&#34;&gt;\(h(x)=0,g(x)\leq 0\)&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;karush-kuhn-tucker-&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Karush-Kuhn-Tucker 必要条件&lt;/h3&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;直观分析&lt;/h4&gt;
&lt;p&gt;一个直观的想法是，我们尽可能的扔掉一些不等式约束。事实上，若一些不等式约束不起作用（即局部最小值点在约束集的内部取得），则这些不等式约束可以忽略。举个简单的例子，考虑如下的岭回归问题&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mathop{min}_\beta\qquad  \vert \vert Y-X\beta\vert \vert ^2\\
\text{subject to:}\quad  \vert \vert \beta\vert \vert \leq t
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;当&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;足够大时，则该不等式约束不起作用（见下图）。从而我们引出&lt;strong&gt;积极的不等式约束集&lt;/strong&gt;的概念。 &lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161218_3.png&#34; alt=&#34;Snip20161218_3&#34; /&gt;&lt;/p&gt;
&lt;p&gt;对任意任意的可行点&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, &lt;strong&gt;积极的不等式约束集&lt;/strong&gt;定义为：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[A(x)=\{j\big\vert g_j(x)=0, j=1,2,...,r\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果&lt;span class=&#34;math inline&#34;&gt;\(j\notin A(x)\)&lt;/span&gt;，则我们称第j个约束是非积极地。&lt;/p&gt;
&lt;p&gt;正如上面所讨论的，若&lt;span class=&#34;math inline&#34;&gt;\(x^*\)&lt;/span&gt;是优化问题的局部最小值点，那么也是该问题去掉了非积极约束后新问题的局部最小值点。（下图还是以岭回归为例做一个简要说明，表明非等式约束条件不起作用。） &lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161218_4.png&#34; alt=&#34;Snip20161218_4&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;kkt-&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;KKT 必要条件&lt;/h4&gt;
&lt;p&gt;下面我们来严格的叙述下上述的结论，首先给出一个不等式版本的&lt;strong&gt;正则性条件&lt;/strong&gt;： 称一个可行解&lt;span class=&#34;math display&#34;&gt;\[x^*\]&lt;/span&gt;是正则的，若在该点梯度构成的向量组 &lt;span class=&#34;math display&#34;&gt;\[\{h_i(x^*),g_j(x^*)\big\vert  i=1,2,...,m j\in A(x^*)\}\]&lt;/span&gt; 线性无关&lt;/p&gt;
&lt;p&gt;&lt;em&gt;KKT 必要性条件&lt;/em&gt; 假设&lt;span class=&#34;math display&#34;&gt;\[x^*\]&lt;/span&gt;是满足下面问题的局部最小值点且是正则的，&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{minimize}\; f(x)\qquad\qquad\qquad\qquad\\
\text{subject to}\; h_i(x)=0,i=1,2,...,m\\
\qquad\qquad g_j(x)\leq 0, j=1,2,...,r
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中 &lt;span class=&#34;math inline&#34;&gt;\(f: R^n\;\vert \rightarrow R\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(h_i: R^n\;\vert \rightarrow R\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(g_j: R^n\;\vert \rightarrow R\)&lt;/span&gt;均是连续可微的。那么存在唯一的Lagrange乘子&lt;span class=&#34;math display&#34;&gt;\[\lambda^*=(\lambda_1^*,...,\lambda_m^*),\mu^*=(\mu_1^*,...,\mu_r^*)\]&lt;/span&gt;使得Lagrange函数&lt;span class=&#34;math inline&#34;&gt;\(L(x,\lambda,\mu)=f(x)+\lambda^Th(x)+\mu^Th(x)\)&lt;/span&gt;关于&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;的偏导数为0,即&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\nabla_x L(x^*,\lambda^*,\mu^*)=0\\
\mu_j\geq 0\quad j=1,...,r\\
\mu_j=0\quad j\notin A(x^*)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中&lt;span class=&#34;math inline&#34;&gt;\(A(x^*)\)&lt;/span&gt;是积极的不等式约束集。如果进一步&lt;span class=&#34;math inline&#34;&gt;\(f,h,g\)&lt;/span&gt;二次连续可微，则对所有满足&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y^T\nabla h_i(x^*)=0,\forall i=1,2..,m\qquad \nabla y^Tg_j(x^*)=0,j\in A(x^*)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;的y，我们都有&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y^T\nabla^2_{xx} L(x^*,\lambda^*,\mu^*)y\geq 0 \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;关于&lt;span class=&#34;math inline&#34;&gt;\(\mu_j\geq 0\)&lt;/span&gt;有如下几何解释 &lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161219_6.png&#34; alt=&#34;Snip20161219_6&#34; /&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在实际使用该定理的时候，我们利用一阶必要性条件&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\nabla_x L(x^*,\lambda^*,\mu^*)=0\\
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;找到待选点。然后再检查每个不等式是不是积极约束。 &lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161219_7.png&#34; alt=&#34;Snip20161219_7&#34; /&gt; &lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161219_8.png&#34; alt=&#34;Snip20161219_8&#34; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;我们称&lt;span class=&#34;math display&#34;&gt;\[\mu_j=0\quad j\notin A(x^*)\]&lt;/span&gt;或者等价的&lt;span class=&#34;math display&#34;&gt;\[\mu_j^*g_j(x^*)=0\]&lt;/span&gt;为互补松弛条件。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;转换为等式约束处理&lt;/h4&gt;
&lt;p&gt;换个角度看待我们的优化问题，如果我们引入一系列的辅助变量，则可以利用第一节提到的等式约束最优性条件。具体做法是引入辅助变量&lt;span class=&#34;math inline&#34;&gt;\(z_1,...,z_r\)&lt;/span&gt;并考虑如下优化问题&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{minimize}\; f(x)\qquad\qquad\qquad\qquad\\
\text{subject to}\; h_i(x)=0,i=1,2,...,m\\
\qquad\qquad g_j(x)+z_j^2=0, j=1,2,...,r
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;若&lt;span class=&#34;math display&#34;&gt;\[x^*\]&lt;/span&gt;是原问题的局部最小值，那么&lt;span class=&#34;math display&#34;&gt;\[(x^*,z^*)\]&lt;/span&gt;是该问题的局部最小值，其中&lt;span class=&#34;math display&#34;&gt;\[z^*=(z_1^*,...,z_r^*)\]&lt;/span&gt;且&lt;span class=&#34;math display&#34;&gt;\[z_j^*=\sqrt{-g_j(x^*)}\]&lt;/span&gt;。显然当&lt;span class=&#34;math display&#34;&gt;\[x^*\]&lt;/span&gt;是原问题的正则点当且仅当&lt;span class=&#34;math display&#34;&gt;\[(x^*,z^*)\]&lt;/span&gt;是该问题的正则点。对于该问题我们利用等式约束版本的一阶最优性条件，我们有&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\nabla_x L(x^*,\lambda^*,\mu^*)=0 \qquad\qquad\\
2\mu_j^*z_j^*=0,\quad j=1,2,...,r
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由于对于&lt;span class=&#34;math inline&#34;&gt;\(j\notin A(x^*)\)&lt;/span&gt;，有&lt;span class=&#34;math inline&#34;&gt;\(z_j^*&amp;gt;0\)&lt;/span&gt;,故最后一族等式等价于&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mu_j^*=0,\quad j\notin A(x^*)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;到此，为了证明KKT的必要性条件，我们还要证明&lt;span class=&#34;math inline&#34;&gt;\(\mu_j\geq 0\)&lt;/span&gt;以及二阶必要性条件。首先利用等式约束的二阶必要性条件，我们有&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
(x,z)^T
\begin{pmatrix}
\nabla_{xx}^2L(x^*,\lambda^*,\mu^*) &amp;amp;      0                &amp;amp;     0            &amp;amp; \dots     &amp;amp;         0\\
                            0                               &amp;amp; 2\mu_1^*       &amp;amp;     0            &amp;amp; \dots     &amp;amp;         0\\
                            0                               &amp;amp;       0               &amp;amp;  2\mu_2^* &amp;amp; \dots     &amp;amp;         0\\
                            \vdots                       &amp;amp;   \vdots           &amp;amp;   \vdots     &amp;amp;  \vdots  &amp;amp;  \vdots\\
                            0                               &amp;amp;       0               &amp;amp;      0           &amp;amp;  \dots   &amp;amp;  2\mu_r^*\\
\end{pmatrix}
\begin{pmatrix}
x\\
z
\end{pmatrix}\geq 0\qquad (++)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中&lt;span class=&#34;math inline&#34;&gt;\(x\in R^n,z\in R^r\)&lt;/span&gt;满足&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x^T\nabla h_i(x^*)=0\quad x^T\nabla g_j(x^*)+2z_j^*z_j=0\quad i=1,...,m,j=1,..,r\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;选取满足如下的&lt;span class=&#34;math inline&#34;&gt;\((x,z)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
z_j=\begin{cases}
        \qquad 0\quad,  j\in A(x^*)\\
        -\frac{x^T\nabla g_j(x^*)}{2z_j^*},j\notin A(x^*)
    \end{cases}\\
x^T\nabla h_i(x^*)=0\quad x^T\nabla g_j(x^*)=0
\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;容易检验，这样定义的&lt;span class=&#34;math inline&#34;&gt;\((x,z_j)\)&lt;/span&gt;满足&lt;span class=&#34;math display&#34;&gt;\[x^T\nabla g_j(x^*)+2z_j^*z_j=0\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;由&lt;span class=&#34;math inline&#34;&gt;\(z_j\)&lt;/span&gt;定义以及&lt;span class=&#34;math display&#34;&gt;\[\mu_j^*=0,j\notin A(x^*)\]&lt;/span&gt;,则对所有的&lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;,我们有&lt;span class=&#34;math display&#34;&gt;\[\mu_j^*z_j=0\]&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;将上述定义的&lt;span class=&#34;math inline&#34;&gt;\((x,z)\)&lt;/span&gt;代入(++)即可证明:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x^T\nabla_{xx}^2L(x^*,\lambda^*,\mu^*)x\geq 0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;至于待证的&lt;span class=&#34;math inline&#34;&gt;\(\mu_j\geq 0\)&lt;/span&gt;，只需考虑&lt;span class=&#34;math inline&#34;&gt;\(j\in A(x^*)\)&lt;/span&gt;的情形,这时定义&lt;span class=&#34;math inline&#34;&gt;\((x,z)\)&lt;/span&gt;如下:&lt;span class=&#34;math inline&#34;&gt;\(x=0,z_j\neq 0\)&lt;/span&gt;对任意&lt;span class=&#34;math inline&#34;&gt;\(k\neq j\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(z_k=0\)&lt;/span&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;该定义满足&lt;span class=&#34;math display&#34;&gt;\[x^T\nabla g_j(x^*)+2z_j^*z_j=0\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;利用(++)得到&lt;span class=&#34;math display&#34;&gt;\[\mu_j\geq 0,\forall j\in A(x^*)\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;充分条件&lt;/h3&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;二阶充分条件&lt;/h4&gt;
&lt;p&gt;假定&lt;span class=&#34;math inline&#34;&gt;\(f: R^n\;\vert \rightarrow R\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(h_i: R^n\;\vert \rightarrow R\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(g_j: R^n\;\vert \rightarrow R\)&lt;/span&gt;均是连续且二次可微的,并且&lt;span class=&#34;math display&#34;&gt;\[x^*\in R^n,\lambda^*\in R^m,\mu^*\in R^r\]&lt;/span&gt;满足&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\nabla_x (x^*,\lambda^*,\mu^*)=0 \qquad  h(x^*)=0 \qquad g(x^*)\leq 0\\
\mu_j^*&amp;gt; 0, j\in A(x^*) \quad \mu_j^*=0,j\notin A(x^*)\\
y^T\nabla_{xx}^2L(x^*,\lambda^*,\mu^*)y\geq 0 \qquad\qquad\quad
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中&lt;span class=&#34;math inline&#34;&gt;\(y\neq 0\)&lt;/span&gt;并且使得&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y^T\nabla h_i(x^*)=0,\forall i=1,...,m \quad y^T\nabla g_j(x^*)=0,\forall j\in A(x^*)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;那么&lt;span class=&#34;math display&#34;&gt;\[x^*\]&lt;/span&gt;是&lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;满足约束条件下的严格局部最小值点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;定理的证明可以将不等式约束换成等式约束，然后利用等式约束版本的二阶充分性条件即可证明。&lt;/li&gt;
&lt;li&gt;条件&lt;span class=&#34;math display&#34;&gt;\[\mu_j^*&amp;gt; 0, j\in A(x^*)\]&lt;/span&gt;被称作&lt;strong&gt;严格的互补松弛条件&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;一般充分条件&lt;/h4&gt;
&lt;p&gt;到目前为止，我们讨论的二阶条件都需要二阶导数存在的假设，在研究无约束优化问题时，我们知道一阶最优性条件加上凸性即可保证最优解的充分性。带约束的问题，也存在类似的定理。事实上，我们甚至不需要凸性以及可微性的假设，而只需要一个最小化Lagrange函数的条件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一般充分性条件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;考虑如下优化问题&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{minimize}\; f(x)\qquad\quad\qquad \\
\text{subject to}\; x\in X \qquad\qquad\\
\qquad\qquad\qquad g_j(x)\leq0, j=1,2,...,r
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中&lt;span class=&#34;math inline&#34;&gt;\(f,g_j\)&lt;/span&gt;定义在&lt;span class=&#34;math display&#34;&gt;\[R^n\]&lt;/span&gt;上的实值函数,&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;是给定的&lt;span class=&#34;math display&#34;&gt;\[R^n\]&lt;/span&gt;的子集。假设&lt;span class=&#34;math display&#34;&gt;\[x^*\]&lt;/span&gt;是该问题的一个可行解,&lt;span class=&#34;math display&#34;&gt;\[\mu^*=(\mu_1^*,...,\mu_r^*)\]&lt;/span&gt;是给定的向量，并且满足:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mu_j\geq 0\quad j=1,...,r\\
\mu_j=0\quad j\notin A(x^*)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;而且&lt;span class=&#34;math display&#34;&gt;\[x^*\]&lt;/span&gt;是Lagrange函数&lt;span class=&#34;math inline&#34;&gt;\(L(x,\mu^*)\)&lt;/span&gt;在&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;上的最小值，则&lt;span class=&#34;math display&#34;&gt;\[x^*\]&lt;/span&gt;是该问题的全局最小值。 &lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161219_13.png&#34; alt=&#34;Snip20161219_13&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Lagrange乘子理论(1)</title>
      <link>/post/zh/lag1/</link>
      <pubDate>Wed, 07 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/zh/lag1/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a&gt;等式约束优化问题&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a&gt;最优解的必要条件&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a&gt;最优解充分条件&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;通过引入一些辅助变量，即Lagrange乘子，我们可以利用他们：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;描述最优解的特性&lt;/li&gt;
&lt;li&gt;灵敏度分析&lt;/li&gt;
&lt;li&gt;对自变量变化引起的目标函数的一阶导数进行定量描述&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本章将沿着&lt;code&gt;惩罚法&lt;/code&gt;和&lt;code&gt;可行方向法&lt;/code&gt;两个角度进行讨论。&lt;/p&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;等式约束优化问题&lt;/h2&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;最优解的必要条件&lt;/h3&gt;
&lt;p&gt;本节我们考虑优化问题：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{minimize}\; f(x)\qquad\qquad\qquad\qquad\\
\text{subject to}\; h_i(x)=0,i=1,2,...,m\\
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中 &lt;span class=&#34;math inline&#34;&gt;\(f: R^n\;\vert \rightarrow R\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(h_i: R^n\;\vert \rightarrow R\)&lt;/span&gt;均是连续可微的。为了记号简洁性，我们引入向量值函数&lt;span class=&#34;math inline&#34;&gt;\(h=(h_1,...,h_m)^T\)&lt;/span&gt;,即&lt;span class=&#34;math inline&#34;&gt;\(h: R^n\;\vert \rightarrow R^m\)&lt;/span&gt;。 从而约束条件变为了 &lt;span class=&#34;math inline&#34;&gt;\(h(x)=0\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Lagrange 理论解决上述优化问题的办法是，通过引入Lagrange乘子&lt;span class=&#34;math inline&#34;&gt;\(\lambda=(\lambda_1,...,\lambda_m)^T\)&lt;/span&gt;，构造Lagrange函数&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[L(x,\lambda)=f(x)+\lambda^T h(x)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;转而考察&lt;span class=&#34;math inline&#34;&gt;\(L(x,\lambda)\)&lt;/span&gt;。该理论指出，对给定的局部最小值点$x_* &lt;span class=&#34;math inline&#34;&gt;\(，存在向量\)&lt;/span&gt;_* $满足&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\nabla f(x_* )+{\lambda_* }^T\nabla h(x_* )=0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;这个方程有两种解释:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;目标函数的梯度&lt;span class=&#34;math inline&#34;&gt;\(\nabla f(x_* )\)&lt;/span&gt;属于&lt;span class=&#34;math inline&#34;&gt;\(\{\nabla h_1(x_* ),...,\nabla h_m(x_* )\}\)&lt;/span&gt;这个向量组张成的n维线性子空间里；&lt;/li&gt;
&lt;li&gt;&lt;p&gt;目标函数的梯度&lt;span class=&#34;math inline&#34;&gt;\(\nabla f(x_* )\)&lt;/span&gt;正交于一阶可行变分子空间，即&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[V(x_* )=\{\Delta x=x-x_* \vert  (x-x_* )^T\nabla h_i(x_* )=0,i=1,2..,m\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;注意到，&lt;span class=&#34;math inline&#34;&gt;\(\forall \Delta x\in V(x_* )\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\nabla h(x_* ) \Delta x=0\)&lt;/span&gt;，从而结合上式，我们有&lt;span class=&#34;math inline&#34;&gt;\(\Delta x^T\nabla f(x_* )=0\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;一阶可行变分子空间中的元素是使得&lt;span class=&#34;math inline&#34;&gt;\(h(x)\)&lt;/span&gt;的一阶近似，&lt;span class=&#34;math inline&#34;&gt;\(h(x_* )+\nabla h(x)\Delta x\)&lt;/span&gt;，在&lt;span class=&#34;math inline&#34;&gt;\(x+\Delta x\)&lt;/span&gt;取值同样为0的元素构成的集合。这是对约束条件&lt;span class=&#34;math inline&#34;&gt;\(h(.)\)&lt;/span&gt;的性质刻画。&lt;/li&gt;
&lt;li&gt;这里&lt;span class=&#34;math inline&#34;&gt;\(V(x_* )\)&lt;/span&gt;的作用类似于带约束优化问题的约束集。在Chapter2中，最优解得$x_* &lt;span class=&#34;math inline&#34;&gt;\(满足的必要条件\)&lt;/span&gt;xX&lt;span class=&#34;math inline&#34;&gt;\(为(\)&lt;/span&gt;X$是约束集)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\nabla f(x_* )(x-x_* )\geq 0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;这里&lt;span class=&#34;math inline&#34;&gt;\(\Delta x^T\nabla f(x_* )=0\)&lt;/span&gt;与上述结论是相似的，同样也类似于Chapter1中提到的一阶“零梯度条件”&lt;span class=&#34;math inline&#34;&gt;\(\nabla f(x_* )=0\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面给出&lt;code&gt;Lagrange乘子定理&lt;/code&gt;的严格表述&lt;/p&gt;
&lt;p&gt;如果 $x_* &lt;span class=&#34;math inline&#34;&gt;\(是\)&lt;/span&gt;f$在 &lt;span class=&#34;math inline&#34;&gt;\(h(x)=0\)&lt;/span&gt;约束条件下的局部最小值点，且假定梯度向量组&lt;span class=&#34;math inline&#34;&gt;\(\{\nabla h_1(x_* ),...,\nabla h_m(x_* )\}\)&lt;/span&gt;,线性无关，那么存在唯一的向量$_* $使得&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\nabla f(x_* )+{\lambda_* }^T\nabla h(x)=0\qquad (一阶条件)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;进一步，如果&lt;span class=&#34;math inline&#34;&gt;\(f,h\)&lt;/span&gt;二次可微，那么有，对任意&lt;span class=&#34;math inline&#34;&gt;\(\Delta x\in V(x_* )\)&lt;/span&gt;,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\Delta x^T\big(\nabla f(x_* )+{\lambda_* }^T\nabla h(x_* )\big)\Delta x\in V(x_* )\geq 0\qquad (二阶条件)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;我们称可行向量&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;为正则的，若约束函数梯度&lt;span class=&#34;math inline&#34;&gt;\(\{\nabla h_1(x),...,\nabla h_m(x)\}\)&lt;/span&gt;线性无关。&lt;/li&gt;
&lt;li&gt;对应于一阶可行变分子空间，我们还要引入&lt;code&gt;真正可行变分集&lt;/code&gt;这个概念。从一阶可行变分子空间的定义不难看出&lt;span class=&#34;math inline&#34;&gt;\(V(x_* )=\{\Delta x\vert \nabla h(x_* )\Delta x=0\}\)&lt;/span&gt;。假设&lt;span class=&#34;math inline&#34;&gt;\(x_* \in R^n\)&lt;/span&gt;,且通常假设&lt;span class=&#34;math inline&#34;&gt;\(m\leq n\)&lt;/span&gt;，则&lt;span class=&#34;math inline&#34;&gt;\(V(x_* )\)&lt;/span&gt;是一个线性方程组的解空间，该空间的维数为&lt;span class=&#34;math inline&#34;&gt;\(n-r( \nabla h(x_* ))\geq n-m\)&lt;/span&gt;。当$x_* &lt;span class=&#34;math inline&#34;&gt;\(满足正则条件式，我们就称\)&lt;/span&gt;V(x_* )$为真正可行变分集。&lt;/li&gt;
&lt;li&gt;&lt;p&gt;存在反例表明，在非正则的局部最小值点处的Lagrange乘子可以不存在。 &lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161201_2.png&#34; alt=&#34;Snip20161201_2&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt; 从一阶可行变分子空间的角度看，由于一阶变分子空间&lt;span class=&#34;math inline&#34;&gt;\(V(x_* )=\{(0,y_2)\vert y_2\in R\}\)&lt;/span&gt;的维数为1，但是真正可行变分集&lt;span class=&#34;math inline&#34;&gt;\(\{(y_1,y_2)\vert y_1=y_2=0\}\)&lt;/span&gt;的维数为0，因此一阶变分子空间比正真可行变分集具有更高的维数。由Lagrange理论指出，$x_* &lt;span class=&#34;math inline&#34;&gt;\(的最优性只能保证\)&lt;/span&gt;f(x_* )&lt;span class=&#34;math inline&#34;&gt;\(正交于可行变分集，但是要使得Lagrange乘子存在，\)&lt;/span&gt;f(x_* )&lt;span class=&#34;math inline&#34;&gt;\(正交于一阶变分子空间。故当\)&lt;/span&gt;{h_1(x),…,h_m(x)}$线性无关时，两个变分集合是相等的。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;当约束条件是线性约束时，比如&lt;span class=&#34;math inline&#34;&gt;\(AX=0\)&lt;/span&gt;，则即使没有&lt;span class=&#34;math inline&#34;&gt;\(\{\nabla h_1(x_* ),...,\nabla h_m(x_* )\}\)&lt;/span&gt;线性无关也可成立，即不需要$x_* $正则的正则性,具体讨论见&lt;code&gt;消元法&lt;/code&gt;这一小节。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对于该理论，我们有两种证明的方法，他们都是基于将有约束的优化问题化为无约束的优化问题，但是思路不同&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;惩罚法：通过对违反约束的情况进行很高的惩罚，从而不必考虑约束条件。通过列出这些带惩罚项的无约束问题的最优性条件，同时让惩罚项的增加趋于无穷大时，可以得到Lagrange乘子定理;&lt;/li&gt;
&lt;li&gt;消元法：把约束条件看做一个n个未知数m个方程的线性方程组(n&amp;gt;m)，将m个变量表示成n-m个变量的函数形式，从而化成无约束的优化问题，进而利用一阶、二阶必要性条件，也可以得到Lagrange乘子定理。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;惩罚法&lt;/h4&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161201_4.png&#34; alt=&#34;Snip20161201_4&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Snip20161201_4&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161201_6.png&#34; alt=&#34;Snip20161201_6&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Snip20161201_6&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;消元法&lt;/h4&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161201_7.png&#34; alt=&#34;Snip20161201_7&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Snip20161201_7&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161201_8.png&#34; alt=&#34;Snip20161201_8&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Snip20161201_8&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上述讨论说明了，在线性约束条件下，Lagrange乘子定理只是要求定义在&lt;span class=&#34;math inline&#34;&gt;\(n-m\)&lt;/span&gt;维空间上的无约束问题(3.12)的“零梯度性”和“Hessian阵半正定性”。&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161201_9.png&#34; alt=&#34;Snip20161201_9&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Snip20161201_9&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161201_10.png&#34; alt=&#34;Snip20161201_10&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Snip20161201_10&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;最优解充分条件&lt;/h3&gt;
&lt;p&gt;利用一阶必要性条件选出来的点，有可能是局部最小值，局部最大值点乃至其他点，加上二阶必要条件可以缩小备选点。但是我们有必要给出判断局部最小点的充分条件。&lt;/p&gt;
&lt;p&gt;【二阶充分条件】 假定&lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(h\)&lt;/span&gt;是二阶可微函数，并且&lt;span class=&#34;math inline&#34;&gt;\(x_* \in R^n,\lambda_* \in R^m\)&lt;/span&gt;满足&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
 \nabla_x L(x_* ,\lambda_* )=0,\nabla_\lambda L(x_* ,\lambda_* )=0\\
 x^T\nabla_{xx} L(x_* ,\lambda_* )x&amp;gt;0\quad 对所有满足\nabla h(x_* )x^T=0的非零x
 \]&lt;/span&gt; 则$x_* &lt;span class=&#34;math inline&#34;&gt;\(是\)&lt;/span&gt;f&lt;span class=&#34;math inline&#34;&gt;\(满足约束\)&lt;/span&gt;h(x)=0&lt;span class=&#34;math inline&#34;&gt;\(的严格局部最小值点，并且存在\)&lt;/span&gt;,&amp;gt;0&lt;span class=&#34;math inline&#34;&gt;\(使得对任意满足\)&lt;/span&gt;h(x)=0,x-x_* &lt;span class=&#34;math inline&#34;&gt;\(的\)&lt;/span&gt;x$成立&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x)-f(x_* )\geq \frac{\gamma}{2}\vert \vert x-x_* \vert \vert ^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;该充分条件并不需要$x_* $的正则性。&lt;/p&gt;
&lt;p&gt;对于该命题，我们打算采取两种方法来证明，一是augmented Lagrange方法，二是可行方向法。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;augmented Lagrange方法的思想在于，通过引入augmented Lagrange函数，&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[L_c(x,\lambda)=f(x)+\lambda^Th(x)+\frac{c}{2}\vert \vert h(x)\vert \vert ^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;使得带约束的原问题&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mathop{min}_{h(x)=0} f(x)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;与新问题问题&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mathop{min}_{h(x)=0} f(x)+\frac{c}{2}\vert \vert h(x)\vert \vert ^2\]&lt;/span&gt;&lt;/p&gt;
有相同的局部最优解。&lt;/li&gt;
&lt;li&gt;&lt;p&gt;可行方向法的思想在于，利用反正法，假设存在一系列比$x_* $更优的点，通过这些点构造方向导出矛盾。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;augmented-lagrange&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;augmented Lagrange方法&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161208_1.png&#34; alt=&#34;Snip20161208_1&#34; /&gt; &lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161208_2.png&#34; alt=&#34;Snip20161208_2&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;可行方向法&lt;/h4&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161208_3.png&#34; alt=&#34;Snip20161208_3&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Snip20161208_3&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Convergence Analysis for Bloock Coordinate Decent Algorithm and Powell&#39;s Examples</title>
      <link>/post/en/convergence-analysis-for-block-coordinate-descent-algorithm-and-powells-examples/</link>
      <pubDate>Thu, 17 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/en/convergence-analysis-for-block-coordinate-descent-algorithm-and-powells-examples/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#problem-description&#34;&gt;Problem description&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#notations&#34;&gt;Notations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#assumption&#34;&gt;Assumption&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#algorithm&#34;&gt;Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#convergence-analysis&#34;&gt;Convergence Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#powells-example&#34;&gt;Powell’s example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#r-codes-for-numerical-experiments&#34;&gt;R codes for numerical experiments&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;We mainly focus on the convergence of Block coordinate decent with exact minimization, whose block update strategy employs Gauss-Seidel manner. And then use Powell’s example to see what will happen if some conditions are not met.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Reference: 1. Dimitri .P Bertsekas, Nonlinear Programming 2ed 2. Powell ,1973, ON SEARCH DIRECTIONS FOR MINIMIZATION ALGORITHMS&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;problem-description&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Problem description&lt;/h1&gt;
&lt;div id=&#34;notations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Notations&lt;/h2&gt;
&lt;p&gt;We want to solve the problem:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mathop{min}_{x\in X}\quad f(x)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where X is a Cartesian product of closed convex sets $X_1,…,X_m:X=_{i=1}^n X_i $&lt;/p&gt;
&lt;p&gt;We assume that &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt; is a closed convex subset of &lt;span class=&#34;math inline&#34;&gt;\(R^{n_i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n=\sum_{i=1}^m n_i\)&lt;/span&gt;. The vector is partitioned into &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; block(s) such that &lt;span class=&#34;math inline&#34;&gt;\(x_i \in X^{n_i}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We denote &lt;span class=&#34;math inline&#34;&gt;\(\nabla_i f\)&lt;/span&gt; as the gradient of &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; with respect to component &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumption&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumption&lt;/h2&gt;
&lt;p&gt;We shall assume that for every &lt;span class=&#34;math inline&#34;&gt;\(x\in X\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(i=1,2,...m\)&lt;/span&gt; the optimization problem&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mathop{min}_{\xi\in X_i}\quad f(x_1,...,x_{i-1},\xi,x_{i+1,....,x_m})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;has &lt;strong&gt;at least one solution&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;algorithm&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Algorithm&lt;/h2&gt;
&lt;p&gt;The Gauss-Seidel method, generates the next iterate &lt;span class=&#34;math inline&#34;&gt;\(x^{k+1}=(x^{k+1}_1,...,x^{k+1}_m)\)&lt;/span&gt;, given the current the iterate &lt;span class=&#34;math inline&#34;&gt;\(x^{k}=(x^{k}_1,...,x^{k}_m)\)&lt;/span&gt;, according to the iteration&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x^{k+1}_i=\mathop{argmin}_{\xi\in X_i}\quad f(x_1^{k+1},...,x^{k+1}_{i-1},\xi,x^k_{i+1},...,x_m^k)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;convergence-analysis&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Convergence Analysis&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;Theorem&lt;/code&gt; Suppose that &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; is &lt;strong&gt;continuously differentiable&lt;/strong&gt; over the set &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; defined as above. Furthermore, suppose that for each &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x\in X\)&lt;/span&gt;,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x_1,...,x_{i-1},\xi,x_{i+1,....,x_m})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;viewed as a function of &lt;span class=&#34;math inline&#34;&gt;\(\xi\)&lt;/span&gt;, attains a unique minimum &lt;span class=&#34;math inline&#34;&gt;\(\bar x_i\)&lt;/span&gt; over &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt; and is monotonically non-increasing in the interval from &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(\bar \xi\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(\{x_k\}\)&lt;/span&gt; be the sequence generated by the block coordinate method with Gauss-Seidel manner. Then, every limit point of &lt;span class=&#34;math inline&#34;&gt;\(\{x_k\}\)&lt;/span&gt; is a stationary point.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;PROOF&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Let&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[z_i^k=(x_1^{k+1},...,x_i^{k+1},x_{i+1}^k,...,x_m^k)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;By the nature of this algorithm, for all &lt;span class=&#34;math inline&#34;&gt;\(k\geq 0\)&lt;/span&gt;, we have following inequality&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x^k)\geq f(z_1^k)\geq f(z_2^k)\geq ...\geq f(z_{m-1}^k)\geq f(x^{k+1}) \quad (*)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Since &lt;span class=&#34;math inline&#34;&gt;\(\{x_k\}in X\)&lt;/span&gt;, we can assume &lt;span class=&#34;math inline&#34;&gt;\(\{x^{k_j}\}\)&lt;/span&gt; is the subsequence that converges to &lt;span class=&#34;math inline&#34;&gt;\(\bar x=(\bar x_1,..,\bar x_m)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Now we want prove that &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt; is the stationary point of &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;From (*), we know that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(z_1^{k_j})\leq f(x_1,x_2^{k_j},..., x_m^{k_j})\qquad \forall x_1\in X_1\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(j\rightarrow +\infty\)&lt;/span&gt;, we derive&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(\bar x)\leq f(x_1,\bar x_2,..., \bar x_m)\overset \Delta = h(x_1)\qquad \forall x_1\in X_1\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;which implies that &lt;span class=&#34;math inline&#34;&gt;\(\bar x_i\)&lt;/span&gt; is the minima of &lt;span class=&#34;math inline&#34;&gt;\(h(x_1)\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(X_1\)&lt;/span&gt;. Using the optimality over a convex set, we conclude that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[h&amp;#39;(\bar x_1)(\bar x_1 -x_1)\geq 0 \Leftrightarrow (x_1-\bar x_1)^T\nabla_1f(\bar x_1)\geq 0\qquad x_1\in X_1\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;At this stage, if we can prove that &lt;span class=&#34;math inline&#34;&gt;\(\{z_1^{k_j}\}\)&lt;/span&gt; converges to &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt;, we can show that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ (x_2-\bar x_2)^T\nabla_2 f(\bar x_2)\geq 0\qquad x_2\in X_2\]&lt;/span&gt;, since&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(z_1^{k_j})=f(x_1^{k_j+1},x_2^{k_j},x_3^{k_j},...,x_m^{k_j})\leq f(x_1^{k_j+1},x_2,x_3^{k_j},...,x_m^{k_j})\qquad x_2\in X_2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(j\rightarrow +\infty\)&lt;/span&gt;, we derive&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(\bar x)\leq f(\bar x_1,\bar x_2,\bar x_3,..., \bar x_m)\qquad \forall x_2\in X_2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[(x_2-\bar x_2)^T\nabla_2f(\bar x_2)\geq 0\qquad x_2\in X_2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;(Note: Although &lt;span class=&#34;math inline&#34;&gt;\(x_1^{k_j+1}\)&lt;/span&gt; may not in the sequence &lt;span class=&#34;math inline&#34;&gt;\(\{x_1^{k_t}\}_{t\geq 1}\)&lt;/span&gt; ,which convergences to &lt;span class=&#34;math inline&#34;&gt;\(\bar x_1\)&lt;/span&gt;, but &lt;span class=&#34;math inline&#34;&gt;\(\{z_1^{k_j}\}\)&lt;/span&gt; converges to &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt;, so its component &lt;span class=&#34;math inline&#34;&gt;\(x_1^{k_j+1}\)&lt;/span&gt; converges to &lt;span class=&#34;math inline&#34;&gt;\(\bar x_1\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;Furthermore, if we prove that for &lt;span class=&#34;math inline&#34;&gt;\(i=1,2,...,m-1\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(\{z_i^{k_j}\}\)&lt;/span&gt; convergences to &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt;, then we have&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[(x_i-\bar x_i)^T\nabla_i\;f(\bar x_i)\geq 0\qquad x_i\in X_i\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;And thus &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt; is a stationary point, since &lt;span class=&#34;math inline&#34;&gt;\((x-\bar x)^T\nabla f(\bar x)\geq 0\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;By far, it remains to prove that &lt;span class=&#34;math inline&#34;&gt;\(\{z_i^{k_j}\}\quad,\forall i\)&lt;/span&gt; convergence to &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt;. First,we try to prove that &lt;span class=&#34;math inline&#34;&gt;\(\{z_1^{k_1}\}\)&lt;/span&gt; convergence to &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Assume the contrary that $r&lt;sup&gt;{k_j}=z_1&lt;/sup&gt;{k_j}-x^{k_j}$ doesn’t convergence to 0. Let &lt;span class=&#34;math inline&#34;&gt;\(s_1^{k_j}=(z_1^{k_j}-x^{k_j})/r^{k_j}\)&lt;/span&gt;. Thus, &lt;span class=&#34;math inline&#34;&gt;\(z_1^{k_j}=x^{k_j}+r^{k_j}s_1^{k_j}\)&lt;/span&gt; , &lt;span class=&#34;math inline&#34;&gt;\(\vert \vert r_{k_j}\vert \vert =1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(s_1^{k_j}\)&lt;/span&gt; differs from 0 only along the first block-component. Since &lt;span class=&#34;math inline&#34;&gt;\(\{s_1^{k_j}\}\)&lt;/span&gt; belong to a compact set and therefore without loss of generality, we assume &lt;span class=&#34;math inline&#34;&gt;\(s_1^{k_j}\)&lt;/span&gt; convergences to &lt;span class=&#34;math inline&#34;&gt;\(\bar s_1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Since &lt;span class=&#34;math inline&#34;&gt;\(r^{k_j}&amp;gt;0\)&lt;/span&gt;,we can find a &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\in (0,1)\)&lt;/span&gt;, such that &lt;span class=&#34;math inline&#34;&gt;\(x^{k_j}+\epsilon s_1^{k_j}\)&lt;/span&gt; lies on the segment joining &lt;span class=&#34;math inline&#34;&gt;\(x^{k_j}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x^{k_j}+s_1^{k_j}=z_1^{k_j}\)&lt;/span&gt;. Using the non-increasing property of &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;,we derive,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(z_1^{k_j})\leq f(x^{k_j}+\epsilon s_1^{k_j}) \leq f(x^{k_j})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Again, using (*), we conclude&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x^{k_{j+1}})\leq f(z_1^{k_j})\leq f(x^{k_j}+\epsilon s_1^{k_j}) \leq f(x^{k_j})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(j\rightarrow +\infty\)&lt;/span&gt;, we derive &lt;span class=&#34;math inline&#34;&gt;\(f(\bar x)=f(\bar x+\epsilon \bar s_1)\)&lt;/span&gt;, which contradicts the hypothesis that &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; is uniquely minimized when viewed as a function of the first block component. This contradiction establishes that &lt;span class=&#34;math inline&#34;&gt;\(\{z_1^{k_1}\}\)&lt;/span&gt; convergence to &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Similarly, let $r_t&lt;sup&gt;{k_j}=z_t&lt;/sup&gt;{k_j}-z_{t-1}^{k_j}$ for &lt;span class=&#34;math inline&#34;&gt;\(t=2,3,...,m-1\)&lt;/span&gt; and using the same technique shown above, we finally prove that &lt;span class=&#34;math inline&#34;&gt;\(\{z_i^{k_j}\},\quad \forall i\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;powells-example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Powell’s example&lt;/h1&gt;
&lt;p&gt;In &lt;em&gt;ON SEARCH DIRECTIONS FOR MINIMIZATION ALGORITHMS&lt;/em&gt;, Power actually gives three examples that sequences generated by the algorithm discussed above do not convergence to stationary points once some hypothesis are not met.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The first example is straightforward, However, the remarkable properties of this example can be destroyed by making a small perturbation to the starting vector &lt;span class=&#34;math inline&#34;&gt;\(x^0\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The second example is not sensitive to either small changes in the initial data or to small errors introduced during the iterative process, for example computer rounding errors.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The third example suggests that a function that is infinitely differentiable that also causes an endless loop in the iterative minimization method.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We here only presents the first example. Consider the following function&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x,y,z)=-(xy+yz+zx)+(x-1)_+^2+(-x-1)_+^2+(y-1)_+^2+(-y-1)_+^2+(z-1)_+^2+(-z-1)_+^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[(x-c)_+^2=\begin{cases}0,x-c&amp;lt; 0\\ (x-c)^2,x-c\geq 0\end{cases}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Given the starting point &lt;span class=&#34;math inline&#34;&gt;\(x_0=(-1-e,1+\frac{1}{2}e,-1-\frac{1}{4}e)\)&lt;/span&gt; and use block coordinate decent algorithm,and we update the variable in a manner of &lt;span class=&#34;math inline&#34;&gt;\(x\rightarrow y\rightarrow z\rightarrow x ...\)&lt;/span&gt; with&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x_{k+1}^{**}\leftarrow sign(y_k+z_k)[1+\frac{1}{2}\vert y_k+z_k\vert ]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{k+1}^{**}\leftarrow sign(x_{k+1}+z_k)[1+\frac{1}{2}\vert x_{k+1}+z_k\vert ]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[z_{k+1}^{**}\leftarrow sign(x_{k+1}+y_{k+1})[1+\frac{1}{2}\vert x_{k+1}+y_{k+1}\vert ]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We here present the first six steps of this case&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;cycle/totall iteration&lt;/th&gt;
&lt;th&gt;x&lt;/th&gt;
&lt;th&gt;y&lt;/th&gt;
&lt;th&gt;z&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{8}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+$e $&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{4}e\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;1/2&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{8}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{16}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{4}e\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;1/3&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{8}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{16}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{32}e\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;2/4&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{64}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{16}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{32}e\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;2/5&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{64}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{128}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{32}e\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;2/6&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{64}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{128}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{256}e\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;3/7&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{512}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{128}e\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{256}e\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This result implies that the sequence obtained by this algorithm can not converge to one single point since &lt;span class=&#34;math inline&#34;&gt;\(x-coordinate\)&lt;/span&gt; change its sign as the even cycle and odd cycle alternate. Situations are similar for &lt;span class=&#34;math inline&#34;&gt;\(y-coordinate\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(z-coordinate\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;But &lt;span class=&#34;math inline&#34;&gt;\(\{x_k\}\)&lt;/span&gt; has six sub-sequences which convergence to (1,1,-1), (1,-1,-1), (1,-1,1), (-1,-1,1),(-1,-1,1),(-1,1,1),(-1,1,-1) respectively.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/14748787199151.jpg&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;A hint to derive the update formula:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x\leftarrow sign(y+z)[1+\frac{1}{2}(y+z)]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Indeed, derivates of &lt;span class=&#34;math inline&#34;&gt;\((x-1)_+^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\((-x-1)_+^2\)&lt;/span&gt; are as follows respecively&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{d(x-1)_+^2}{dx}=\begin{cases}2(x-1),x\geq 1\\0,x&amp;lt;1\end{cases}\quad 
    \frac{d(-x-1)_+^2}{dx}=\begin{cases}2(-x-1),x\leq -1\\0,x&amp;gt;-1\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;So for the univariate optimization problem, setting the derivate of &lt;span class=&#34;math inline&#34;&gt;\(g(x)=f(x,y,z)\)&lt;/span&gt; to zero, we conclude&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{\partial f(x,y,x)}{\partial x}=0\Rightarrow 
\begin{cases}x\geq 1: x=1+\frac{1}{2}(y+z)\\-1&amp;lt; x&amp;lt;1: -(y+z)=0\\x\leq -1:x=-1+\frac{1}{2}(y+z) \end{cases}\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The gradient of &lt;span class=&#34;math inline&#34;&gt;\(f(x,y,z)\)&lt;/span&gt; on this cyclic path, is &lt;span class=&#34;math inline&#34;&gt;\(\nabla f(x,y,z)=(-y-z,-x-z,-x-y)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\vert \vert \nabla f(x,y,z)\vert \vert _1=2\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;This example is unstable with respect to small perturbations. Small changes in the starting point &lt;span class=&#34;math inline&#34;&gt;\(x_0=(-1-e,1+\frac{1}{2}e,-1-\frac{1}{4}e)\)&lt;/span&gt; or smal errors in the numbers that are computed during the calculation will destroy the cyclic behavior.&lt;/p&gt;
&lt;p&gt;It’s s clear the choice of perturbations &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt; plays a key role. Say, &lt;span class=&#34;math inline&#34;&gt;\(x_0=(-1-e_1,1+e_2,-1-e_3)\)&lt;/span&gt; and we have &lt;span class=&#34;math inline&#34;&gt;\(e_k=\frac{1}{2}(e_{k-2}- e_{k-1})\)&lt;/span&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;cycle/totall iteration&lt;/th&gt;
&lt;th&gt;x&lt;/th&gt;
&lt;th&gt;y&lt;/th&gt;
&lt;th&gt;z&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(e_4\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(e_2\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(e_3\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;1/2&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(e_4\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(e_5\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(e_3\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;1/3&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(e_4\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(e_5\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(e_6\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;2/4&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(e_7\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(e_5\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(e_6\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;2/5&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(e_7\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(e_8\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(e_6\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;2/6&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(e_7\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;1+&lt;span class=&#34;math inline&#34;&gt;\(e_8\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;-1-&lt;span class=&#34;math inline&#34;&gt;\(e_9\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;To preserve the cyclic behavior , we have to make sure that &lt;span class=&#34;math inline&#34;&gt;\(e_{k-2}&amp;gt;e_{k-1}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;And in practice, when we do some numerical tests, we shall find that, this theoretically-existed endless loop actual breaks down due to the rounding errors. A brief illustration is given below. In this experiment, loop ends at the 52 steps.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161117_13.png&#34; alt=&#34;Snip20161117_13&#34; /&gt; &lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161117_14.png&#34; alt=&#34;Snip20161117_14&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161117_15.png&#34; alt=&#34;Snip20161117_15&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Snip20161117_15&lt;/p&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;As&lt;br /&gt;
&lt;span class=&#34;math display&#34;&gt;\[\frac{\partial f(x,y,x)}{\partial x}=0\Rightarrow 
\begin{cases}x\geq 1: x=1+\frac{1}{2}(y+z)\\-1&amp;lt; x&amp;lt;1: -(y+z)=0\\x\leq -1:x=-1+\frac{1}{2}(y+z) \end{cases}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;suggests that, when &lt;span class=&#34;math inline&#34;&gt;\(-1&amp;lt;x&amp;lt;1\)&lt;/span&gt;, the choice of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is arbitrary and we set &lt;span class=&#34;math inline&#34;&gt;\(x^*=0\)&lt;/span&gt; in the case above. So the uniqueness requirement is violated. It turns out that the six vertices are even not the stationary points.&lt;/p&gt;
&lt;p&gt;For example, at point &lt;span class=&#34;math inline&#34;&gt;\(\bar x=(1,1,-1)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\nabla f(\bar x)=(0,0,-2)\)&lt;/span&gt; and for any ponit &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; in the unit cubic &lt;span class=&#34;math inline&#34;&gt;\((x-\bar x)^T\nabla f(\bar x)\leq 0\)&lt;/span&gt;. Say, &lt;span class=&#34;math inline&#34;&gt;\(x=(0.9,0.9,-0.9)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\((x-\bar x)^T\nabla f(\bar x)=-0.2&amp;lt;0\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Actually, as in the proof of &lt;code&gt;Theorem&lt;/code&gt;, we prove that &lt;span class=&#34;math inline&#34;&gt;\(\{z_1^{k_j}\}\)&lt;/span&gt; converges to &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\bar x\)&lt;/span&gt; is the limit point of &lt;span class=&#34;math inline&#34;&gt;\(\{x^{k_j}\}\)&lt;/span&gt;. But in this example, the limit point of &lt;span class=&#34;math inline&#34;&gt;\(\{z_1^{k_j}\}\)&lt;/span&gt; is (1,1,-1) while the limit point of &lt;span class=&#34;math inline&#34;&gt;\(\{x^{k_j}\}\)&lt;/span&gt; is either (-1,1,-1) or (1,-1,1). So the requirement of uniqueness is not met.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;r-codes-for-numerical-experiments&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R codes for numerical experiments&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;####################
### Function for test ###
####################

PowellE1&amp;lt;-function(xstart,cycles,fig=T){
  #######function part ##############
  UpdateCycle&amp;lt;-function(x){
    Sign&amp;lt;-function(x){
      if (x&amp;gt;0){
        return(1)
      }else{
        if (x&amp;lt;0){
          return(-1)
        }else{
          return(0)
        }
      }
    }
    x.new&amp;lt;-c()
    x.new[1]&amp;lt;-Sign(x[2]+x[3])*(1+0.5*abs(x[2]+x[3]))
    x.new[2]&amp;lt;-Sign(x.new[1]+x[3])*(1+0.5*abs(x.new[1]+x[3]))
    x.new[3]&amp;lt;-Sign(x.new[1]+x.new[2])*(1+0.5*abs(x.new[1]+x.new[2]))
    cycle&amp;lt;-matrix(c(x.new[1],x[2],x[3],x.new[1],x.new[2],x[3],x.new[1],x.new[2],x.new[3]),
                  ncol=3,byrow=T)
    return(cycle)
  }
  
  fpowell&amp;lt;-function(x){
    
    PostivePart&amp;lt;-function(x){
      ifelse(x&amp;gt;=0,x,0)
    }
    
    fval&amp;lt;-(-(x[1]*x[2]+x[2]*x[3]+x[1]*x[3]))+
      PostivePart(x[1]-1)^2+PostivePart(-x[1]-1)^2+
      PostivePart(x[2]-1)^2+PostivePart(-x[2]-1)^2+
      PostivePart(x[3]-1)^2+PostivePart(-x[3]-1)^2
    return(fval)
  }
  ############ operation part ################
  x.store&amp;lt;-matrix(ncol=3,nrow=cycles*3+1)
  x.store[1,]&amp;lt;-xstart
  for (i in seq_len(cycles)){
    x.store[(3*i-1):(3*i+1),]&amp;lt;-UpdateCycle(x.store[3*i-2,])
  }
  x.store&amp;lt;-x.store[-1,]
  fval&amp;lt;-rep(0,cycles*3)
  
  for(i in seq_len(cycles*3)){
    fval[i]&amp;lt;-fpowell(x.store[i,])
  }
  fval&amp;lt;-as.matrix(fval)
  
  if (fig==T){
    plot(fval,ylim=c(min(fval)-1,max(fval)+1),type=&amp;quot;l&amp;quot;,xlab=&amp;quot;Iterations&amp;quot;,ylab = &amp;quot;F value&amp;quot;)
  }
  r&amp;lt;-list()
  r$x.iterate&amp;lt;-x.store
  r$fval&amp;lt;-fval
  return(r)
}


##################
#### Test 1 ########
##################


perturb&amp;lt;-0.5
xstart&amp;lt;-c(-1-perturb,1+0.5*perturb,-1-0.25*perturb)
cycles&amp;lt;-20

r&amp;lt;-PowellE1(xstart,cycles,fig=T)

##################
#### Test 2 ########
##################

perturb&amp;lt;-0.5
xstart&amp;lt;-c(-1-perturb,1+0.5*perturb,-1-0.25*perturb)
cycles&amp;lt;-20

r&amp;lt;-PowellE1(xstart,cycles,fig=T)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/EN/2016-11-17-stationary-powell_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;##################
#### Test 3 ########
##################

xstart&amp;lt;-c(3,2,1)
cycles&amp;lt;-100

r&amp;lt;-PowellE1(xstart,cycles,fig=T)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/EN/2016-11-17-stationary-powell_files/figure-html/unnamed-chunk-1-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>约束优化(2)</title>
      <link>/post/zh/con2/</link>
      <pubDate>Mon, 14 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/zh/con2/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a&gt;可行方向法&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a&gt;下降方向&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a&gt;步长准则&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a&gt;寻找初始可行点&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a&gt;收敛性&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#case&#34;&gt;Case：条件梯度法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;可行方向法&lt;/h2&gt;
&lt;p&gt;下面我们讨论，如何求解第一节中提到的优化问题。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mathop{min}_{x\in X}\qquad f(x)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;X是非空、闭凸集&lt;/li&gt;
&lt;li&gt;函数 &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; 是连续可微的&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们这里讨论的方法平行于不带约束的优化问题：即沿着函数下降的方向产生一个可行点列&lt;span class=&#34;math inline&#34;&gt;\(\{x_k\}\)&lt;/span&gt;。&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;下降方向&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;可行方向：给定可行点 &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, 在&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;处的一个可行方向是指一个向量&lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;,对所有充分小的正数&lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt;,成立&lt;span class=&#34;math inline&#34;&gt;\(ad+x\in X\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;可行方向法： 从初始可行方向开始，然后按照类似梯度方法的形式产生下述迭代列:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x_{k+1}=x_k+a_kd_k\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中&lt;span class=&#34;math inline&#34;&gt;\(\{d_k\}\)&lt;/span&gt;既是可行方向，也是下降方向，即&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\forall k, \nabla f(x_k)^Td_k\leq 0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;同时&lt;span class=&#34;math inline&#34;&gt;\(a_k\)&lt;/span&gt;是正的步长，使得有&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x_k+a_kd_k\in X\\ f(x_k+a_kd_k)&amp;lt; f(x_k)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;为了保证产生的迭代序列都是可行点，我们要求&lt;span class=&#34;math inline&#34;&gt;\(x_k+ad_k\in X\)&lt;/span&gt;, 因此存在异于&lt;span class=&#34;math inline&#34;&gt;\(x_k\)&lt;/span&gt;的点&lt;span class=&#34;math inline&#34;&gt;\(\bar x_k\in X\)&lt;/span&gt;,使得&lt;span class=&#34;math inline&#34;&gt;\(x_k+ad_k=\bar x_k\)&lt;/span&gt;,因此我们可以改写&lt;span class=&#34;math inline&#34;&gt;\(d_k=r(\bar x_k-x_k)\)&lt;/span&gt;,进而我们改写迭代式为&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x_{k+1}=x_k+a_k(\bar x_k-x_k)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中对于所有的k，&lt;span class=&#34;math inline&#34;&gt;\(a_k\in (0,1],\bar x_k\in X\)&lt;/span&gt;。 限制&lt;span class=&#34;math inline&#34;&gt;\(a_k\in (0,1]\)&lt;/span&gt;， 是为了保证&lt;span class=&#34;math inline&#34;&gt;\(x_{k+1}\)&lt;/span&gt;在&lt;span class=&#34;math inline&#34;&gt;\(x_k\)&lt;/span&gt;与&lt;span class=&#34;math inline&#34;&gt;\(\bar x_{k}\)&lt;/span&gt;的连线上，进而利用&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的凸性保证&lt;span class=&#34;math inline&#34;&gt;\(x_{k+1}\in X\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;按照改写方式产生的序列&lt;span class=&#34;math inline&#34;&gt;\(\{x_k\}\)&lt;/span&gt;中的点&lt;span class=&#34;math inline&#34;&gt;\(x_k\)&lt;/span&gt;如果不是驻点，则一定能够找到&lt;span class=&#34;math inline&#34;&gt;\(\bar x_k\in X\)&lt;/span&gt;满足&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[(\bar x_k-x_k)\nabla f(x_k)&amp;lt;0\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在后面的分析中，我们总是假设可行方向形如&lt;span class=&#34;math inline&#34;&gt;\(d_k=\bar x_k-x_k\)&lt;/span&gt;。因此，可行方向法可以看做是交替寻找合适的&lt;span class=&#34;math inline&#34;&gt;\(\bar x_k\)&lt;/span&gt;与&lt;span class=&#34;math inline&#34;&gt;\(a_k\)&lt;/span&gt;的算法。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;步长准则&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;有限最小化准则&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[a_k=\mathop{argmin}_{a\in [0,1]} f(x_k+a(\bar x_k-x_k))\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Armijo准则&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;给定&lt;span class=&#34;math inline&#34;&gt;\(\beta&amp;gt;0,\sigma&amp;gt;0\)&lt;/span&gt;,其中&lt;span class=&#34;math inline&#34;&gt;\(\beta\in (0,1),\sigma\in (0,1)\)&lt;/span&gt;,并且假设&lt;span class=&#34;math inline&#34;&gt;\(a_k=\beta^{m_k}\)&lt;/span&gt;，其中&lt;span class=&#34;math inline&#34;&gt;\(m_k\)&lt;/span&gt;是使得下式成立的第一个非负整数&lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt;,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x_k)-f(x_k+\beta^{m}(\bar x_k-x_k))\geq -\sigma\beta^m\nabla f(x_k)(\bar x_k-x_k)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;寻找初始可行点&lt;/h3&gt;
&lt;p&gt;我们考虑利用人造变量的方法构造初始可行点, 我们要求该人工变量非负并且在目标函数中具有很大的惩罚系数，从而保证去在最优解中为0。特别地，我们考虑两类约束问题:&lt;/p&gt;
&lt;p&gt;第一类，等式约束:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mathop{min}\;f(x) \qquad\qquad\qquad\qquad\qquad\qquad\qquad\\
subject\; to\; a_i^Tx=b_i\qquad i=1,2,..,m,\quad x\geq 0
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中&lt;span class=&#34;math inline&#34;&gt;\(a_i\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(b_i\)&lt;/span&gt;分别是&lt;span class=&#34;math inline&#34;&gt;\(R^n\)&lt;/span&gt;中的向量和给定的常数。于是上述问题可以被如下问题所替代，&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mathop{min}\;f(x)+cy \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\\
subject\; to\; a_i^Tx+(b_i-\sum_{j=1}^na_{i,j})y=b_i\qquad i=1,2,..,m,\quad x,y\geq 0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中c是一个很大的惩罚系数，&lt;span class=&#34;math inline&#34;&gt;\(a_{i,j}\)&lt;/span&gt;是&lt;span class=&#34;math inline&#34;&gt;\(a_i\)&lt;/span&gt;的第j个分量。向量&lt;span class=&#34;math inline&#34;&gt;\((x_0,y_0)=(\bf{1_n},1)\)&lt;/span&gt;是一个可行解。&lt;/p&gt;
&lt;p&gt;第二类，不等式约束:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mathop{min}\; f(x)\qquad\qquad\qquad\qquad\qquad\qquad\qquad\\
subject\; to\; a_i^Tx\leq b_i\qquad  i=1,2,..,m,\quad x\geq 0
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;同样可以转化成&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mathop{min}\; f(x)+cy \qquad\qquad\qquad\qquad\qquad\qquad\qquad\\
subject\; to\; a_i^Tx-y\leq b_i\qquad i=1,2,..,m,\quad x,y\geq 0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中c是一个很大的惩罚系数。对原问题任何不可行的向量&lt;span class=&#34;math inline&#34;&gt;\(x_0\)&lt;/span&gt;,向量&lt;span class=&#34;math inline&#34;&gt;\((x_0,y_0)\)&lt;/span&gt;均是新问题的可行解，其中&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_0=\mathop{max}_{i}\{a_i^Tx_0-b_i\}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;收敛性&lt;/h3&gt;
&lt;p&gt;可行方向法的收敛性分析在最小化步长准则或者Armijo准则下，和Chapter1中的梯度方法分析是平行的。同样我们假设方向序列&lt;span class=&#34;math inline&#34;&gt;\(\{d_k=\bar x_k-x_k\}\)&lt;/span&gt;与迭代序列&lt;span class=&#34;math inline&#34;&gt;\(\{x_k\}\)&lt;/span&gt;是梯度相关的。我们有如下结论&lt;/p&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(\{x_k\}\)&lt;/span&gt;是由可行方法&lt;span class=&#34;math inline&#34;&gt;\(x_{k+1}=x_{k}+a_kd_k\)&lt;/span&gt;产生的序列,假设&lt;span class=&#34;math inline&#34;&gt;\(\{d_k\}\)&lt;/span&gt;是梯度相关的并且&lt;span class=&#34;math inline&#34;&gt;\(a_k\)&lt;/span&gt;的选取是根据Armijo准则或者最小化准则选取的，那么&lt;span class=&#34;math inline&#34;&gt;\(\{x_k\}\)&lt;/span&gt;的每一个极限点(若存在)都是驻点。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;case&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Case：条件梯度法&lt;/h3&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;方法&lt;/h4&gt;
&lt;p&gt;为了找到合适的&lt;span class=&#34;math inline&#34;&gt;\(\bar x_k\)&lt;/span&gt;,满足&lt;span class=&#34;math inline&#34;&gt;\(\nabla f(x_k)^T(\bar x_k-x_k)&amp;lt; 0\)&lt;/span&gt;， 在前面的讨论中，当&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;是紧集时，我们知道这样的&lt;span class=&#34;math inline&#34;&gt;\(\bar x_k\)&lt;/span&gt;是一定存在的，并且为了使得函数下降得尽可能多，我们考虑如下子优化问题&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mathop{min}_{x\in X}\nabla f(x_k)^T(x-x_k)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;利用该问题的最优解 &lt;span class=&#34;math inline&#34;&gt;\(\bar x_k=\mathop{agrmin}_{x\in X} \nabla f(x_k)^T(x-x_k)\)&lt;/span&gt; 可以得到新的下降方向。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;该优化问题的几何直观非常明确，就是寻找&lt;span class=&#34;math inline&#34;&gt;\(\bar x_{k}\)&lt;/span&gt;在当前迭代带点&lt;span class=&#34;math inline&#34;&gt;\(x_k\)&lt;/span&gt;的负梯度方向&lt;span class=&#34;math inline&#34;&gt;\(-\nabla f(x_k)\)&lt;/span&gt;投影最长的点。 &lt;img src=&#34;http://ogfa13jyv.bkt.clouddn.com/Snip20161121_3.png&#34; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;考虑计算的实用性，我们总是希望该优化问题比原问题求解更加容易。一个典型的例子是，当&lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;是非线性函数，&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;为线性等式及不等式构成的约束的时候，该子问题是线性规划，容易求解。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
